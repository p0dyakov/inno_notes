[
  {
    "objectID": "Mathematical Analysis I/lec_1.html",
    "href": "Mathematical Analysis I/lec_1.html",
    "title": "1. Real Analysis, Complex Numbers",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 What is Real Analysis?\n\n1.1.1 The Foundation of Calculus\nReal analysis is the branch of mathematics that provides the rigorous, theoretical foundation for calculus. While introductory calculus teaches you how to use rules like the chain rule or L’Hopital’s rule, real analysis explains why these rules are true. It builds the entire framework of calculus from a small set of fundamental truths, or axioms. The primary goal is to gain a deep understanding of concepts like the limit, the derivative, and the integral.\n\n\n1.1.2 The Dangers of Applying Rules Blindly\nTo study mathematics effectively, one must know not just what is true, but why it is true. Applying familiar algebraic rules without understanding their underlying principles and limitations can lead to logical disasters.\n\nExample 1: Hidden Division by Zero: In the equation \\(x(x+1) = x^2\\), one might be tempted to cancel an x from both sides to get \\(x+1 = x\\), which implies the absurdity \\(1=0\\). The error is canceling x without first checking if it is zero.\nExample 2: Invalid Operations on Infinite Sequences: An incorrect manipulation of limits can “prove” that the sequence \\(1, 2, 4, 8, ...\\) converges to zero. The operations used in the faulty proof are only valid if the limit exists in the first place, which it does not for this sequence.\nExample 3: Manipulating Infinite Series: The same algebraic trick can be used to show that \\(1 + 1/2 + 1/4 + ... = 2\\) (which is correct) and that \\(1 + 2 + 4 + ... = -1\\) (which is nonsensical). This demonstrates that rules for finite sums do not automatically apply to infinite series.\n\n\n\n\n1.2 Essential Tools: Logic and Set Theory\n\n1.2.1 Logical Symbols and Statements\nAnalysis relies on precise language. A statement is something that is either true or false, but not both.\n\nConjunction (\\(\\land\\)): Read as “and”.\nDisjunction (\\(\\lor\\)): Read as “or”.\nImplication (\\(\\Rightarrow\\)): “A implies B” or “If A, then B”.\nEquivalence (\\(\\Leftrightarrow\\)): “A if and only if B”.\nQuantifiers: ∀ reads as “for all”. ∃ reads as “there exists”.\n\n\n\n1.2.2 Fundamentals of Set Theory\nA set is a well-defined collection of distinct objects, called elements.\n\nEmpty Set (\\(\\emptyset\\)): The set containing no elements.\nSubset (\\(\\subseteq\\)): A set A is a subset of B if every element of A is also in B.\nUnion (\\(\\cup\\)): \\(A \\cup B\\) is the set of all elements in A, or in B, or in both.\nIntersection (\\(\\cap\\)): \\(A \\cap B\\) is the set containing only elements common to both A and B.\nComplement (\\(A^c\\)): Relative to a universal set U, the complement of A is the set of all elements in U that are not in A.\nDe Morgan’s Laws: \\((A \\cup B)^c = A^c \\cap B^c\\) and \\((A \\cap B)^c = A^c \\cup B^c\\).\n\n\n\n\n\n1.3 The Real Number System (\\(\\mathbb{R}\\))\n\n1.3.1 The Axiomatic Foundation\nThe real numbers (\\(\\mathbb{R}\\)) are defined rigorously by a set of axioms.\n\nField Axioms (Algebraic): These define standard arithmetic (commutativity, associativity, identities, inverses, distributivity).\nOrder Axioms: These establish the properties of inequality (&lt;, &gt;), ensuring that any two real numbers can be compared.\nCompleteness Axiom: This is the key axiom that ensures there are no “holes” on the number line. Its most common form is the Least Upper Bound Property: every non-empty set of real numbers that is bounded above has a least upper bound (a supremum).\n\n\n\n1.3.2 Properties and Consequences of the Axioms\n\nAbsolute Value: The absolute value of x, denoted \\(|x|\\), is its distance from zero. Its most important property is the Triangle Inequality: \\(|x + y| \\le |x| + |y|\\).\nArchimedean Property: A consequence of completeness, this states that for any real number x, there exists a natural number n such that \\(n &gt; x\\).\nDensity: Both the rational numbers (\\(\\mathbb{Q}\\)) and the irrational numbers are dense in the real number line, meaning between any two real numbers, you can always find one of each.\n\n\n\n\n1.4 Sizing Infinity: Cardinality and the Continuum\n\n1.4.1 Countable vs. Uncountable Sets\n\nCountable Set: An infinite set that can be put into a one-to-one correspondence with the natural numbers (\\(\\mathbb{N}\\)). The rational numbers (\\(\\mathbb{Q}\\)) are a key example of a countable set.\nUncountable Set: An infinite set that is too large to be put into a one-to-one correspondence with \\(\\mathbb{N}\\).\n\n\n\n1.4.2 The Continuum\nThe set of real numbers (\\(\\mathbb{R}\\)) is uncountable, a fact proven by Cantor’s diagonalization argument. An infinite set that has the same cardinality (size) as the real numbers is said to have the cardinality of the continuum. This reveals that there are different, distinct sizes of infinity.\n\n\n\n1.5 Introduction to Complex Numbers\nA complex number extends the real number system by introducing the imaginary unit, \\(i\\), defined by \\(i^2 = -1\\). \\[ z = a + bi \\]\n\n\\(a\\) is the real part and \\(b\\) is the imaginary part.\nComplex numbers are visualized on a two-dimensional complex plane (or Argand plane).\n\n\n\n1.5.1 Geometric Properties\n\nModulus (\\(|z|\\)): The distance from the origin to the point \\((a, b)\\). Calculated as \\(|z| = \\sqrt{a^2 + b^2}\\).\nArgument (\\(\\theta\\)): The angle the line from the origin to \\((a, b)\\) makes with the positive real axis.\nThe equation \\(|z - c| = r\\) represents a circle of radius r centered at the complex number c. This leads to several important geometric sets:\n\n\\(|z - c| \\le r\\) describes a closed disk (the circle and its interior).\n\\(|z - c| &lt; r\\) describes an open disk (the interior of the circle only).\n\\(|z - c| \\ge r\\) describes the exterior of a disk, including its boundary.\n\n\n\n\n1.5.2 Trigonometric and Exponential Forms\nUsing the modulus r and argument \\(\\theta\\), a complex number can be expressed in two other crucial forms:\n\nTrigonometric Form: \\(z = r(\\cos\\theta + i\\sin\\theta)\\)\nExponential (Polar) Form: Using Euler’s Formula, \\(e^{i\\theta} = \\cos\\theta + i\\sin\\theta\\), we get the compact form \\(z = re^{i\\theta}\\).\n\n\n\n\n1.6 De Moivre’s Theorem\nThis theorem provides a straightforward way to calculate powers and roots of complex numbers.\n\nPowers: For any integer n, the n-th power of a complex number is: \\[ z^n = r^n(\\cos(n\\theta) + i\\sin(n\\theta)) \\]\nRoots: A complex number has exactly n distinct n-th roots, given by: \\[ \\sqrt[n]{z} = \\sqrt[n]{r} \\left( \\cos\\left(\\frac{\\theta + 2k\\pi}{n}\\right) + i\\sin\\left(\\frac{\\theta + 2k\\pi}{n}\\right) \\right) \\] for \\(k = 0, 1, 2, \\dots, n-1\\).\n\n\n\n1.7 The Principle of Mathematical Induction\n\n1.7.1 A Tool for Deductive Proof\nMathematical induction is a rigorous proof technique used to establish that a statement holds for all natural numbers. It is a deductive method and should not be confused with inductive reasoning (generalizing from patterns).\n\n\n1.7.2 The Domino Effect: Base Case and Inductive Step\nA proof by induction requires two parts:\n\nBase Case: Prove the statement is true for the first value (e.g., \\(n=1\\)).\nInductive Step: Assume the statement is true for an arbitrary integer \\(k\\) (the Inductive Hypothesis), and use this assumption to prove the statement is also true for \\(k+1\\).\n\n\n\n\n1.7.3 A Cautionary Tale: Moser’s Circle Problem\nThe danger of relying on patterns is shown by Moser’s circle problem. If you place n points on a circle and connect them, the number of regions appears to be \\(2^{n-1}\\) for \\(n=1, ..., 5\\). However, this pattern fails at \\(n=6\\). This illustrates why a rigorous proof like induction is essential.\n\n\n\n\n2. Definitions\n\nSet: A well-defined collection of distinct objects.\nSubset: A set A is a subset of B if all elements of A are also elements of B.\nCountable Set: An infinite set whose elements can be put into a one-to-one correspondence with the natural numbers.\nUncountable Set: An infinite set that is not countable (e.g., the real numbers).\nContinuum: The cardinality (size) of the set of real numbers.\nSupremum (sup): The least upper bound of a set of real numbers.\nInfimum (inf): The greatest lower bound of a set of real numbers.\nComplex Number: A number of the form \\(a + bi\\), where \\(a, b \\in \\mathbb{R}\\) and \\(i = \\sqrt{-1}\\).\nComplex Plane: A two-dimensional plane for representing complex numbers.\nModulus (\\(|z|\\)): The magnitude of a complex number; its distance from the origin.\nArgument (\\(\\theta\\)): The angle of a complex number’s vector on the complex plane.\nEuler’s Formula: The identity \\(e^{i\\theta} = \\cos\\theta + i\\sin\\theta\\).\nDe Moivre’s Theorem: A formula for computing powers and roots of complex numbers.\nMathematical Induction: A proof technique used to establish the truth of a statement for all natural numbers.\n\n\n\n3. Formulas\n\nDe Morgan’s Laws: \\((A \\cup B)^c = A^c \\cap B^c\\) and \\((A \\cap B)^c = A^c \\cup B^c\\)\nTriangle Inequality: \\(|x + y| \\le |x| + |y|\\)\nBernoulli’s Inequality: For \\(x &gt; -1\\) and integer \\(n \\ge 1\\), \\((1+x)^n \\ge 1+nx\\).\nModulus of a Complex Number: \\(|z| = \\sqrt{a^2 + b^2}\\)\nTrigonometric Form: \\(z = r(\\cos\\theta + i\\sin\\theta)\\)\nEuler’s Formula: \\(e^{i\\theta} = \\cos\\theta + i\\sin\\theta\\)\nExponential (Polar) Form: \\(z = re^{i\\theta}\\)\nDe Moivre’s Theorem (Powers): \\(z^n = r^n(\\cos(n\\theta) + i\\sin(n\\theta))\\)\nDe Moivre’s Theorem (Roots): \\(\\sqrt[n]{z} = \\sqrt[n]{r} \\left( \\cos\\left(\\frac{\\theta + 2k\\pi}{n}\\right) + i\\sin\\left(\\frac{\\theta + 2k\\pi}{n}\\right) \\right)\\) for \\(k = 0, \\dots, n-1\\)\n\n\n\n4. Mistakes\n\nConfusing Inductive Reasoning with Mathematical Induction: Observing a pattern for a few cases (e.g., Moser’s circle problem) and concluding it holds for all cases. Why it’s wrong: Patterns can break. Mathematical induction is a rigorous proof that establishes a logical link between successive cases.\nApplying Familiar Rules Blindly: Manipulating infinite series as if they were finite sums or cancelling terms without checking for division by zero. Why it’s wrong: The rules of finite arithmetic do not always apply to infinite processes and require rigorous justification from analysis.\nForgetting the Quadrant for the Argument: Using \\(\\theta = \\tan^{-1}(b/a)\\) without checking the signs of a and b. Why it’s wrong: The arctan function has a limited range. You must adjust the angle to place it in the correct quadrant, otherwise all subsequent calculations will be incorrect.\nFinding Only One n-th Root: When asked for the roots of a complex number, only calculating the principal root (for \\(k=0\\)). Why it’s wrong: A complex number has exactly n distinct n-th roots. You must iterate through \\(k = 0, 1, \\dots, n-1\\).\nSkipping the Base Case in Induction: Starting an induction proof with the inductive hypothesis without first proving the statement is true for the initial value. Why it’s wrong: The entire logical chain depends on the first “domino” falling. Without a valid base case, the proof is meaningless.\nAssuming P(k+1) is True in the Inductive Step: Starting the inductive step by writing down the statement for \\(k+1\\). Why it’s wrong: This is circular reasoning. The correct method is to start with the assumption for k and logically derive the statement for \\(k+1\\).\n\n\n\n5. Examples\n\n5.1. Irrationality Proof\nQuestion: Prove that \\(\\sqrt{2}\\) is an irrational number.\n\n\nClick to see the solution\n\n\nAssume the opposite: Assume \\(\\sqrt{2}\\) is rational, so \\(\\sqrt{2} = p/q\\) where \\(p, q\\) are integers with no common factors.\nSquare both sides: \\(2 = p^2/q^2 \\implies p^2 = 2q^2\\).\nDeduce properties of p: \\(p^2\\) is even, so p must be even. Let \\(p = 2k\\).\nSubstitute and deduce properties of q: \\((2k)^2 = 2q^2 \\implies 4k^2 = 2q^2 \\implies q^2 = 2k^2\\). So \\(q^2\\) is even, which means q is even.\nContradiction: Both p and q are even, contradicting that they have no common factors. Answer: Therefore, \\(\\sqrt{2}\\) is irrational.\n\n\n\n\n5.2. Finding Supremum and Infimum\nQuestion: Find the supremum and infimum of the set \\(E = \\{ \\frac{1}{n} : n \\in \\mathbb{N} \\}\\).\n\n\nClick to see the solution\n\n\nList elements: The set is \\(\\{1, \\frac{1}{2}, \\frac{1}{3}, ...\\}\\).\nFind bounds: The largest element is 1. As n grows, the elements approach 0 but never reach it.\nIdentify sup and inf: The least upper bound is 1. The greatest lower bound is 0.\nCheck for max/min: The supremum (1) is in the set, so it is a maximum. The infimum (0) is not in the set, so there is no minimum. Answer: \\(\\sup(E) = 1\\), \\(\\inf(E) = 0\\).\n\n\n\n\n5.3. Complex Number Division\nQuestion: Find the values of \\(P\\) and \\(Q\\) if \\(P+Qi = \\frac{3-i}{1+i}\\).\n\n\nClick to see the solution\n\n\nMultiply by the complex conjugate of the denominator, which is \\(1-i\\). \\[ \\frac{3-i}{1+i} \\times \\frac{1-i}{1-i} = \\frac{3 - 3i - i + i^2}{1^2 - i^2} \\]\nSimplify: \\[ \\frac{3 - 4i - 1}{1 - (-1)} = \\frac{2 - 4i}{2} = 1 - 2i \\]\nIdentify P and Q: Comparing \\(1-2i\\) with \\(P+Qi\\), we find \\(P=1\\) and \\(Q=-2\\). Answer: \\(P=1\\), \\(Q=-2\\).\n\n\n\n\n5.4. Powers of Complex Numbers\nQuestion: Compute \\((1 - i)^{8}\\) using De Moivre’s Theorem.\n\n\nClick to see the solution\n\n\nConvert to trigonometric form: For \\(z = 1-i\\), the modulus is \\(r = \\sqrt{1^2 + (-1)^2} = \\sqrt{2}\\). The argument is \\(\\theta = 7\\pi/4\\) (or \\(-\\pi/4\\)). So \\(z = \\sqrt{2}(\\cos(7\\pi/4) + i\\sin(7\\pi/4))\\).\nApply De Moivre’s Theorem with \\(n=8\\): \\[ z^8 = (\\sqrt{2})^8 \\left( \\cos\\left(8 \\cdot \\frac{7\\pi}{4}\\right) + i\\sin\\left(8 \\cdot \\frac{7\\pi}{4}\\right) \\right) \\]\nSimplify: \\[ z^8 = 16 ( \\cos(14\\pi) + i\\sin(14\\pi) ) = 16(1 + i \\cdot 0) = 16 \\] Answer: 16.\n\n\n\n\n5.5. Roots of Complex Numbers\nQuestion: Find the three cube roots of \\(z = -8i\\).\n\n\nClick to see the solution\n\n\nConvert to trigonometric form: For \\(z=-8i\\), \\(r=8\\) and \\(\\theta=3\\pi/2\\).\nApply the n-th root formula with \\(n=3\\), \\(k=0, 1, 2\\): \\[ w_k = \\sqrt[3]{8} \\left( \\cos\\left(\\frac{3\\pi/2 + 2k\\pi}{3}\\right) + i\\sin\\left(\\frac{3\\pi/2 + 2k\\pi}{3}\\right) \\right) \\]\nCalculate for \\(k=0\\): \\(w_0 = 2(\\cos(\\pi/2) + i\\sin(\\pi/2)) = 2i\\).\nCalculate for \\(k=1\\): \\(w_1 = 2(\\cos(7\\pi/6) + i\\sin(7\\pi/6)) = -\\sqrt{3} - i\\).\nCalculate for \\(k=2\\): \\(w_2 = 2(\\cos(11\\pi/6) + i\\sin(11\\pi/6)) = \\sqrt{3} - i\\). Answer: The three cube roots are \\(2i\\), \\(-\\sqrt{3} - i\\), and \\(\\sqrt{3} - i\\).\n\n\n\n\n5.6. Geometric Set Description\nQuestion: Describe the set of points in the complex plane satisfying \\(1 \\le |z + 2| &lt; 3\\).\n\n\nClick to see the solution\n\n\nInterpret the expression: \\(|z+2|\\) is \\(|z - (-2)|\\), the distance from \\(z\\) to the point \\(-2\\).\nInterpret the inequalities: The distance must be greater than or equal to 1, and less than 3.\nCombine: This describes an annulus (a ring) centered at \\(-2\\), with an inner radius of 1 (inclusive) and an outer radius of 3 (exclusive). Answer: The set is an annulus centered at \\(-2+0i\\), including the inner circle of radius 1 and excluding the outer circle of radius 3.\n\n\n\n\n5.7. Induction with Divisibility\nQuestion: Prove that \\(4^n - 1\\) is divisible by 3 for all integers \\(n \\ge 1\\).\n\n\nClick to see the solution\n\n\nBase Case (\\(n=1\\)): \\(4^1 - 1 = 3\\), which is divisible by 3. True.\nInductive Hypothesis: Assume for some integer \\(k \\ge 1\\), \\(4^k - 1 = 3m\\) for some integer \\(m\\).\nInductive Step: We must prove \\(4^{k+1} - 1\\) is divisible by 3. \\[ 4^{k+1} - 1 = 4 \\cdot 4^k - 1 \\] From the hypothesis, \\(4^k = 3m + 1\\). Substitute this in. \\[ 4(3m + 1) - 1 = 12m + 4 - 1 = 12m + 3 = 3(4m + 1) \\] This is a multiple of 3. Answer: By the principle of mathematical induction, the statement is true for all integers \\(n \\ge 1\\).",
    "crumbs": [
      "Mathematical Analysis I",
      "1. Real Analysis, Complex Numbers"
    ]
  },
  {
    "objectID": "Computer Architecture/lec_1.html",
    "href": "Computer Architecture/lec_1.html",
    "title": "1. Computer Architecture, CPU Principles, Memory Hierarchy, FPGA Boards",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 What is a Computer?\nA computer is an electronic machine designed to automatically execute a sequence of arithmetic or logical operations based on a given program. It processes input data and produces an output result. Fundamentally, computers operate on binary data—strings of zeros and ones—manipulating this input to generate a binary output according to a predefined sequence of instructions.\n\n\n\n1.2 The Problem Solution Stack\nSolving a problem with a computer involves multiple layers of abstraction, from the physical world to the software application. This is often visualized as a stack.\n\nProblem to Solve: The high-level goal.\nAlgorithm + Data Structures: The conceptual solution.\nUser Program: The implementation in a high-level language (e.g., C++, Python).\nSystem Programs: The operating system and compilers that translate the user program into machine instructions.\nProcessor Instruction Set Architecture (ISA): The specific set of low-level instructions the hardware can execute. This is the interface between hardware and software.\nMicroarchitecture: The specific implementation of the ISA in hardware (e.g., how the CPU components are arranged and connected).\nLogic Circuits: The fundamental building blocks, like AND and OR gates, that implement the microarchitecture.\nElectrons, Photons, etc.: The underlying physics that makes the circuits work.\n\nComputer architecture is the study of the layers from the Instruction Set Architecture down to the logic circuits, including how they interact with system software.\n\n\n1.3 What is Computer Architecture?\nComputer Architecture is a field of computer science and engineering that covers three main areas:\n\nHardware organization of computer systems: How components like the CPU, memory, and I/O devices are structured and interconnected.\nHardware/Software interaction principles: The rules and methods by which software controls the hardware, primarily through the instruction set.\nPerformance-related computer aspects: Analyzing and designing systems to optimize for speed, power efficiency, and cost.\n\nStudying architecture helps us understand how to design efficient hardware, write high-performance software, and customize computing systems for specific tasks.\n\n\n1.4 Core Components of a Computer\nA modern computer’s architecture is built around several key interacting components.\n\n1.4.1 CPU (Central Processing Unit)\nThe “brain” of the computer, the CPU executes program instructions. It is a complex electrical circuit with several key parts:\n\nControl Unit (CU): Fetches instructions from memory, decodes them, and directs the other components to carry them out.\nArithmetic-Logic Unit (ALU): Performs all arithmetic (e.g., addition, subtraction) and logical (e.g., AND, OR) operations.\nRegisters: A small number of extremely fast memory locations located directly within the CPU. They hold data that is being actively processed, such as the arguments for an ALU operation or its result.\n\n\n\n\n1.4.2 The Processor Principle\nA processor operates by receiving electrical signals on its input pins and producing a result on its output pins. The inputs consist of:\n\nInstruction Code: A binary code that tells the processor which operation to perform (e.g., 0 for logical OR, 1 for logical AND).\nInput Arguments: The data values on which the operation will be performed.\n\nThe combination of the instruction code and its arguments forms a machine instruction (e.g., the binary string 010 could mean “OR the values 1 and 0”).\n\n\n1.4.3 System Memory (RAM)\nRandom Access Memory is the computer’s main workspace. It stores program instructions and data for the CPU to access quickly. RAM is volatile, meaning its contents are lost when power is cut.\n\n\n1.4.4 Storage Devices:\nThese provide long-term, non-volatile storage for the operating system, applications, and files. Examples include Solid-State Drives (SSDs) and hard disk drives (HDDs). Data is loaded from storage into RAM for execution.\n\n\n1.4.5 Input/Output (I/O) Devices\nPeripherals that allow the computer to interact with the world, such as keyboards, monitors, printers, and network interfaces.\n\n\n1.4.6 Communication Bus\nThe set of electrical pathways connecting all components, allowing them to communicate and exchange data. Bus speed is a critical factor in system performance. Significant delays in data transfer between the CPU and memory lead to the “memory wall problem,” a key performance limitation in modern computers.\n\n\n1.5 The Memory Hierarchy\nTo balance speed, cost, and capacity, computers organize memory in a hierarchy. Data is moved between levels based on how frequently the CPU needs it.\n\nRegisters (inside the CPU): Fastest access (&lt;1 nanosecond), smallest capacity (hundreds of bytes).\nCPU Cache (L1, L2, L3): Very fast memory on or near the CPU. It stores copies of frequently used data from RAM.\n\nL1 Cache: Embedded in each CPU core, fastest cache, smallest capacity (tens of kilobytes).\nL2 Cache: Slower but larger than L1.\nL3 Cache (LLC - Last Level Cache): Shared among all CPU cores, slowest and largest cache (megabytes).\n\nSystem Memory (RAM): Much larger capacity (gigabytes) but significantly slower than cache.\nStorage Devices (SSD/HDD): Largest capacity (terabytes) but the slowest access speeds.\n\n\n\n\n1.6 CPU Architectures and Multicore Systems\nA CPU’s design is defined by its Instruction Set Architecture (ISA).\n\n1.6.1 Widely-known Architectures\n\nIntel x86 / AMD64: Dominant in desktop and server computers (CISC - Complex Instruction Set Computer).\nARM: Dominant in mobile and embedded devices (RISC - Reduced Instruction Set Computer).\nRISC-V: A modern, open-standard RISC architecture gaining popularity.\nOthers include Baikal and Elbrus.\n\n\n\n1.6.2 Multicore Systems\nModern CPUs are multicore processors, meaning a single chip contains multiple independent processing units (cores). Each core has its own ALU, CU, and L1 cache, while typically sharing an L3 cache and main memory. This allows for parallel execution of tasks but introduces challenges in coordinating, or scheduling, work across the cores.\n\n\n\n1.7 Processors vs. FPGAs\nA standard CPU is a general-purpose processor with a fixed, unchangeable hardware design. An FPGA (Field-Programmable Gate Array) is an integrated circuit containing a grid of configurable logic blocks that can be reprogrammed by the user after manufacturing.\n\n1.7.1 Key Differences\n\nProgrammability: A CPU’s hardware is fixed; it executes software. An FPGA’s hardware itself is reconfigured to create a custom circuit.\nInstruction Set: A CPU has a fixed instruction set defined by its manufacturer. An FPGA has no inherent instruction set; you design the digital logic circuits directly.\nComputation Speed: For general tasks, CPUs are optimized and efficient. For highly specific, parallelizable tasks, an FPGA’s custom hardware can be much faster.\nPower Consumption: FPGAs typically consume more power than a CPU for the same task due to their programmable nature.\nCost: FPGAs are generally more expensive than mass-produced CPUs.\n\n\n\n1.7.2 Use Cases for FPGAs\nFPGAs are used for prototyping new processor designs, high-frequency trading, real-time signal processing, and other tasks requiring massive parallelism and low latency.\n\n\n\n1.8 FPGA Programming and Development Boards\nFPGAs are programmed using a Hardware Description Language (HDL) like Verilog or VHDL. These languages describe the structure of hardware circuits rather than a sequence of software instructions. A tool like Intel Quartus Prime Lite is used to synthesize the HDL code into a configuration file that is then loaded onto the FPGA.\nEducational boards like the DE10-Lite MAX 10 include an FPGA chip along with various I/O devices for hands-on learning, such as:\n\nLEDs and Switches\nPush Buttons\n7-Segment Displays\nVGA Output\nAccelerometer (G-Sensor)\nGPIO (General-Purpose Input/Output) pins\n\n\n\n1.9 Course Structure and Grading\nThis course is structured with weekly lectures and corresponding lab assignments.\n\nLabs Planning:\n\nWeeks 1-5: FPGA programming with block diagrams and Verilog HDL using Quartus Prime Lite.\nWeeks 6-9: Designing a custom CPU in Verilog, simulated with ModelSim.\nWeeks 10-14: Low-level programming in assembly language.\n\nGrading Policy:\n\nRegular Quizzes: 5%\nLab Assignments: 15%\nMidterm Exam: 20%\nFinal Exam: 60%\nOptional FPGA Project: At most 3% extra points.\n\n\n\n\n\n2. Definitions\n\nComputer: An electronic device that processes data by executing a sequence of instructions defined in a program.\nComputer Architecture: The design and operational structure of a computer system, defining its hardware components, their interconnections, and the hardware-software interface (the instruction set).\nCPU (Central Processing Unit): The component of a computer that executes program instructions and performs arithmetic, logic, and control operations.\nALU (Arithmetic-Logic Unit): A digital circuit within the CPU that performs arithmetic and bitwise logic operations.\nCU (Control Unit): The component of the CPU that directs the processor by interpreting instructions and generating control signals.\nRegister: A small, high-speed storage location directly within the CPU.\nInstruction Set Architecture (ISA): The specific set of commands that a CPU can execute, acting as the interface between the hardware and the software.\nSystem Memory (RAM): Volatile memory that stores data and machine code currently in use.\nCPU Cache: A small, fast volatile memory that stores copies of frequently used data from main memory to reduce access times.\nMemory Hierarchy: A tiered structure of memory and storage devices that balances speed, cost, and capacity.\nFPGA (Field-Programmable Gate Array): An integrated circuit with configurable logic blocks and programmable interconnects that can be rewired by the user after manufacturing.\nVerilog HDL: A hardware description language (HDL) used to model and design digital electronic systems.\nMulticore Processor: A single CPU chip that contains two or more independent processing units called “cores.”\n\n\n\n3. Mistakes\n\nConfusing an FPGA with a CPU: Treating an FPGA as just a “faster CPU.” Why it’s wrong: They are fundamentally different. A CPU is a fixed processor that runs software instructions, while an FPGA is a blank slate of configurable hardware. An FPGA is only faster for tasks that can be efficiently implemented in custom, parallel hardware.\nIgnoring the Memory Hierarchy: Writing code without considering how data moves between CPU cache and main memory. Why it’s wrong: The “memory wall”—the large speed gap between the CPU and RAM—is a primary performance bottleneck. Programs that access memory without locality will perform poorly as the CPU constantly stalls waiting for data.\nTreating Verilog like a software programming language: Writing Verilog code sequentially and expecting it to execute line by line. Why it’s wrong: Verilog is a hardware description language. It describes physical circuits that operate in parallel. This misunderstanding leads to designs that don’t synthesize into working hardware or behave unexpectedly.\nBelieving a processor’s functionality can be changed with software: Thinking you can add new hardware-level instructions to a CPU through a software update. Why it’s wrong: A CPU’s instruction set is physically etched into its silicon circuits during manufacturing and cannot be altered.\nUnderestimating the Communication Bus: Focusing only on CPU speed while ignoring the performance of the bus connecting the CPU to RAM. Why it’s wrong: A slow bus will starve a fast CPU of data, creating a massive bottleneck. The entire system’s performance depends on the ability of the bus to transfer data efficiently.\n\n\n\n4. Examples\n\n4.1 Simple Logic in Verilog\nQuestion: Write a Verilog module that implements a simple AND gate. It should take two single-bit inputs, a and b, and produce one single-bit output, y.\n\n\nClick to see the solution\n\n\nDefine the module: Start by declaring a module with a name (e.g., simple_and) and list its input and output ports. verilog     module simple_and(         input  logic a,         input  logic b,         output logic y     );\nAssign the logic: Use a continuous assign statement to describe the relationship between the inputs and the output. The & operator performs a bitwise AND operation. verilog     assign y = a & b;\nEnd the module: Close the module definition. verilog     endmodule\n\nAnswer: The complete Verilog module is:\nmodule simple_and(\n    input  logic a,\n    input  logic b,\n    output logic y\n);\n\nassign y = a & b;\n\nendmodule\n\n\n\n4.2 Controlling an LED with a Switch\nQuestion: On an FPGA board like the DE10-Lite, you have a switch (SW0) and an LED (LED0). Write a Verilog module to make the LED turn on when the switch is on, and turn off when the switch is off.\n\n\nClick to see the solution\n\n\nDefine the module and ports: Create a module named led_control with one input for the switch and one output for the LED. verilog     module led_control(         input  logic SW0,         output logic LED0     );\nConnect the switch to the LED: The simplest way to achieve this is to directly connect the input to the output. An assign statement creates a “wire” between the two. verilog     assign LED0 = SW0;\nEnd the module: Close the module definition. verilog     endmodule Answer: The Verilog module directly connects the switch’s state to the LED’s state:\n\nmodule led_control(\n    input  logic SW0,\n    output logic LED0\n);\n\nassign LED0 = SW0;\n\nendmodule\n\n\n\n4.3 CPU vs. FPGA Application Choice\nQuestion: You are designing a system for real-time video encoding that needs to process 4K video at 60 frames per second with very low latency. Would a general-purpose CPU or an FPGA be a better choice for the core processing unit? Explain why.\n\n\nClick to see the solution\n\n\nAnalyze the task requirements: The task involves processing a massive, continuous stream of data (4K video) with strict timing constraints (60 fps, low latency). The operations are highly repetitive and can be broken down into many small, parallel steps.\nEvaluate the CPU’s suitability: A CPU would process the video frames using software. While powerful, it executes instructions sequentially (even with multiple cores) and has overhead from the operating system. Achieving consistent low latency for every single frame would be extremely challenging.\nEvaluate the FPGA’s suitability: An FPGA can be configured to have a dedicated hardware pipeline for video processing. Multiple stages of the encoding algorithm can run simultaneously on different parts of the chip. This massive parallelism is ideal for video streams and guarantees consistent, low-latency processing. Answer: An FPGA is the better choice. Why: Video encoding is a highly parallel task. An FPGA allows for the creation of a custom hardware pipeline where many calculations happen simultaneously, which is far more efficient and provides the low, predictable latency required for real-time processing, something a general-purpose CPU struggling with OS and other overheads cannot guarantee.\n\n\n\n\n4.4 Memory Hierarchy Access\nQuestion: A program is executing a for loop that repeatedly adds two numbers. The machine code instruction for the addition operation is currently being executed by the CPU. In which level of the memory hierarchy would you most likely find this instruction?\n\n\nClick to see the solution\n\n\nConsider the CPU’s immediate needs: The CPU can only execute instructions that are physically inside it.\nRecall the fastest memory level: The fastest and closest memory to the ALU and CU are the registers. The Control Unit fetches instructions from memory into a special-purpose register (often called the Instruction Register) just before decoding and execution.\nConsider the role of cache: Since the instruction is part of a loop, it’s being used repeatedly. Therefore, it is almost certain to have been copied from the slower main memory (RAM) into the much faster L1 instruction cache for quick access on subsequent loop iterations.\nCombine the points: The instruction must be in a register to be executed. Given it’s in a loop, it would also reside in the L1 cache to avoid fetching it from slow RAM every time. The most immediate location is a register. Answer: The instruction would be found in a CPU register (specifically, the instruction register) at the moment of execution. A copy of it would also reside in the L1 cache for fast re-access during the next iteration of the loop.\n\n\n\n\n4.5 2-to-1 Multiplexer in Verilog\nQuestion: A 2-to-1 multiplexer (MUX) is a circuit that selects one of two inputs (a or b) to pass to the output (y) based on a selector signal (sel). If sel is 0, y should be a. If sel is 1, y should be b. Implement this in a Verilog module.\n\n\nClick to see the solution\n\n\nDefine the module and its ports: The module requires three inputs (a, b, sel) and one output (y). verilog     module mux_2_to_1(         input  logic a,         input  logic b,         input  logic sel,         output logic y     );\nImplement the selection logic: A conditional assign statement using the ternary operator (? :) is a concise way to model this. The structure is condition ? value_if_true : value_if_false. verilog     assign y = (sel == 1) ? b : a; This line reads as: “Assign y the value of b if sel is 1; otherwise, assign it the value of a.”\nEnd the module: Close the module definition. verilog     endmodule Answer: The complete Verilog module for a 2-to-1 MUX is:\n\nmodule mux_2_to_1(\n    input  logic a,\n    input  logic b,\n    input  logic sel,\n    output logic y\n);\n\nassign y = sel ? b : a; // A more compact way of writing (sel == 1)\n\nendmodule\n\n\n\n4.6 Processor Instruction Set Limitation\nQuestion: Imagine a very simple processor whose instruction set only contains ADD, SUBTRACT, and STORE. You need to perform a multiplication, for example, 5 * 3. How could you accomplish this using only the available instructions?\n\n\nClick to see the solution\n\n\nUnderstand the core concept of multiplication: Multiplication is repeated addition. For example, 5 * 3 is the same as 5 + 5 + 5.\nFormulate an algorithm using available instructions:\n\nInitialize a result variable (in a register, let’s call it R1) to 0.\nUse the ADD instruction to add 5 to R1.\nUse the ADD instruction again to add 5 to R1. R1 now holds 10.\nUse the ADD instruction a third time to add 5 to R1. R1 now holds 15.\nUse the STORE instruction to save the value from R1 to a memory location.\n\nStructure the process: This would be implemented as a software loop. The program would use the ADD instruction three times. Answer: You can perform multiplication by implementing it as a series of additions. To calculate 5 * 3, you would write a short program that uses a loop to execute the ADD 5 instruction three times, accumulating the result in a register.\n\n\n\n\n4.7 Identifying FPGA Board Components\nQuestion: You are looking at a DE10-Lite FPGA board. You see a large, square chip in the center labeled “MAX 10”. What is the function of this component?\n\n\nClick to see the solution\n\n\nAnalyze the component’s description: The chip is large, centrally located, and has a specific model name (“MAX 10”).\nRecall the purpose of an FPGA board: The primary purpose of an FPGA development board is to provide a platform for programming and testing an FPGA.\nConnect the information: The central, most prominent chip on an FPGA board is almost always the FPGA itself. The “MAX 10” is a product family of FPGAs made by Altera (now Intel). Answer: The chip labeled “MAX 10” is the FPGA (Field-Programmable Gate Array) itself. It is the main component that you program with your hardware design using a language like Verilog.",
    "crumbs": [
      "Computer Architecture",
      "1. Computer Architecture, CPU Principles, Memory Hierarchy, FPGA Boards"
    ]
  },
  {
    "objectID": "Discrete Mathematics/lec_1.html",
    "href": "Discrete Mathematics/lec_1.html",
    "title": "1. Truth Tables, Normal Forms (DNF, CNF)",
    "section": "",
    "text": "1. Summary\n\n1.1 Propositions and Logical Values\nIn logic, a proposition is a statement that can be definitively determined as either True or False, but not both. It is the fundamental building block of logical expressions. For example, “The sky is blue” is a proposition. “What time is it?” is not, because it’s a question and cannot be assigned a truth value. In discrete mathematics and computing, we represent these values numerically:\n\nTrue is represented by 1.\nFalse is represented by 0.\n\n\n\n1.2 Logical Operators\nLogical operators are symbols used to connect propositions and form more complex logical expressions. Each operator has a specific rule for determining the truth value of the expression it forms.\n\n1.2.1 Negation (NOT) The Negation operator, denoted by ¬ (e.g., ¬P), inverts the truth value of a proposition. If P is true, ¬P is false. If P is false, ¬P is true. It corresponds to the word “not”.\n1.2.2 Conjunction (AND) The Conjunction operator, denoted by & or ∧ (e.g., P ∧ Q), connects two propositions. The result is True only if both propositions are true. If either or both are false, the result is false. It corresponds to the word “and”.\n1.2.3 Disjunction (OR) The Disjunction operator, denoted by ∨ (e.g., P ∨ Q), connects two propositions. The result is True if at least one of the propositions is true. It is only false when both propositions are false. This is also known as an inclusive OR.\n1.2.4 Implication (IF…THEN) The Implication operator, denoted by → (e.g., P → Q), represents a conditional statement. It is read as “if P, then Q”. The expression P → Q is only False when P is true and Q is false. In all other cases, it is true. This can seem counter-intuitive. Think of it as a promise: “If I pass the exam (P), then I will celebrate (Q)”. The only way the promise is broken is if I pass the exam but do not celebrate. If I don’t pass the exam, the promise is not broken, regardless of whether I celebrate or not.\n1.2.5 Equivalence (IF AND ONLY IF) The Equivalence operator, denoted by ↔︎ (e.g., P ↔︎ Q), is also known as a biconditional. The result is True only when both propositions have the same truth value (both true or both false).\n\n\n\n1.3 Truth Tables\nA truth table is a tool used to systematically determine the truth value of a complex logical formula for every possible combination of truth values of its component propositions.\n\nConstruction: To build a truth table for a formula with n distinct propositional variables, you need \\(2^n\\) rows to cover all possible scenarios.\nStructure: The initial columns list all combinations of truth values for the variables. Subsequent columns break down the complex formula into smaller parts, building up to the final result in the last column.\n\n\n\n\n1.4 Normal Forms\nA normal form in logic is a standardized way of writing a logical formula. Having a standard representation is useful for comparing formulas, simplifying them, and for automated processing in computer science. The two most common are Disjunctive Normal Form (DNF) and Conjunctive Normal Form (CNF).\n\n1.4.1 Disjunctive Normal Form (DNF) A formula is in Disjunctive Normal Form (DNF) if it is a disjunction (ORs) of conjuncts (ANDs of literals). A literal is a variable or its negation.\n\nStructure: \\((A \\land \\neg B) \\lor (C \\land D) \\lor (\\neg E)\\)\nIntuition: Think of DNF as describing the specific conditions that make the formula True. Each conjunct represents one “true” scenario. The entire formula is true if any one of these scenarios is met.\n\nAlgorithm to Find DNF from a Truth Table:\n\nIdentify all rows in the truth table where the final result is 1 (True).\nFor each of these rows, create a conjunct (an AND clause).\nWithin each conjunct, if a variable’s value in that row is 1, use the variable directly (e.g., A).\nIf a variable’s value is 0, use its negation (e.g., ¬A).\nConnect all the resulting conjuncts with the disjunction (∨) operator.\n\n1.4.2 Conjunctive Normal Form (CNF) A formula is in Conjunctive Normal Form (CNF) if it is a conjunction (ANDs) of disjuncts (ORs of literals).\n\nStructure: \\((A \\lor \\neg B) \\land (C \\lor D) \\land (\\neg E)\\)\nIntuition: Think of CNF as a set of rules or constraints, all of which must be satisfied for the formula to be true. The formula is made false if any single clause is false.\n\nAlgorithm to Find CNF from a Truth Table:\n\nIdentify all rows in the truth table where the final result is 0 (False).\nFor each of these rows, create a disjunct (an OR clause).\nWithin each disjunct, if a variable’s value in that row is 0, use the variable directly (e.g., A).\nIf a variable’s value is 1, use its negation (e.g., ¬A). (This is the opposite of the DNF rule).\nConnect all the resulting disjuncts with the conjunction (∧) operator.\n\n\n\n\n\n2. Definitions\n\nProposition: A declarative statement that is unambiguously either true or false.\nTruth Table: A table that displays the truth values of a logical formula for all possible combinations of truth values of its component variables.\nLiteral: A propositional variable (e.g., A) or its negation (e.g., ¬A).\nConjunct (Minterm): A conjunction (AND) of one or more literals. For example, A ∧ ¬B ∧ C.\nDisjunct (Maxterm): A disjunction (OR) of one or more literals. For example, A ∨ ¬B ∨ C.\nDisjunctive Normal Form (DNF): A logical formula written as a disjunction of conjuncts. It is an OR of ANDs.\nConjunctive Normal Form (CNF): A logical formula written as a conjunction of disjuncts. It is an AND of ORs.\n\n\n\n3. Formulas\n\nImplication Equivalence: The implication P → Q is logically equivalent to ¬P ∨ Q.\nBiconditional Equivalence: The equivalence P ↔︎ Q is logically equivalent to (P → Q) ∧ (Q → P), which further expands to (¬P ∨ Q) ∧ (P ∨ ¬Q).\nDe Morgan’s Laws:\n\n¬(P ∧ Q) ≡ ¬P ∨ ¬Q\n¬(P ∨ Q) ≡ ¬P ∧ ¬Q\n\nGeneral Formula for DNF: For a function \\(f(x_1, ..., x_n)\\): \\[ f = \\bigvee_{f(\\sigma_1, ..., \\sigma_n)=1} (x_1^{\\sigma_1} \\land ... \\land x_n^{\\sigma_n}) \\] Where \\(x^1\\) means \\(x\\) and \\(x^0\\) means \\(\\neg x\\).\nGeneral Formula for CNF: For a function \\(f(x_1, ..., x_n)\\): \\[ f = \\bigwedge_{f(\\sigma_1, ..., \\sigma_n)=0} (x_1^{\\overline{\\sigma_1}} \\lor ... \\lor x_n^{\\overline{\\sigma_n}}) \\] Where \\(x^{\\overline{1}}\\) means \\(\\neg x\\) and \\(x^{\\overline{0}}\\) means \\(x\\).\n\n\n\n4. Mistakes\n\nConfusing the Direction of Implication: Assuming that if P → Q is true, then Q → P must also be true. Why it’s wrong: “If it is raining, the ground is wet” is true. However, “If the ground is wet, it is raining” is not necessarily true (e.g., a sprinkler could be on). The implication is not symmetric.\nIncorrectly Negating Expressions: Writing ¬(A ∧ B) as ¬A ∧ ¬B. Why it’s wrong: This violates De Morgan’s laws. The correct negation is ¬A ∨ ¬B. The negation of “it is cold AND raining” is “it is NOT cold OR it is NOT raining”.\nMixing up DNF and CNF Creation Rules: Using the wrong rule for variables when constructing normal forms from a truth table. For example, using A for a 1 when building a CNF clause. Why it’s wrong: The rules are inverted. For CNF, you look at the 0 (false) rows, and a 1 in the input corresponds to a negated literal (¬A) in the clause.\nCreating Invalid Normal Form Structures: Writing a DNF with disjunctions (ORs) inside the conjuncts, such as (A ∨ B) ∧ C. Why it’s wrong: A DNF must be strictly an OR of ANDs. The term (A ∨ B) is not a valid conjunct.\nForgetting Rows in a Truth Table: Not listing all \\(2^n\\) possible combinations of inputs. Why it’s wrong: An incomplete truth table can lead to an incorrect analysis of the formula and incorrect DNF/CNF representations.\nMisinterpreting the P → Q case where P is False: Believing that if the premise P is false, the implication P → Q is also false. Why it’s wrong: In classical logic, an implication with a false premise is always considered true. This is known as the principle of “ex falso quodlibet” (from falsehood, anything follows).\n\n\n\n5. Examples\n\n5.1. Construct a Truth Table\nQuestion: Construct the full truth table for the expression (A ∨ B) → ¬A.\n\n\nClick to see the solution\n\n\nSet up columns: We need columns for the variables A and B, the intermediate expression A ∨ B, the negation ¬A, and the final expression (A ∨ B) → ¬A.\nList input combinations: For two variables, there are \\(2^2=4\\) combinations.\nEvaluate A ∨ B: This is true if A or B (or both) are true.\nEvaluate ¬A: This is the opposite of the value of A.\nEvaluate the final implication: The result is false only when the left side (A ∨ B) is true and the right side (¬A) is false.\n\n\n\n\nA\nB\nA ∨ B\n¬A\n(A ∨ B) → ¬A\n\n\n\n\n0\n0\n0\n1\n1\n\n\n0\n1\n1\n1\n1\n\n\n1\n0\n1\n0\n0\n\n\n1\n1\n1\n0\n0\n\n\n\nAnswer: The final truth values for the expression are (1, 1, 0, 0).\n\n\n\n5.2. Truth Table with Equivalence\nQuestion: Construct the truth table for (A → B) ↔︎ (¬B → ¬A).\n\n\nClick to see the solution\n\n\nSet up columns: We need columns for A, B, A → B, ¬B, ¬A, ¬B → ¬A, and the final expression.\nList input combinations: Four rows for variables A and B.\nEvaluate A → B: False only when A=1 and B=0.\nEvaluate negations: ¬A and ¬B.\nEvaluate ¬B → ¬A: False only when ¬B=1 and ¬A=0 (which means B=0 and A=1).\nEvaluate the final equivalence: The result is true when A → B and ¬B → ¬A have the same truth value.\n\n\n\n\nA\nB\nA → B\n¬B\n¬A\n¬B → ¬A\n(A → B) ↔︎ (¬B → ¬A)\n\n\n\n\n0\n0\n1\n1\n1\n1\n1\n\n\n0\n1\n1\n0\n1\n1\n1\n\n\n1\n0\n0\n1\n0\n0\n1\n\n\n1\n1\n1\n0\n0\n1\n1\n\n\n\nAnswer: The expression is a tautology; its truth values are (1, 1, 1, 1).\n\n\n\n5.3. Find DNF from a Truth Table\nQuestion: A function of two variables, T(x, y), has the truth table result (0, 1, 1, 0). Find its Disjunctive Normal Form (DNF). The input order is (0,0), (0,1), (1,0), (1,1).\n\n\nClick to see the solution\n\n\nIdentify the ‘True’ rows: The function T(x, y) is true (1) for the input combinations (x=0, y=1) and (x=1, y=0).\nCreate a conjunct for the first ‘True’ row (0, 1):\n\nx is 0, so we use ¬x.\ny is 1, so we use y.\nThe conjunct is (¬x ∧ y).\n\nCreate a conjunct for the second ‘True’ row (1, 0):\n\nx is 1, so we use x.\ny is 0, so we use ¬y.\nThe conjunct is (x ∧ ¬y).\n\nCombine the conjuncts with OR: Join the terms from steps 2 and 3 with ∨.\n\nAnswer: The DNF is (¬x ∧ y) ∨ (x ∧ ¬y). (This is the formula for XOR).\n\n\n\n5.4. Find CNF from a Truth Table\nQuestion: A function of two variables, T(x, y), has the truth table result (0, 1, 1, 0). Find its Conjunctive Normal Form (CNF).\n\n\nClick to see the solution\n\n\nIdentify the ‘False’ rows: The function T(x, y) is false (0) for the input combinations (x=0, y=0) and (x=1, y=1).\nCreate a disjunct for the first ‘False’ row (0, 0):\n\nx is 0, so we use x.\ny is 0, so we use y.\nThe disjunct is (x ∨ y).\n\nCreate a disjunct for the second ‘False’ row (1, 1):\n\nx is 1, so we use ¬x.\ny is 1, so we use ¬y.\nThe disjunct is (¬x ∨ ¬y).\n\nCombine the disjuncts with AND: Join the terms from steps 2 and 3 with ∧.\n\nAnswer: The CNF is (x ∨ y) ∧ (¬x ∨ ¬y).\n\n\n\n5.5. DNF and CNF for Three Variables\nQuestion: Find both the DNF and CNF for the function T(A, B, C) given by the result vector (0, 1, 0, 1, 1, 0, 1, 0).\n\n\nClick to see the solution\n\nPart 1: Disjunctive Normal Form (DNF)\n\nIdentify ‘True’ rows: The output is 1 for inputs: (0,0,1), (0,1,1), (1,0,0), and (1,1,0).\nCreate conjuncts for each ‘True’ row:\n\n(0,0,1) → (¬A ∧ ¬B ∧ C)\n(0,1,1) → (¬A ∧ B ∧ C)\n(1,0,0) → (A ∧ ¬B ∧ ¬C)\n(1,1,0) → (A ∧ B ∧ ¬C)\n\nCombine with OR: (¬A ∧ ¬B ∧ C) ∨ (¬A ∧ B ∧ C) ∨ (A ∧ ¬B ∧ ¬C) ∨ (A ∧ B ∧ ¬C)\n\nPart 2: Conjunctive Normal Form (CNF)\n\nIdentify ‘False’ rows: The output is 0 for inputs: (0,0,0), (0,1,0), (1,0,1), and (1,1,1).\nCreate disjuncts for each ‘False’ row:\n\n(0,0,0) → (A ∨ B ∨ C)\n(0,1,0) → (A ∨ ¬B ∨ C)\n(1,0,1) → (¬A ∨ B ∨ ¬C)\n(1,1,1) → (¬A ∨ ¬B ∨ ¬C)\n\nCombine with AND: (A ∨ B ∨ C) ∧ (A ∨ ¬B ∨ C) ∧ (¬A ∨ B ∨ ¬C) ∧ (¬A ∨ ¬B ∨ ¬C)\n\nAnswer: * DNF: (¬A ∧ ¬B ∧ C) ∨ (¬A ∧ B ∧ C) ∨ (A ∧ ¬B ∧ ¬C) ∨ (A ∧ B ∧ ¬C) * CNF: (A ∨ B ∨ C) ∧ (A ∨ ¬B ∨ C) ∧ (¬A ∨ B ∨ ¬C) ∧ (¬A ∨ ¬B ∨ ¬C)\n\n\n\n5.6. Convert Formula to DNF\nQuestion: Convert the formula P → (P ∧ Q) to its DNF by first creating its truth table.\n\n\nClick to see the solution\n\n\nCreate the truth table:\n\n\n\n\nP\nQ\nP ∧ Q\nP → (P ∧ Q)\n\n\n\n\n0\n0\n0\n1\n\n\n0\n1\n0\n1\n\n\n1\n0\n0\n0\n\n\n1\n1\n1\n1\n\n\n\n\nIdentify the ‘True’ rows: The final expression is true for inputs (0,0), (0,1), and (1,1).\nCreate conjuncts:\n\n(0,0) → (¬P ∧ ¬Q)\n(0,1) → (¬P ∧ Q)\n(1,1) → (P ∧ Q)\n\nCombine with OR: (¬P ∧ ¬Q) ∨ (¬P ∧ Q) ∨ (P ∧ Q)\n\nAnswer: The DNF is (¬P ∧ ¬Q) ∨ (¬P ∧ Q) ∨ (P ∧ Q).\n\n\n\n5.7. Convert Formula to CNF\nQuestion: Convert the formula P ↔︎ ¬Q to its CNF by first creating its truth table.\n\n\nClick to see the solution\n\n\nCreate the truth table:\n\n\n\n\nP\nQ\n¬Q\nP ↔︎ ¬Q\n\n\n\n\n0\n0\n1\n0\n\n\n0\n1\n0\n1\n\n\n1\n0\n1\n1\n\n\n1\n1\n0\n0\n\n\n\n\nIdentify the ‘False’ rows: The final expression is false for inputs (0,0) and (1,1).\nCreate disjuncts:\n\n(0,0) → (P ∨ Q)\n(1,1) → (¬P ∨ ¬Q)\n\nCombine with AND: (P ∨ Q) ∧ (¬P ∨ ¬Q)\n\nAnswer: The CNF is (P ∨ Q) ∧ (¬P ∨ ¬Q).",
    "crumbs": [
      "Discrete Mathematics",
      "1. Truth Tables, Normal Forms (DNF, CNF)"
    ]
  },
  {
    "objectID": "Discrete Mathematics/lec_2.html",
    "href": "Discrete Mathematics/lec_2.html",
    "title": "2. Logical Equivalence, Normal Forms (DNF, CNF, ANF)",
    "section": "",
    "text": "1. Summary\n\n1.1 Logical Formulas and Operators\nIn logic, a formula (or proposition) is a statement that can be definitively determined as either true or false. Simple formulas, often represented by variables like \\(p\\) or \\(q\\), can be combined using logical operators to form more complex formulas.\n\nNegation (\\(\\neg\\)): Reverses the truth value of a formula. \\(\\neg p\\) is read as “not p”. If \\(p\\) is true, \\(\\neg p\\) is false.\nConjunction (\\(\\land\\) or &): Represents logical “AND”. The formula \\(p \\land q\\) is true only if both \\(p\\) and \\(q\\) are true.\nDisjunction (\\(\\lor\\)): Represents logical “OR”. The formula \\(p \\lor q\\) is true if at least one of \\(p\\) or \\(q\\) is true. It is only false when both are false.\nImplication (\\(\\to\\)): Represents an “if-then” statement. \\(p \\to q\\) is read as “if p, then q”. It is only false when \\(p\\) is true and \\(q\\) is false. In all other cases, it is true.\nBi-implication (\\(\\leftrightarrow\\)): Represents “if and only if”. \\(p \\leftrightarrow q\\) is true only when \\(p\\) and \\(q\\) have the same truth value (both true or both false).\n\n\n\n1.2 Classification of Logical Formulas\nFormulas can be classified based on their truth values across all possible interpretations of their variables.\n\n\nTautology: A formula that is always true, regardless of the truth values of its constituent variables. For example, the formula \\(p \\lor \\neg p\\) is always true because a proposition must be either true or false.\nContradiction: A formula that is always false. For example, \\(p \\land \\neg p\\) is a contradiction because a proposition cannot be both true and false at the same time.\nContingency: A formula that is neither a tautology nor a contradiction. Its truth value depends on the truth values of its variables. For example, \\(p \\lor q\\) is a contingency because its truth depends on whether \\(p\\) or \\(q\\) is true.\nSatisfiability: A formula is considered satisfiable if there exists at least one assignment of truth values to its variables that makes the entire formula true. Tautologies and contingencies are satisfiable, while contradictions are not. The problem of determining if a formula is satisfiable is a famous problem in computer science known as the Boolean Satisfiability Problem (SAT), which the Cook-Levin theorem proved to be NP-complete.\n\n\n\n1.3 Logical Equivalence\nTwo formulas are logically equivalent if they have identical truth tables. This means that for every possible combination of truth values for their variables, the two formulas produce the same result. This relationship is denoted by the symbol \\(\\equiv\\). Understanding these equivalences is crucial for simplifying and manipulating logical expressions.\n\nIdentity Laws: A variable OR-ed with false is the variable itself. A variable AND-ed with true is the variable itself.\n\n\\(p \\lor F \\equiv p\\)\n\\(p \\land T \\equiv p\\)\n\nDomination Laws: Any variable OR-ed with true is always true. Any variable AND-ed with false is always false.\n\n\\(p \\lor T \\equiv T\\)\n\\(p \\land F \\equiv F\\)\n\nIdempotent Laws: OR-ing or AND-ing a variable with itself does not change its value.\n\n\\(p \\lor p \\equiv p\\)\n\\(p \\land p \\equiv p\\)\n\nDouble Negation Law: Negating a negation cancels out.\n\n\\(\\neg(\\neg p) \\equiv p\\)\n\nCommutative Laws: The order of variables does not matter for AND and OR operations.\n\n\\(p \\lor q \\equiv q \\lor p\\)\n\\(p \\land q \\equiv q \\land p\\)\n\nAssociative Laws: The grouping of variables does not matter for a sequence of the same operator (AND or OR).\n\n\\((p \\lor q) \\lor r \\equiv p \\lor (q \\lor r)\\)\n\\((p \\land q) \\land r \\equiv p \\land (q \\land r)\\)\n\nDistributive Laws: An operator can be distributed over another within parentheses.\n\n\\(p \\land (q \\lor r) \\equiv (p \\land q) \\lor (p \\land r)\\)\n\\(p \\lor (q \\land r) \\equiv (p \\lor q) \\land (p \\lor r)\\)\n\nDe Morgan’s Laws: These laws describe how to negate a conjunction or a disjunction. To do this, you negate each term and flip the operator.\n\n\\(\\neg(p \\land q) \\equiv \\neg p \\lor \\neg q\\)\n\\(\\neg(p \\lor q) \\equiv \\neg p \\land \\neg q\\)\n\nAbsorption Laws: These laws simplify expressions where a variable is combined with an expression containing that same variable.\n\n\\(p \\lor (p \\land q) \\equiv p\\)\n\\(p \\land (p \\lor q) \\equiv p\\)\n\nImplication and Bi-implication Equivalences: These are fundamental for rewriting conditional statements.\n\nImplication: \\(p \\to q \\equiv \\neg p \\lor q\\)\nContrapositive: \\(p \\to q \\equiv \\neg q \\to \\neg p\\)\nBi-implication: \\(p \\leftrightarrow q \\equiv (p \\to q) \\land (q \\to p)\\) and \\(p \\leftrightarrow q \\equiv (p \\land q) \\lor (\\neg p \\land \\neg q)\\)\n\n\n\n\n1.4 Normal Forms\nA normal form in logic is a standardized way of writing a formula. Two of the most common are Disjunctive Normal Form (DNF) and Conjunctive Normal Form (CNF).\n\nDisjunctive Normal Form (DNF): A formula is in DNF if it is a disjunction (ORs) of conjunctions (ANDs) of literals. A literal is a variable or its negation (e.g., \\(p\\) or \\(\\neg p\\)).\n\nExample: \\((p \\land q) \\lor (\\neg p \\land r)\\)\nTo create a DNF from a truth table, you identify all rows where the output is true. For each such row, you create a conjunction (an AND clause) that is true for that specific combination of inputs. Finally, you connect all these conjunctions with disjunctions (ORs).\n\nConjunctive Normal Form (CNF): A formula is in CNF if it is a conjunction (ANDs) of disjunctions (ORs) of literals.\n\nExample: \\((p \\lor q) \\land (\\neg p \\lor r)\\)\nTo create a CNF from a truth table, you identify all rows where the output is false. For each such row, you create a disjunction (an OR clause) that is false for that specific combination. Finally, you connect all these disjunctions with conjunctions (ANDs).\n\n\n\n\n1.5 Algebraic Normal Form (ANF)\nAlgebraic Normal Form (ANF), also known as a Zhegalkin polynomial, is a unique way to represent any logical formula using only two operators: XOR (\\(\\oplus\\)) and AND (\\(\\cdot\\)). The calculations are performed modulo 2, which means that \\(1 + 1 = 0\\). This form is a polynomial where variables can only have a power of 1 (since \\(x \\cdot x = x\\)).\nThe key conversion formulas are:\n\n\\(\\neg p \\equiv p \\oplus 1\\)\n\\(p \\land q \\equiv p \\cdot q\\) (or just \\(pq\\))\n\\(p \\lor q \\equiv p \\oplus q \\oplus pq\\)\n\\(p \\to q \\equiv 1 \\oplus p \\oplus pq\\)\n\\(p \\leftrightarrow q \\equiv 1 \\oplus x \\oplus y\\)\n\nImportant properties in modulo 2 arithmetic include: * \\(p \\oplus p \\equiv 0\\) * \\(p \\cdot p \\equiv p\\) (or \\(p^2 \\equiv p\\))\n\n\n\n\n2. Definitions\n\nTautology: A logical formula that is always true for any assignment of truth values to its variables.\nContradiction: A logical formula that is always false for any assignment of truth values to its variables.\nContingency: A logical formula that can be either true or false depending on the truth values of its variables.\nSatisfiability: The property of a formula for which there is at least one assignment of truth values that makes it true.\nLogical Equivalence: The relationship between two formulas that have identical truth tables.\nLiteral: A propositional variable or its negation (e.g., \\(p\\) or \\(\\neg p\\)).\nDisjunctive Normal Form (DNF): A logical formula expressed as a disjunction (OR) of one or more conjunctions (ANDs) of literals.\nConjunctive Normal Form (CNF): A logical formula expressed as a conjunction (AND) of one or more disjunctions (ORs) of literals.\nAlgebraic Normal Form (ANF): A canonical representation of a logical formula as a polynomial over a two-element field, using XOR (addition) and AND (multiplication). Also known as a Zhegalkin polynomial.\n\n\n\n\n3. Formulas\n\nDouble Negation: \\(\\neg(\\neg p) \\equiv p\\)\nDe Morgan’s Laws:\n\n\\(\\neg(p \\lor q) \\equiv \\neg p \\land \\neg q\\)\n\\(\\neg(p \\land q) \\equiv \\neg p \\lor \\neg q\\)\n\nDistributive Laws:\n\n\\(p \\land (q \\lor r) \\equiv (p \\land q) \\lor (p \\land r)\\)\n\\(p \\lor (q \\land r) \\equiv (p \\lor q) \\land (p \\lor r)\\)\n\nImplication Equivalence: \\(p \\to q \\equiv \\neg p \\lor q\\)\nBi-implication Equivalence: \\(p \\leftrightarrow q \\equiv (p \\land q) \\lor (\\neg p \\land \\neg q)\\)\nANF Conversions (Modulo 2):\n\n\\(\\neg p \\equiv p \\oplus 1\\)\n\\(p \\lor q \\equiv p \\oplus q \\oplus pq\\)\n\\(p \\to q \\equiv 1 \\oplus p \\oplus pq\\)\n\\(p \\leftrightarrow q \\equiv 1 \\oplus p \\oplus q\\)\n\\(p \\oplus p \\equiv 0\\)\n\\(p \\cdot p \\equiv p\\)\n\n\n\n\n\n4. Mistakes\n\nIncorrectly Applying De Morgan’s Law: A common error is only negating the variables but forgetting to flip the operator. For example, stating that \\(\\neg(p \\lor q)\\) is equivalent to \\(\\neg p \\lor \\neg q\\). Why it’s wrong: De Morgan’s Law requires both negating the terms and inverting the connective, so the correct equivalence is \\(\\neg p \\land \\neg q\\).\nConfusing the Distributive Laws: Incorrectly distributing OR over AND, or vice-versa. For example, assuming \\(p \\lor (q \\land r)\\) simplifies to \\((p \\lor q) \\land r\\). Why it’s wrong: The distribution must apply to both terms inside the parentheses, resulting in the correct form: \\((p \\lor q) \\land (p \\lor r)\\).\nTreating Implication as Commutative: Assuming that \\(p \\to q\\) is the same as \\(q \\to p\\). Why it’s wrong: These are different statements. \\(p \\to q\\) is the original implication, while \\(q \\to p\\) is its converse. They do not have the same truth table and are not logically equivalent.\nErrors in ANF Arithmetic: Forgetting that all arithmetic in ANF is modulo 2. For instance, simplifying \\(p \\oplus p\\) to \\(2p\\) instead of \\(0\\). Why it’s wrong: The XOR operation corresponds to addition in a field with only two elements, {0, 1}, where \\(1+1=0\\).\nIncorrectly Constructing DNF/CNF: Using the “false” rows of a truth table to construct DNF, or the “true” rows for CNF. Why it’s wrong: DNF is a disjunction of terms representing the true outcomes, so each term must correspond to a row where the function is true. CNF is a conjunction of clauses that rule out the false outcomes, so each clause must correspond to a row where the function is false.\nSimplifying \\(\\neg a \\to \\neg b\\) to \\(a \\to b\\): Assuming that negating both sides of an implication preserves the original meaning. Why it’s wrong: The statement \\(\\neg a \\to \\neg b\\) is the inverse of \\(a \\to b\\), not an equivalent form. The correct logical equivalence is the contrapositive: \\(\\neg b \\to \\neg a\\).\n\n\n\n\n5. Examples\n\n5.1. Proving Equivalence with a Truth Table\nQuestion: Prove the equivalence \\(p \\to q \\equiv \\neg p \\lor q\\).\n\n\nClick to see the solution\n\n\nSet up the table: Create columns for the variables \\(p\\) and \\(q\\), and for the expressions \\(p \\to q\\) and \\(\\neg p \\lor q\\). Include an intermediate column for \\(\\neg p\\).\nList all possible truth value combinations for \\(p\\) and \\(q\\).\nEvaluate \\(\\neg p\\): Fill in the column for \\(\\neg p\\) based on the values in the \\(p\\) column.\nEvaluate \\(p \\to q\\): This is false only when \\(p\\) is true and \\(q\\) is false.\nEvaluate \\(\\neg p \\lor q\\): This is true if either \\(\\neg p\\) is true or \\(q\\) is true.\nCompare the final columns: Check if the columns for \\(p \\to q\\) and \\(\\neg p \\lor q\\) are identical.\n\n\n\n\n\\(p\\)\n\\(q\\)\n\\(\\neg p\\)\n\\(p \\to q\\)\n\\(\\neg p \\lor q\\)\n\n\n\n\nT\nT\nF\nT\nT\n\n\nT\nF\nF\nF\nF\n\n\nF\nT\nT\nT\nT\n\n\nF\nF\nT\nT\nT\n\n\n\nAnswer: Since the truth columns for \\(p \\to q\\) and \\(\\neg p \\lor q\\) are identical, the two expressions are logically equivalent.\n\n\n\n5.2. Simplifying a Logical Expression\nQuestion: Simplify the expression \\(\\neg(p \\lor (\\neg p \\land q))\\).\n\n\nClick to see the solution\n\n\nApply De Morgan’s Law to the outermost negation: \\[ \\neg p \\land \\neg(\\neg p \\land q) \\]\nApply De Morgan’s Law to the second part of the expression: \\[ \\neg p \\land (\\neg(\\neg p) \\lor \\neg q) \\]\nApply the Double Negation Law to \\(\\neg(\\neg p)\\): \\[ \\neg p \\land (p \\lor \\neg q) \\]\nApply the Distributive Law: \\[ (\\neg p \\land p) \\lor (\\neg p \\land \\neg q) \\]\nApply the Contradiction Law (\\(\\neg p \\land p \\equiv F\\)): \\[ F \\lor (\\neg p \\land \\neg q) \\]\nApply the Identity Law (\\(F \\lor A \\equiv A\\)): \\[ \\neg p \\land \\neg q \\]\n\nAnswer: The simplified expression is \\(\\neg p \\land \\neg q\\).\n\n\n\n5.3. Finding Disjunctive Normal Form (DNF)\nQuestion: Find the DNF for the function \\(\\Phi(p, q, r)\\) defined by the following truth table:\n\n\n\n\\(p\\)\n\\(q\\)\n\\(r\\)\n\\(\\Phi\\)\n\n\n\n\nT\nT\nT\nT\n\n\nT\nT\nF\nF\n\n\nT\nF\nT\nT\n\n\nT\nF\nF\nF\n\n\nF\nT\nT\nF\n\n\nF\nT\nF\nF\n\n\nF\nF\nT\nT\n\n\nF\nF\nF\nF\n\n\n\n\n\nClick to see the solution\n\n\nIdentify the ‘true’ rows: The function \\(\\Phi\\) is true for the input combinations (T, T, T), (T, F, T), and (F, F, T).\nCreate a conjunction for each ‘true’ row:\n\nFor (T, T, T), the term is \\(p \\land q \\land r\\).\nFor (T, F, T), the term is \\(p \\land \\neg q \\land r\\).\nFor (F, F, T), the term is \\(\\neg p \\land \\neg q \\land r\\).\n\nCombine the conjunctions with disjunctions (ORs): \\[ (p \\land q \\land r) \\lor (p \\land \\neg q \\land r) \\lor (\\neg p \\land \\neg q \\land r) \\]\n\nAnswer: The DNF is \\((p \\land q \\land r) \\lor (p \\land \\neg q \\land r) \\lor (\\neg p \\land \\neg q \\land r)\\).\n\n\n\n5.4. Finding Conjunctive Normal Form (CNF)\nQuestion: Find the CNF for the function \\(\\Psi(p, q)\\) defined by \\(p \\leftrightarrow q\\).\n\n\n\n\\(p\\)\n\\(q\\)\n\\(p \\leftrightarrow q\\)\n\n\n\n\nT\nT\nT\n\n\nT\nF\nF\n\n\nF\nT\nF\n\n\nF\nF\nT\n\n\n\n\n\nClick to see the solution\n\n\nIdentify the ‘false’ rows: The function is false for the input combinations (T, F) and (F, T).\nCreate a disjunction for each ‘false’ row that is false for that specific input. To do this, negate each literal in the row and combine them with OR.\n\nFor (T, F), we negate the literals to get \\(\\neg p\\) and \\(\\neg(\\neg q) = q\\). The clause is \\(\\neg p \\lor q\\).\nFor (F, T), we negate the literals to get \\(\\neg(\\neg p) = p\\) and \\(\\neg q\\). The clause is \\(p \\lor \\neg q\\).\n\nCombine the disjunctions with conjunctions (ANDs): \\[ (\\neg p \\lor q) \\land (p \\lor \\neg q) \\]\n\nAnswer: The CNF is \\((\\neg p \\lor q) \\land (p \\lor \\neg q)\\).\n\n\n\n5.5. Converting to Algebraic Normal Form (ANF)\nQuestion: Convert the expression \\((a \\land \\neg b) \\to a\\) to ANF.\n\n\nClick to see the solution\n\n\nSubstitute the logical operators with their ANF equivalents.\n\n\\(\\neg b \\equiv b \\oplus 1\\)\n\\(X \\to Y \\equiv 1 \\oplus X \\oplus XY\\)\n\nFirst, convert the term inside the parenthesis, \\(a \\land \\neg b\\): \\[ a \\land (b \\oplus 1) = a(b \\oplus 1) = ab \\oplus a \\]\nNow, substitute this result into the implication formula, where \\(X = ab \\oplus a\\) and \\(Y = a\\): \\[ 1 \\oplus (ab \\oplus a) \\oplus (ab \\oplus a)a \\]\nDistribute the final \\(a\\) term: \\[ 1 \\oplus ab \\oplus a \\oplus (aba \\oplus aa) \\]\nSimplify using \\(a \\cdot a = a^2 = a\\): \\[ 1 \\oplus ab \\oplus a \\oplus (ab \\oplus a) \\]\nGroup like terms. Remember that \\(X \\oplus X = 0\\) in modulo 2 arithmetic: \\[ 1 \\oplus (ab \\oplus ab) \\oplus (a \\oplus a) \\] \\[ 1 \\oplus 0 \\oplus 0 \\]\nFinal simplification: \\[ 1 \\]\n\nAnswer: The ANF is \\(1\\), which means the original expression is a tautology.\n\n\n\n5.6. Negating a Complex Expression\nQuestion: Apply De Morgan’s laws to negate and simplify the expression \\((\\neg a \\lor b) \\land (c \\lor \\neg d)\\).\n\n\nClick to see the solution\n\n\nEnclose the entire expression in a negation: \\[ \\neg((\\neg a \\lor b) \\land (c \\lor \\neg d)) \\]\nApply De Morgan’s Law to the central AND (\\(\\land\\)) operator. This splits the negation and flips the operator to OR (\\(\\lor\\)): \\[ \\neg(\\neg a \\lor b) \\lor \\neg(c \\lor \\neg d) \\]\nApply De Morgan’s Law to the first part, \\(\\neg(\\neg a \\lor b)\\): \\[ (\\neg(\\neg a) \\land \\neg b) \\lor \\neg(c \\lor \\neg d) \\]\nApply the Double Negation Law to \\(\\neg(\\neg a)\\): \\[ (a \\land \\neg b) \\lor \\neg(c \\lor \\neg d) \\]\nApply De Morgan’s Law to the second part, \\(\\neg(c \\lor \\neg d)\\): \\[ (a \\land \\neg b) \\lor (\\neg c \\land \\neg(\\neg d)) \\]\nApply the Double Negation Law to \\(\\neg(\\neg d)\\): \\[ (a \\land \\neg b) \\lor (\\neg c \\land d) \\]\n\nAnswer: The negated and simplified expression is \\((a \\land \\neg b) \\lor (\\neg c \\land d)\\).\n\n\n\n5.7. Simplification Using Logical Laws\nQuestion: Prove that \\((p \\to q) \\land (p \\to r) \\equiv p \\to (q \\land r)\\).\n\n\nClick to see the solution\n\n\nStart with the left-hand side (LHS) and convert implications to their \\(\\neg p \\lor q\\) form: \\[ (\\neg p \\lor q) \\land (\\neg p \\lor r) \\]\nThis expression is in the form \\((A \\lor B) \\land (A \\lor C)\\). We can use the Distributive Law in reverse, where \\(A = \\neg p\\), \\(B = q\\), and \\(C = r\\): \\[ \\neg p \\lor (q \\land r) \\]\nNow, convert this expression back from its OR form into an implication, using the equivalence \\(\\neg X \\lor Y \\equiv X \\to Y\\): \\[ p \\to (q \\land r) \\]\nThis matches the right-hand side (RHS) of the original statement.\n\nAnswer: Since the left-hand side can be transformed into the right-hand side using logical equivalence laws, the equivalence is proven.",
    "crumbs": [
      "Discrete Mathematics",
      "2. Logical Equivalence, Normal Forms (DNF, CNF, ANF)"
    ]
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_3.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_3.html",
    "title": "3. Matrices, Determinants, Vector Cross Product, and Triple Products",
    "section": "",
    "text": "1. Summary\n\n1.1 Introduction to Matrices\nA matrix is a rectangular grid of numbers or expressions arranged in rows and columns. It serves as a powerful tool for organizing data and representing systems of linear equations or transformations. A matrix is denoted by a capital letter (e.g., \\(A\\)), and its individual entries are called elements.\nThe dimensions of a matrix are expressed as m x n, where m is the number of rows and n is the number of columns. An element at the intersection of the i-th row and j-th column is denoted by \\(a_{ij}\\).\nFor example, a 2x3 matrix A is written as: \\[ A = \\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\end{pmatrix} \\]\n\n\n1.2 Types of Matrices\nMatrices with specific structures and properties are given special names:\n\nSquare Matrix: A matrix where the number of rows equals the number of columns (m = n). These are the only matrices that have determinants and inverses.\nIdentity Matrix (\\(I\\)): A square matrix with ones on the main diagonal (top-left to bottom-right) and zeros everywhere else. It is the matrix equivalent of the number 1; multiplying a matrix by the identity matrix leaves it unchanged (\\(AI = IA = A\\)).\nZero Matrix: A matrix where every element is zero.\nDiagonal Matrix: A square matrix where all elements not on the main diagonal are zero.\nSymmetric Matrix: A square matrix that is unchanged by transposition (\\(A = A^T\\)). This means that for any i and j, the element \\(a_{ij}\\) is equal to \\(a_{ji}\\).\nTriangular Matrix: A square matrix where all elements are zero either above or below the main diagonal. If the elements below the diagonal are zero, it is an upper triangular matrix. If the elements above are zero, it is a lower triangular matrix.\nHermitian Matrix: An extension of symmetric matrices for complex numbers. A matrix is Hermitian if it is equal to its own conjugate transpose (taking the transpose and then the complex conjugate of each element).\n\n\n\n1.3 Basic Matrix Operations\n\nAddition and Subtraction: These operations are only defined for matrices of the same dimensions. The operation is performed element-wise, meaning the corresponding elements of the matrices are added or subtracted. For \\(C = A \\pm B\\), the elements are \\(c_{ij} = a_{ij} \\pm b_{ij}\\).\nScalar Multiplication: To multiply a matrix by a scalar (a single number), you multiply every element in the matrix by that scalar. For \\(B = \\lambda A\\), the elements are \\(b_{ij} = \\lambda a_{ij}\\).\nTranspose (\\(A^T\\)): The transpose of a matrix is found by interchanging its rows and columns. The first row becomes the first column, the second row becomes the second column, and so on. If A is an m x n matrix, \\(A^T\\) is an n x m matrix. A key property is that the transpose of a product reverses the order: \\((AB)^T = B^T A^T\\).\nTrace (\\(tr(A)\\)): The trace is defined only for a square matrix and is the sum of the elements on its main diagonal. A crucial property is its cyclic invariance under multiplication: \\(tr(ABC) = tr(BCA) = tr(CAB)\\).\n\n\n\n1.4 Matrix Multiplication\nMatrix multiplication is a more complex operation. For the product \\(AB\\) to be defined, the number of columns in matrix A must equal the number of rows in matrix B. If A is an m x n matrix and B is an n x p matrix, the resulting product C will be an m x p matrix.\nThe element \\(c_{ij}\\) in the resulting matrix is the dot product of the i-th row of A and the j-th column of B.  There are two key ways to conceptualize matrix-vector multiplication (\\(Ax\\)):\n\nDot Product View: Each element of the resulting vector is the dot product of a corresponding row of matrix A with the vector x.\nLinear Combination View: The resulting vector is a weighted sum (a linear combination) of the columns of matrix A, where the weights are the elements of vector x.\n\nA fundamental property of matrix multiplication is that it is not commutative: in general, \\(AB \\neq BA\\). The order matters greatly. Think of it like real-world actions: putting on socks then shoes is very different from putting on shoes then socks. However, matrix multiplication is associative (\\((AB)C = A(BC)\\)) and distributive (\\(A(B+C) = AB + AC\\)).\n\n\n1.5 The Determinant of a Matrix\nThe determinant, denoted \\(det(A)\\) or \\(|A|\\), is a unique scalar value that can only be calculated from a square matrix. It provides crucial information:\n\nInvertibility: A matrix has an inverse if and only if its determinant is non-zero. A matrix with a zero determinant is called a singular matrix.\nGeometric Meaning: The determinant represents the scaling factor of the linear transformation described by the matrix. For a 2x2 matrix, its absolute value tells you how much area is scaled. For a 3x3 matrix, it’s the scaling factor for volume. A negative determinant indicates that the transformation also involves a reflection (an “inversion” of orientation).\n\nKey properties of determinants include:\n\n\\(det(AB) = det(A)det(B)\\)\n\\(det(A^T) = det(A)\\)\n\\(det(A^{-1}) = 1 / det(A)\\)\nFor an n x n matrix, \\(det(kA) = k^n det(A)\\)\n\n\n\n1.6 The Matrix Inverse\nThe inverse of a square matrix A, written as \\(A^{-1}\\), is the matrix that “undoes” the operation of A. When multiplied together, they yield the identity matrix: \\(AA^{-1} = A^{-1}A = I\\). This is analogous to how a number multiplied by its reciprocal equals 1 (e.g., \\(5 \\times \\frac{1}{5} = 1\\)). An inverse exists only if the matrix is non-singular (\\(det(A) ≠ 0\\)).\nThe adjugate method is a common way to find the inverse of a 3x3 matrix:\n\nMatrix of Minors (\\(M\\)): For each element \\(a_{ij}\\), its minor \\(M_{ij}\\) is the determinant of the 2x2 sub-matrix that remains after deleting the i-th row and j-th column.\nMatrix of Cofactors (\\(C\\)): The cofactor \\(C_{ij}\\) is the minor with a sign applied, determined by a “checkerboard” pattern. The formula is \\(C_{ij} = (-1)^{i+j}M_{ij}\\).\nAdjugate Matrix (\\(adj(A)\\)): This is the transpose of the cofactor matrix, \\(adj(A)\\) = \\(C^T\\).\nCalculate Inverse: The inverse is found by multiplying the adjugate matrix by the reciprocal of the determinant: \\(A^{-1} = \\frac{1}{\\det(A)}\\text{adj}(A)\\).\n\n\n\n1.7 The Vector Cross Product\nThe cross product is an operation between two vectors in 3D space, written as a x b. The result is a new vector that is geometrically perpendicular (orthogonal) to both of the original vectors.\nThe direction of the resulting vector is given by the right-hand rule: point the fingers of your right hand in the direction of vector a, then curl them toward vector b. Your thumb will point in the direction of a x b.  Key properties of the cross product:\n\nAnti-commutative: Reversing the order flips the direction of the resulting vector: a x b = - (b x a).\nParallel Vectors: The cross product of two parallel vectors is the zero vector (0).\nMagnitude: The magnitude, \\(|| \\mathbf{a} \\times \\mathbf{b} ||\\), equals the area of the parallelogram formed by vectors a and b. The area of the triangle with these sides is half this value.\n\n\n\n1.8 Triple Products\nTriple products combine dot and cross products for three vectors.\n\nScalar Triple Product: This product, \\(\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})\\), results in a scalar. Its absolute value represents the volume of the parallelepiped with sides a, b, and c. If the result is 0, the vectors are coplanar (they all lie in the same plane), meaning the parallelepiped is flat and has no volume. The operation is cyclically symmetric: \\(\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c}) = \\mathbf{b} \\cdot (\\mathbf{c} \\times \\mathbf{a}) = \\mathbf{c} \\cdot (\\mathbf{a} \\times \\mathbf{b})\\). \nVector Triple Product: This product, \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\), results in a vector. The resulting vector lies in the same plane as b and c. It can be simplified with the “BAC-CAB” identity: \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = (\\mathbf{a} \\cdot \\mathbf{c})\\mathbf{b} - (\\mathbf{a} \\cdot \\mathbf{b})\\mathbf{c}\\).\n\nAnother key identity is the Jacobi identity, which shows a cyclic relationship between triple products: \\[ \\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) + \\mathbf{b} \\times (\\mathbf{c} \\times \\mathbf{a}) + \\mathbf{c} \\times (\\mathbf{a} \\times \\mathbf{b}) = \\mathbf{0} \\]\n\n\n\n2. Definitions\n\nMatrix: A rectangular array of numbers arranged in rows and columns.\nScalar: A single numerical quantity that scales a vector or matrix.\nSquare Matrix: A matrix with an equal number of rows and columns.\nIdentity Matrix (\\(I\\)): A square matrix with ones on the main diagonal and zeros elsewhere, which acts as the multiplicative identity.\nDeterminant (\\(det(A)\\)): A scalar value computed from a square matrix that determines its invertibility and geometric scaling properties.\nSingular Matrix: A square matrix whose determinant is zero, meaning it has no inverse.\nMatrix Inverse (\\(A^{-1}\\)): For a non-singular square matrix A, it is the unique matrix that yields the identity matrix when multiplied with A.\nTranspose (\\(A^T\\)): A matrix formed by interchanging the rows and columns of the original matrix.\nTrace (\\(tr(A)\\)): The sum of the elements on the main diagonal of a square matrix.\nAdjugate Matrix (\\(adj(A)\\)): The transpose of the matrix of cofactors.\nCoplanar Vectors: A set of vectors that all lie within the same two-dimensional plane.\nVector Cross Product (\\(\\mathbf{a} \\times \\mathbf{b}\\)): A binary operation on two vectors in 3D space, resulting in a vector perpendicular to both.\nScalar Triple Product (\\(\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})\\)): An operation whose absolute value is the volume of the parallelepiped defined by three vectors.\nVector Triple Product (\\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\)): An operation involving three vectors that results in a new vector coplanar with the second and third vectors.\n\n\n\n3. Formulas\n\nMatrix Multiplication Transpose: \\((AB)^T = B^T A^T\\).\nMatrix Multiplication Inverse: \\((AB)^{-1} = B^{-1} A^{-1}\\).\nTrace Cyclic Invariance: \\(tr(ABC) = tr(BCA) = tr(CAB)\\).\nDeterminant of a Product: \\(det(AB) = det(A)det(B)\\).\nDeterminant of a Transpose: \\(det(A^T) = det(A)\\).\nDeterminant of an Inverse: \\(det(A^{-1}) = 1 / det(A)\\).\nDeterminant of Scalar Multiple: For an n x n matrix, \\(det(kA) = k^n det(A)\\).\n2x2 Determinant: For \\(A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}\\), \\(\\det(A) = ad - bc\\).\nGeneral Matrix Inverse: \\(A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)\\).\nCross Product (Determinant Form): For \\(\\mathbf{a} = \\langle a_1, a_2, a_3 \\rangle\\) and \\(\\mathbf{b} = \\langle b_1, b_2, b_3 \\rangle\\), \\[ \\mathbf{a} \\times \\mathbf{b} = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ a_1 & a_2 & a_3 \\\\ b_1 & b_2 & b_3 \\end{pmatrix} \\]\nScalar Triple Product (Determinant Form): \\[ \\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c}) = \\det \\begin{pmatrix} a_1 & a_2 & a_3 \\\\ b_1 & b_2 & b_3 \\\\ c_1 & c_2 & c_3 \\end{pmatrix} \\]\nVector Triple Product (BAC-CAB): \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = (\\mathbf{a} \\cdot \\mathbf{c})\\mathbf{b} - (\\mathbf{a} \\cdot \\mathbf{b})\\mathbf{c}\\).\nArea of Parallelogram: Area \\(= || \\mathbf{a} \\times \\mathbf{b} ||\\).\nArea of Triangle: Area \\(= \\frac{1}{2} || \\mathbf{a} \\times \\mathbf{b} ||\\).\nVolume of Parallelepiped: Volume \\(= |\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})|\\).\n\n\n\n4. Mistakes\n\nAssuming Matrix Multiplication is Commutative: Always remember that \\(AB\\) is generally not equal to \\(BA\\). Why it’s wrong: The dot product of rows with columns is order-dependent. Swapping the matrices changes which rows are multiplied by which columns, leading to a completely different operation and result.\nIncorrectly Applying Determinant Properties: Assuming that \\(det(A + B) = det(A) + det(B)\\). Why it’s wrong: The determinant does not distribute over addition. This property simply does not hold true. The multiplicative property \\(det(AB) = det(A)det(B)\\) is valid, but an additive equivalent does not exist.\nForgetting the Sign Pattern in Cofactor Expansion: When calculating a determinant or a matrix of cofactors, it is easy to forget the \\((-1)^{i+j}\\) “checkerboard” pattern of signs. Why it’s wrong: These alternating signs are a fundamental part of the definition of the determinant. Omitting them will almost certainly lead to an incorrect value.\nMultiplying Matrices with Incompatible Dimensions: Trying to multiply an m x n matrix by a p x q matrix where n ≠ p. Why it’s wrong: Matrix multiplication is defined by the dot product of rows from the first matrix and columns from the second. The length of these rows (n) must match the length of these columns (p) for the dot product to be a valid operation.\nConfusing the Adjugate with the Cofactor Matrix: Using the cofactor matrix directly to find the inverse instead of its transpose (the adjugate). Why it’s wrong: The formula for the inverse explicitly requires the adjugate, \\(adj(A)\\), which is defined as the transpose of the cofactor matrix (\\(C^T\\)). Using C directly will produce an incorrect inverse.\nMisremembering the Vector Triple Product Rule: Switching the terms in the BAC-CAB rule, for example as \\((a \\cdot b)c - (a \\cdot c)b\\). Why it’s wrong: The rule is precise. The positive term is formed by the dot product of the “outer” vectors (\\(\\mathbf{a}, \\mathbf{c}\\)) scaling the “middle” vector (\\(\\mathbf{b}\\)). Getting the order or signs wrong changes the resulting vector completely.\n\n\n\n5. Examples\n\n5.1. Matrix Multiplication\nQuestion: Given matrices \\(A = \\begin{pmatrix} 2 & 1 & 0 \\\\ -1 & 3 & 4 \\end{pmatrix}\\) and \\(B = \\begin{pmatrix} 5 & -2 \\\\ 1 & 1 \\\\ 0 & -3 \\end{pmatrix}\\), compute the product \\(AB\\).\n\n\nClick to see the solution\n\n\nCheck dimensions: A is a 2x3 matrix and B is a 3x2 matrix. The inner dimensions match (3 and 3), so multiplication is possible. The resulting matrix will be 2x2.\nCalculate the element in the 1st row, 1st column: Take the dot product of the first row of A and the first column of B. \\[ (2)(5) + (1)(1) + (0)(0) = 10 + 1 + 0 = 11 \\]\nCalculate the element in the 1st row, 2nd column: Take the dot product of the first row of A and the second column of B. \\[ (2)(-2) + (1)(1) + (0)(-3) = -4 + 1 + 0 = -3 \\]\nCalculate the element in the 2nd row, 1st column: Take the dot product of the second row of A and the first column of B. \\[ (-1)(5) + (3)(1) + (4)(0) = -5 + 3 + 0 = -2 \\]\nCalculate the element in the 2nd row, 2nd column: Take the dot product of the second row of A and the second column of B. \\[ (-1)(-2) + (3)(1) + (4)(-3) = 2 + 3 - 12 = -7 \\]\nAssemble the final matrix: \\[ \\begin{pmatrix} 11 & -3 \\\\ -2 & -7 \\end{pmatrix} \\]\n\nAnswer: \\(AB = \\begin{pmatrix} 11 & -3 \\\\ -2 & -7 \\end{pmatrix}\\)\n\n\n\n5.2. Determinant of a 3x3 Matrix\nQuestion: Find the determinant of the matrix \\(A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 4 \\\\ 5 & 6 & 0 \\end{pmatrix}\\).\n\n\nClick to see the solution\n\n\nUse cofactor expansion along the first row. The formula is \\(a_{11}C_{11} + a_{12}C_{12} + a_{13}C_{13}\\).\nCalculate the first term (\\(a_{11}C_{11}\\)): \\[ 1 \\cdot (-1)^{1+1} \\det \\begin{pmatrix} 1 & 4 \\\\ 6 & 0 \\end{pmatrix} = 1 \\cdot ((1)(0) - (4)(6)) = 1 \\cdot (-24) = -24 \\]\nCalculate the second term (\\(a_{12}C_{12}\\)): \\[ 2 \\cdot (-1)^{1+2} \\det \\begin{pmatrix} 0 & 4 \\\\ 5 & 0 \\end{pmatrix} = 2 \\cdot (-1) \\cdot ((0)(0) - (4)(5)) = -2 \\cdot (-20) = 40 \\]\nCalculate the third term (\\(a_{13}C_{13}\\)): \\[ 3 \\cdot (-1)^{1+3} \\det \\begin{pmatrix} 0 & 1 \\\\ 5 & 6 \\end{pmatrix} = 3 \\cdot (1) \\cdot ((0)(6) - (1)(5)) = 3 \\cdot (-5) = -15 \\]\nSum the terms: \\[ -24 + 40 - 15 = 1 \\]\n\nAnswer: \\(\\det(A) = 1\\)\n\n\n\n5.3. Inverse of a 3x3 Matrix\nQuestion: Find the inverse of the matrix \\(A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 4 \\\\ 5 & 6 & 0 \\end{pmatrix}\\).\n\n\nClick to see the solution\n\n\nFind the determinant: From the previous example, we know \\(\\det(A) = 1\\). Since it’s not zero, the inverse exists.\nFind the matrix of minors: Calculate the determinant of the 2x2 sub-matrix for each element. \\[ M = \\begin{pmatrix} \\det\\begin{pmatrix}1&4\\\\6&0\\end{pmatrix} & \\det\\begin{pmatrix}0&4\\\\5&0\\end{pmatrix} & \\det\\begin{pmatrix}0&1\\\\5&6\\end{pmatrix} \\\\ \\det\\begin{pmatrix}2&3\\\\6&0\\end{pmatrix} & \\det\\begin{pmatrix}1&3\\\\5&0\\end{pmatrix} & \\det\\begin{pmatrix}1&2\\\\5&6\\end{pmatrix} \\\\ \\det\\begin{pmatrix}2&3\\\\1&4\\end{pmatrix} & \\det\\begin{pmatrix}1&3\\\\0&4\\end{pmatrix} & \\det\\begin{pmatrix}1&2\\\\0&1\\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} -24 & -20 & -5 \\\\ -18 & -15 & -4 \\\\ 5 & 4 & 1 \\end{pmatrix} \\]\nFind the matrix of cofactors by applying the checkerboard pattern of signs: \\[ C = \\begin{pmatrix} -24 & 20 & -5 \\\\ 18 & -15 & 4 \\\\ 5 & -4 & 1 \\end{pmatrix} \\]\nFind the adjugate matrix by transposing the cofactor matrix: \\[ \\text{adj}(A) = C^T = \\begin{pmatrix} -24 & 18 & 5 \\\\ 20 & -15 & -4 \\\\ -5 & 4 & 1 \\end{pmatrix} \\]\nCalculate the inverse using the formula \\(A^{-1} = \\frac{1}{\\det(A)}\\text{adj}(A)\\): \\[ A^{-1} = \\frac{1}{1} \\begin{pmatrix} -24 & 18 & 5 \\\\ 20 & -15 & -4 \\\\ -5 & 4 & 1 \\end{pmatrix} \\]\n\nAnswer: \\(A^{-1} = \\begin{pmatrix} -24 & 18 & 5 \\\\ 20 & -15 & -4 \\\\ -5 & 4 & 1 \\end{pmatrix}\\)\n\n\n\n5.4. Area of a Triangle in 3D\nQuestion: Find the area of the triangle with vertices at points A(1, 2, 0), B(3, 0, -3), and C(5, 2, 6).\n\n\nClick to see the solution\n\n\nDefine two vectors forming the sides of the triangle, originating from the same vertex: \\[ \\vec{AB} = B - A = \\langle 3-1, 0-2, -3-0 \\rangle = \\langle 2, -2, -3 \\rangle \\] \\[ \\vec{AC} = C - A = \\langle 5-1, 2-2, 6-0 \\rangle = \\langle 4, 0, 6 \\rangle \\]\nCompute the cross product \\(\\vec{AB} \\times \\vec{AC}\\). The magnitude of this vector will be the area of the parallelogram formed by \\(\\vec{AB}\\) and \\(\\vec{AC}\\). \\[ \\vec{AB} \\times \\vec{AC} = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 2 & -2 & -3 \\\\ 4 & 0 & 6 \\end{pmatrix} \\] \\[ = \\mathbf{i}((-2)(6) - (-3)(0)) - \\mathbf{j}((2)(6) - (-3)(4)) + \\mathbf{k}((2)(0) - (-2)(4)) \\] \\[ = \\mathbf{i}(-12 - 0) - \\mathbf{j}(12 + 12) + \\mathbf{k}(0 + 8) \\] \\[ = \\langle -12, -24, 8 \\rangle \\]\nFind the magnitude of the cross product vector: \\[ || \\langle -12, -24, 8 \\rangle || = \\sqrt{(-12)^2 + (-24)^2 + 8^2} = \\sqrt{144 + 576 + 64} = \\sqrt{784} = 28 \\]\nCalculate the triangle’s area, which is exactly half the area of the parallelogram: \\[ \\text{Area} = \\frac{1}{2} \\times 28 = 14 \\]\n\nAnswer: The area of the triangle is 14 square units.\n\n\n\n5.5. Volume of a Parallelepiped\nQuestion: Compute the volume of the parallelepiped formed by the vectors \\(\\mathbf{a} = \\langle 1, 1, 0 \\rangle\\), \\(\\mathbf{b} = \\langle 0, 1, 1 \\rangle\\), and \\(\\mathbf{c} = \\langle 1, 0, 1 \\rangle\\).\n\n\nClick to see the solution\n\n\nSet up the scalar triple product as the determinant of the matrix formed by the vectors. The absolute value of this determinant gives the volume. \\[ V = |\\mathbf{a} \\cdot (\\mathbf{b} \\times \\mathbf{c})| = \\left| \\det \\begin{pmatrix} 1 & 1 & 0 \\\\ 0 & 1 & 1 \\\\ 1 & 0 & 1 \\end{pmatrix} \\right| \\]\nCalculate the determinant using cofactor expansion along the first row: \\[ 1 \\det \\begin{pmatrix} 1 & 1 \\\\ 0 & 1 \\end{pmatrix} - 1 \\det \\begin{pmatrix} 0 & 1 \\\\ 1 & 1 \\end{pmatrix} + 0 \\det \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix} \\] \\[ = 1((1)(1) - (1)(0)) - 1((0)(1) - (1)(1)) + 0 \\] \\[ = 1(1) - 1(-1) = 1 + 1 = 2 \\]\nTake the absolute value: \\[ V = |2| = 2 \\]\n\nAnswer: The volume of the parallelepiped is 2 cubic units.\n\n\n\n5.6. Vector Triple Product\nQuestion: Let \\(\\mathbf{a} = \\langle 1, 2, 0 \\rangle\\), \\(\\mathbf{b} = \\langle 3, 0, 1 \\rangle\\), and \\(\\mathbf{c} = \\langle -1, 1, 4 \\rangle\\). Verify the identity \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = (\\mathbf{a} \\cdot \\mathbf{c})\\mathbf{b} - (\\mathbf{a} \\cdot \\mathbf{b})\\mathbf{c}\\).\n\n\nClick to see the solution\n\n\nCalculate the left side: \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\) First, find the inner cross product \\(\\mathbf{b} \\times \\mathbf{c}\\): \\[ \\mathbf{b} \\times \\mathbf{c} = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 3 & 0 & 1 \\\\ -1 & 1 & 4 \\end{pmatrix} = \\mathbf{i}(0-1) - \\mathbf{j}(12 - (-1)) + \\mathbf{k}(3-0) = \\langle -1, -13, 3 \\rangle \\] Next, find the outer cross product \\(\\mathbf{a} \\times (\\text{result})\\): \\[ \\mathbf{a} \\times \\langle -1, -13, 3 \\rangle = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 1 & 2 & 0 \\\\ -1 & -13 & 3 \\end{pmatrix} = \\mathbf{i}(6-0) - \\mathbf{j}(3-0) + \\mathbf{k}(-13 - (-2)) = \\langle 6, -3, -11 \\rangle \\]\nCalculate the right side: \\((\\mathbf{a} \\cdot \\mathbf{c})\\mathbf{b} - (\\mathbf{a} \\cdot \\mathbf{b})\\mathbf{c}\\) First, find the required dot products: \\[ \\mathbf{a} \\cdot \\mathbf{c} = (1)(-1) + (2)(1) + (0)(4) = -1 + 2 = 1 \\] \\[ \\mathbf{a} \\cdot \\mathbf{b} = (1)(3) + (2)(0) + (0)(1) = 3 \\] Next, use these scalars to weigh the vectors: \\[ (1)\\mathbf{b} - (3)\\mathbf{c} = 1\\langle 3, 0, 1 \\rangle - 3\\langle -1, 1, 4 \\rangle \\] \\[ = \\langle 3, 0, 1 \\rangle - \\langle -3, 3, 12 \\rangle = \\langle 3 - (-3), 0 - 3, 1 - 12 \\rangle = \\langle 6, -3, -11 \\rangle \\]\nCompare the results: Both sides evaluate to the same vector, \\(\\langle 6, -3, -11 \\rangle\\).\n\nAnswer: The identity is verified, as both sides of the equation result in the vector \\(\\langle 6, -3, -11 \\rangle\\).\n\n\n\n5.7. Jacobi Identity\nQuestion: Prove the Jacobi identity \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) + \\mathbf{b} \\times (\\mathbf{c} \\times \\mathbf{a}) + \\mathbf{c} \\times (\\mathbf{a} \\times \\mathbf{b}) = \\mathbf{0}\\) for the standard basis vectors \\(\\mathbf{a} = \\mathbf{i} = \\langle 1, 0, 0 \\rangle\\), \\(\\mathbf{b} = \\mathbf{j} = \\langle 0, 1, 0 \\rangle\\), and \\(\\mathbf{c} = \\mathbf{k} = \\langle 0, 0, 1 \\rangle\\).\n\n\nClick to see the solution\n\n\nCalculate the first term: \\(\\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c})\\) \\[ \\mathbf{b} \\times \\mathbf{c} = \\mathbf{j} \\times \\mathbf{k} = \\mathbf{i} = \\mathbf{a} \\] \\[ \\mathbf{a} \\times (\\mathbf{b} \\times \\mathbf{c}) = \\mathbf{a} \\times \\mathbf{a} = \\mathbf{0} \\] (The cross product of any vector with itself is the zero vector).\nCalculate the second term: \\(\\mathbf{b} \\times (\\mathbf{c} \\times \\mathbf{a})\\) \\[ \\mathbf{c} \\times \\mathbf{a} = \\mathbf{k} \\times \\mathbf{i} = \\mathbf{j} = \\mathbf{b} \\] \\[ \\mathbf{b} \\times (\\mathbf{c} \\times \\mathbf{a}) = \\mathbf{b} \\times \\mathbf{b} = \\mathbf{0} \\]\nCalculate the third term: \\(\\mathbf{c} \\times (\\mathbf{a} \\times \\mathbf{b})\\) \\[ \\mathbf{a} \\times \\mathbf{b} = \\mathbf{i} \\times \\mathbf{j} = \\mathbf{k} = \\mathbf{c} \\] \\[ \\mathbf{c} \\times (\\mathbf{a} \\times \\mathbf{b}) = \\mathbf{c} \\times \\mathbf{c} = \\mathbf{0} \\]\nSum the three resulting vectors: \\[ \\mathbf{0} + \\mathbf{0} + \\mathbf{0} = \\mathbf{0} \\]\n\nAnswer: The Jacobi identity holds, as the sum is the zero vector, \\(\\mathbf{0}\\).",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "3. Matrices, Determinants, Vector Cross Product, and Triple Products"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "InnoNotes",
    "section": "",
    "text": "InnoNotes\n\n\nCreated by Zakhar Podyakov with ❤️ If you find any mistakes or have suggestions for improvement, please write to me. Telegram | Github | InnoNotes Github | Prompt for generating guides Innopolis Mafia 🤘\n\n\n\nNews\n\nSeptember 18, 2025 – Google Analytics connected. Started adding videos, quizzes, and flashcards. Check out the updated ITP guides. Added link to prompt for generating guides.\nSeptember 17, 2025 – Launched InnoNotes."
  },
  {
    "objectID": "Introduction to Programming/lec_3.html",
    "href": "Introduction to Programming/lec_3.html",
    "title": "3. Pointers, Declarations, Preprocessing, and File I/O in C",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 The C Memory Model: Stack, Heap, and Global Storage\nTo understand pointers and variables in C, it’s crucial to know how a program organizes its memory. A C program typically divides memory into three main regions:\n\nGlobal (or Static) Storage Area: This area holds global variables (declared outside any function) and static variables (declared with the static keyword). These objects are created when the program starts and exist for the entire duration of the program’s execution. They have a fixed, known memory address.\nThe Stack: The stack is a region of memory used for managing function calls. When a function is called, a new stack frame is created. This frame holds all the function’s local variables (also called automatic variables), its parameters, and the return address. The stack operates on a Last-In, First-Out (LIFO) basis. When a function returns, its stack frame is destroyed, and all its local variables cease to exist. This process is managed automatically by the compiler.\nThe Heap: The heap is a large pool of memory available for use during the program’s execution. Unlike the stack, the heap’s memory is not managed automatically. The programmer must explicitly request memory from the heap and is responsible for releasing it once it’s no longer needed. This is known as dynamic memory allocation and is used for creating objects whose size or lifetime is not known at compile time.\n\n\n\n\n1.2 Pointers: The Foundation\nA pointer is a special type of variable that does not hold data directly but instead holds the memory address of another variable. It “points to” the location where the actual data is stored. This mechanism allows for powerful features like dynamic memory management and efficient manipulation of arrays and data structures.\nThe two fundamental pointer operators are:\n\nAddress-of operator (&): When placed before a variable name, it returns the memory address of that variable. For example, &my_var gives the address where my_var is stored.\nDereference operator (*): When placed before a pointer variable, it accesses the value stored at the memory address the pointer is holding. For instance, if p holds the address of my_var, then *p is equivalent to my_var itself.\n\n\n\n1.3 Pointer Arithmetic and Arrays\nIn C, pointers and arrays are intimately related. An array’s name, when used in an expression, is treated as a constant pointer to its first element. This means array is equivalent to &array[0].\nThis relationship enables pointer arithmetic, which allows you to perform mathematical operations on pointer addresses. When you add an integer n to a pointer p, the result is not p + n bytes. Instead, the address is advanced by n * sizeof(type), where type is the data type the pointer points to. This makes it easy to navigate through arrays.\n\np + i: Points to the i-th element after the one p currently points to.\n*(p + i): Is equivalent to accessing the array element p[i].\np++: Increments the pointer to point to the next element in memory.\n\nBecause of this, the C standard defines the array subscript operation E1[E2] as being identical to (*((E1)+(E2))). Since addition is commutative, this means *(E1+E2) is the same as *(E2+E1), which leads to the surprising but valid syntax E2[E1]. For example, if arr is an array, arr[5] is the same as 5[arr].\n\n\n1.4 Dynamic Memory Management\nDynamic memory is allocated on the heap using functions from the &lt;stdlib.h&gt; library.\n\nAllocation (malloc): The malloc function reserves a block of memory.\n\nIt takes one argument: the number of bytes to allocate. The sizeof operator is essential here to ensure portability and correctness (e.g., malloc(10 * sizeof(int)) for an array of 10 integers).\nIt returns a generic pointer of type void* to the first byte of the allocated block. If allocation fails (e.g., the system is out of memory), it returns NULL.\nThis void* must be cast to the appropriate pointer type (e.g., int*) before it can be used, to inform the compiler how to interpret the data and perform correct pointer arithmetic.\n\nDeallocation (free): The free function releases a block of dynamically allocated memory back to the heap.\n\nIt takes a single argument: the pointer that was returned by malloc.\nIt is the programmer’s absolute responsibility to call free for every malloc. Failure to do so results in a memory leak.\n\n\n\n\n\n1.5 Common Pointer Pitfalls\nPointers are powerful but introduce risks if not managed carefully. Scott Meyer identified several common categories of pointer problems:\n\nOwnership and Destruction: A pointer itself doesn’t carry information about who is responsible for freeing the memory it points to. This can lead to memory leaks (if no one frees the memory) or double frees (if multiple parts of the code try to free it), which can corrupt the heap.\nDangling Pointers: A dangling pointer is a pointer that refers to a memory location that has already been deallocated with free. Using (dereferencing) a dangling pointer results in undefined behavior, as that memory may now contain garbage or be in use by another part of the program.\nPointer vs. Array Ambiguity: A pointer of type T* can point either to a single object or to the first element of an array of objects. The language itself provides no way to know which it is, or the size of the array, from the pointer alone.\nUninitialized Pointers: A pointer that has been declared but not assigned a valid address contains a garbage value. Dereferencing it will access a random memory location, almost always leading to a crash.\n\n\n\n1.6 C Declarations\nA declaration introduces an identifier (like a variable or function name) and specifies its properties. A declaration can contain up to four parts: a storage class (static), a type specifier (int), an entity name (a), and an initializer (= 1).\nC’s declaration syntax is famously complex because it follows the rule “declaration follows use.” This means the declaration mimics how the identifier would be used in an expression.\n\nint *p;: “*p gives an int,” so p is a pointer to an int.\nint arr[10];: “arr[i] gives an int,” so arr is an array of 10 ints.\nvoid (*f)(int);: “*f called with an int gives void,” so f is a pointer to a function that takes an int parameter and returns void.\n\nThe typedef keyword allows you to create an alias for a data type, which is invaluable for simplifying complex declarations and improving code readability. For instance, typedef int (*MathFunc)(int, int); creates a type MathFunc for a pointer to a function that takes two integers and returns one.\n\n\n\n1.7 The C Preprocessor\nThe C preprocessor is a text-processing tool that runs before the compiler. It scans the source code for lines beginning with #, known as preprocessor directives.\n\n#include &lt;filename&gt; or #include \"filename\": Replaces this line with the content of the specified header file.\n#define MACRO_NAME value: Defines a macro. The preprocessor will replace every subsequent occurrence of MACRO_NAME with value. Function-like macros with parameters are also possible, but they are a common source of bugs if not written carefully (parameters and the body should always be enclosed in parentheses).\nConditional Compilation: Directives like #if, #ifdef, #ifndef, #else, and #endif allow blocks of code to be included or excluded from compilation based on a condition. Their most important use is creating include guards in header files to prevent errors from multiple inclusions. An include guard typically looks like this: c     #ifndef MY_HEADER_H     #define MY_HEADER_H     // ... header content ...     #endif\n\n\n\n\n1.8 File I/O in C\nFile Input/Output (I/O) in C is handled by a set of standard library functions declared in &lt;stdio.h&gt;. Operations are performed on streams, which are represented by a FILE* pointer, also known as a file handle.\nThe standard workflow is:\n\nOpen: Use fopen(\"filename\", \"mode\") to open a file. The mode string specifies the operation:\n\n\"r\": Read text.\n\"w\": Write text (discards existing content).\n\"a\": Append text.\n\"rb\", \"wb\", \"ab\": Corresponding operations for binary files.\n\"r+\", \"w+\", \"a+\": Update modes (both reading and writing). fopen returns a FILE* on success or NULL on failure. Always check for NULL.\n\nRead/Write: Use functions like fprintf, fscanf, fgetc, fputc, fgets, fputs, fread, and fwrite to interact with the file.\nClose: Use fclose(file_handle) to close the stream. This flushes any buffered data to the disk and releases system resources. Failing to close a file can lead to data loss.\n\n\n\n\n2. Definitions\n\nPointer: A variable that stores the memory address of another object.\nDereferencing: The action of accessing the value stored at the memory address pointed to by a pointer, using the * operator.\nPointer Arithmetic: Performing arithmetic operations (like addition or subtraction) on a pointer, which scales the result by the size of the pointed-to data type.\nDynamic Memory Allocation: The process of requesting and managing memory on the heap at runtime using functions like malloc() and free().\nHeap: A region of a program’s memory used for dynamic allocation.\nStack: A region of memory used to store local variables and manage function calls in a Last-In, First-Out (LIFO) manner.\nMemory Leak: A situation where dynamically allocated memory is no longer needed but is not deallocated, making it unusable for the program’s lifetime.\nDangling Pointer: A pointer that refers to a memory location that has been freed or is otherwise no longer valid.\nPreprocessor: A program that processes source code before compilation, performing tasks like file inclusion, macro expansion, and conditional compilation.\nMacro: An identifier defined with #define that is replaced by its corresponding value or code block by the preprocessor.\nInclude Guard: A preprocessor construct used in header files to prevent their content from being included more than once in a single compilation unit.\nTypedef: A keyword used to create a synonym or alias for an existing data type.\nFile Handle: A pointer to a FILE structure (FILE*), which represents an open file stream and holds information needed to manage it.\n\n\n\n4. Mistakes\n\nDereferencing an Uninitialized or NULL Pointer: Attempting to access memory via a pointer that hasn’t been assigned a valid address (*p) will read from or write to an arbitrary, invalid memory location, typically causing a segmentation fault. Why it’s wrong: It’s an attempt to access memory that the program does not own or that is not meaningful.\nForgetting to Free Dynamically Allocated Memory: If you allocate memory with malloc() but do not release it with free() when it is no longer needed, you create a memory leak. Why it’s wrong: Over time, memory leaks consume available system memory, which can degrade performance and eventually crash the program or the entire system.\nUsing a Pointer After free(): This is a classic dangling pointer error. After free(p) is called, the memory p points to is invalid. Why it’s wrong: The memory manager may have already reassigned that memory block. Writing to it can silently corrupt unrelated data, leading to bugs that are extremely difficult to diagnose.\nReturning a Pointer to a Local Variable: A function’s local variables are created on the stack and are destroyed when the function returns. Returning a pointer to such a variable is a serious error. Why it’s wrong: The caller receives a dangling pointer to a memory location that is no longer valid. Any attempt to use it will result in undefined behavior.\nIncorrect Macro Definitions: Defining a macro like #define MAX(a,b) a&gt;b?a:b can lead to incorrect results due to operator precedence when used with complex expressions. Why it’s wrong: The preprocessor performs simple text substitution. Always wrap macro parameters and the entire macro body in parentheses to ensure correct evaluation: #define MAX(a,b) (((a)&gt;(b))?(a):(b)).\nNot Checking the Return Value of fopen() and malloc(): Both fopen() and malloc() return NULL to signal failure. Proceeding to use this NULL pointer will cause a program crash. Why it’s wrong: It’s a specific case of dereferencing a NULL pointer. Robust code must always check the return values of functions that can fail before using the results.\n\n\n\n5. Examples\n\n5.1. Basic Pointer Manipulation\nQuestion: Write a C program that declares an integer x with a value of 100. Declare a pointer p, make it point to x, and then use the pointer to change the value of x to 200. Print the final value of x.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    // 1. Declare an integer and a pointer.\n    int x;\n    int *p;\n\n    // 2. Initialize the integer and make the pointer point to it.\n    x = 100;\n    p = &x; // Assign the address of x to p\n\n    // 3. Use the pointer to modify the value.\n    // *p accesses the value at the address p is holding.\n    *p = 200;\n\n    // 4. Print the result.\n    printf(\"The final value of x is: %d\\n\", x);\n\n    return 0;\n}\nAnswer: The program will print The final value of x is: 200.\n\n\n\n5.2. Dynamic Memory Allocation for an Array\nQuestion: Write a C program to dynamically allocate memory for an array of 5 integers, fill it with the first 5 multiples of 10, print the array, and then free the memory.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt; // Required for malloc() and free()\n\nint main() {\n    // 1. Declare a pointer to hold the base address of the array.\n    int *arr;\n    int n = 5;\n\n    // 2. Allocate memory for 5 integers using malloc().\n    arr = (int *)malloc(n * sizeof(int));\n\n    // 3. Check if malloc() was successful.\n    if (arr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1; // Exit with an error code\n    }\n\n    // 4. Fill the array using pointer arithmetic or array syntax.\n    for (int i = 0; i &lt; n; i++) {\n        arr[i] = (i + 1) * 10;\n    }\n\n    // 5. Print the array's content.\n    printf(\"Array values: \");\n    for (int i = 0; i &lt; n; i++) {\n        printf(\"%d \", arr[i]);\n    }\n    printf(\"\\n\");\n\n    // 6. Free the allocated memory to prevent a leak.\n    free(arr);\n    arr = NULL; // Good practice to nullify pointer after freeing\n\n    return 0;\n}\nAnswer: The program will print Array values: 10 20 30 40 50.\n\n\n\n5.3. Passing Pointers to Functions (Swap)\nQuestion: Create a function swap that takes pointers to two integers as arguments and swaps their values. Demonstrate its use in the main function.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\n// 1. Define the swap function that accepts pointers.\nvoid swap(int *a, int *b) {\n    int temp = *a; // Store the value at address 'a'\n    *a = *b;       // Put the value at address 'b' into address 'a'\n    *b = temp;     // Put the stored original value into address 'b'\n}\n\nint main() {\n    // 2. Initialize two integers.\n    int x = 10;\n    int y = 20;\n\n    printf(\"Before swap: x = %d, y = %d\\n\", x, y);\n\n    // 3. Call swap, passing the addresses of x and y.\n    swap(&x, &y);\n\n    printf(\"After swap: x = %d, y = %d\\n\", x, y);\n\n    return 0;\n}\nAnswer: The program’s output will be: Before swap: x = 10, y = 20 After swap: x = 20, y = 10\n\n\n\n5.4. Pointer to a Function\nQuestion: Create two functions, add(int, int) and subtract(int, int). Create a pointer to a function that can point to either of them. Use the pointer to call both functions with inputs 5 and 3 and print the results.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint add(int a, int b) {\n    return a + b;\n}\n\nint subtract(int a, int b) {\n    return a - b;\n}\n\nint main() {\n    // 1. Declare a pointer to a function that takes two ints and returns an int.\n    int (*operation)(int, int);\n    int result;\n\n    // 2. Point it to the 'add' function and call it.\n    operation = &add;\n    result = operation(5, 3); // or (*operation)(5, 3)\n    printf(\"Result of addition: %d\\n\", result);\n\n    // 3. Point it to the 'subtract' function and call it.\n    operation = &subtract;\n    result = operation(5, 3);\n    printf(\"Result of subtraction: %d\\n\", result);\n\n    return 0;\n}\nAnswer: The output will be: Result of addition: 8 Result of subtraction: 2\n\n\n\n5.5. Fixing a Faulty Macro\nQuestion: The following macro is intended to calculate the square of a number but fails for expressions like SQUARE(2+3). Correct the macro. #define SQUARE(x) x*x\n\n\nClick to see the solution\n\n\nIdentify the problem: The expression SQUARE(2+3) expands to 2+3*2+3, which evaluates to 2 + 6 + 3 = 11 due to operator precedence, not the expected 5*5=25.\nAdd parentheses around parameters: To ensure the parameter x is evaluated as a single unit, wrap every instance of it in parentheses. The macro becomes #define SQUARE(x) (x)*(x).\nAdd parentheses around the whole body: To protect the macro from the surrounding context when used in larger expressions, wrap the entire body in parentheses.\n\nCorrected Macro:\n#define SQUARE(x) ((x)*(x))\nExample Usage:\n#include &lt;stdio.h&gt;\n\n#define SQUARE(x) ((x)*(x))\n\nint main() {\n    int result = SQUARE(2+3);\n    printf(\"The result is: %d\\n\", result); // Prints 25\n    return 0;\n}\nAnswer: The corrected macro is #define SQUARE(x) ((x)*(x)).\n\n\n\n5.6. Reading from a File\nQuestion: Write a program that creates a file named data.txt, writes “Hello, World!” to it, closes it, and then re-opens it for reading to print its content to the console.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    FILE *file_ptr;\n    char buffer; // A buffer to hold the line read from the file\n\n    // 1. Open file for writing (\"w\" mode).\n    file_ptr = fopen(\"data.txt\", \"w\");\n    if (file_ptr == NULL) {\n        printf(\"Could not create file for writing.\\n\");\n        return 1;\n    }\n    \n    // 2. Write to the file and close it.\n    fprintf(file_ptr, \"Hello, World!\\n\");\n    fclose(file_ptr);\n    printf(\"Wrote to data.txt successfully.\\n\");\n\n    // 3. Open the same file for reading (\"r\" mode).\n    file_ptr = fopen(\"data.txt\", \"r\");\n    if (file_ptr == NULL) {\n        printf(\"Could not open file for reading.\\n\");\n        return 1;\n    }\n\n    // 4. Read the line from the file and print it.\n    if (fgets(buffer, sizeof(buffer), file_ptr) != NULL) {\n        printf(\"Content of data.txt: %s\", buffer);\n    }\n    \n    // 5. Close the file.\n    fclose(file_ptr);\n\n    return 0;\n}\nAnswer: The program will first print Wrote to data.txt successfully. and then Content of data.txt: Hello, World!.\n\n\n\n5.7. Using an Include Guard\nQuestion: Create a header file math_utils.h that defines a simple PI constant. Protect it with an include guard to prevent multiple inclusion errors. Then, create a main.c file that includes it twice to show the guard works.\n\n\nClick to see the solution\n\nStep 1: Create math_utils.h\n// math_utils.h\n\n// 1. The include guard starts here. Checks if the macro is NOT defined.\n#ifndef MATH_UTILS_H\n// 2. If not defined, define it now.\n#define MATH_UTILS_H\n\n// 3. The actual content of the header file.\n#define PI 3.14159\n\n// 4. The include guard ends here.\n#endif // MATH_UTILS_H\nStep 2: Create main.c\n// main.c\n#include &lt;stdio.h&gt;\n\n// 5. Include the header file the first time.\n// The preprocessor sees that MATH_UTILS_H is not defined,\n// so it defines it and includes the content.\n#include \"math_utils.h\"\n\n// 6. Include the header file the second time.\n// The preprocessor sees that MATH_UTILS_H is now defined,\n// so it skips the content between #ifndef and #endif.\n#include \"math_utils.h\"\n\nint main() {\n    printf(\"The value of PI is: %f\\n\", PI);\n    return 0;\n}\nExplanation: Without the include guard, the preprocessor would try to #define PI twice, causing a compilation error. With the guard, the second #include does nothing, and the program compiles and runs correctly.\nAnswer: The program will compile successfully and print The value of PI is: 3.141590.",
    "crumbs": [
      "Introduction to Programming",
      "3. Pointers, Declarations, Preprocessing, and File I/O in C"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_1.html",
    "href": "Academic Writing and Argumentation/lec_1.html",
    "title": "1. Effective Sentence Structure",
    "section": "",
    "text": "1. Summary\n\n1.1 What is a Sentence?\nA sentence is a fundamental unit of language that expresses a complete thought. To be considered a sentence, a group of words must satisfy four basic grammatical rules:\n\nIt must contain a complete idea.\nIt must have a specific grammatical structure, centered around a subject and a verb.\nIt must begin with a capital letter.\nIt must end with a punctuation mark (such as a period, question mark, or exclamation point).\n\n\n\n1.2 The Clause\nThe core of every sentence is a clause. A clause is a group of words that contains both a subject (who or what performs the action) and a verb (the action or state of being). The simple formula is:\nSubject + Verb = Clause\nIf a group of words lacks a subject, a verb, or both, it is not a clause. It is called a sentence fragment. A fragment cannot stand on its own because it does not express a complete thought.\n\nExample of a fragment: “In the building at night.” (This has no subject or verb).\nExample of a fragment: “Have learned a lot today.” (This has a verb phrase but is missing a subject).\n\n\n\n1.3 Clause Types\nClauses are divided into two main categories: independent and dependent. The combination of these clause types determines the structure of a sentence.\n\n1.3.1 Independent Clause\nAn independent clause (or main clause) contains a subject and a verb and expresses a complete thought. It is grammatically complete and can stand alone as its own sentence.\n\nExample: “I like pizza.”\nExample: “He has read a lot of books.”\n\n\n\n1.3.2 Dependent Clause\nA dependent clause (or subordinate clause) also contains a subject and a verb, but it does not express a complete thought. It cannot stand alone as a sentence. It begins with a subordinating conjunction (e.g., because, although, when, if) which makes the clause reliant on an independent clause to complete its meaning.\n\nExample: “Although I like pizza…” (The thought is incomplete).\nExample: “…because he has read a lot of books.” (This explains a reason but doesn’t state the main idea).\n\n\n\n\n1.4 Sentence Types\nThere are four main types of sentences in English, categorized by the number and type of clauses they contain.\n\n\n1.4.1 Simple Sentence\nA simple sentence consists of exactly one independent clause. It has a single subject and verb combination and expresses a single complete thought.\n\nExample: “A woman went to the gym.”\nExample: “The black rabbit died yesterday.”\n\n\n\n1.4.2 Compound Sentence\nA compound sentence consists of two or more independent clauses joined together. These clauses are typically linked by a coordinating conjunction. The most common coordinating conjunctions can be remembered with the acronym FANBOYS:\n\nFor\nAnd\nNor\nBut\nOr\nYet\nSo\n\n\nPunctuation Rule: When joining two independent clauses with a coordinating conjunction, a comma must be placed before the conjunction.\nIndependent Clause 1 + , + Coordinating Conjunction + Independent Clause 2\n\n\nExample: “A woman went to the gym, and everybody liked her immediately.”\nExample: “The black rabbit died yesterday, so we have bought a white elephant today.”\n\n\n\n1.4.3 Complex Sentence\nA complex sentence contains one independent clause and at least one dependent clause. The dependent clause is linked to the independent clause by a subordinating conjunction (e.g., because, since, although, while, when).\nPunctuation Rules: The punctuation of a complex sentence depends on the order of the clauses.\n\nNo Comma: If the independent clause comes first, followed by the dependent clause, no comma is needed. Independent Clause + Subordinating Conjunction + Dependent Clause \n\nExample: “The woman went to the gym because she wanted to get fit.”\n\nUse a Comma: If the dependent clause comes first, it must be followed by a comma before the independent clause. Subordinating Conjunction + Dependent Clause + , + Independent Clause \n\nExample: “Because she wanted to get fit, the woman went to the gym.”\n\n\n\n\n1.4.4 Compound-Complex Sentence\nA compound-complex sentence is the most intricate structure. It combines elements of both compound and complex sentences. It must contain at least two independent clauses and at least one dependent clause.\n\nExample: “Although he organized his sources by theme, Mongo decided to arrange them chronologically, and he carefully followed the MEAL plan for organization.”\n\nDependent Clause: “Although he organized his sources by theme”\nIndependent Clause 1: “Mongo decided to arrange them chronologically”\nIndependent Clause 2: “he carefully followed the MEAL plan for organization”\n\n\nWarning: Use compound-complex sentences carefully. While powerful, they can make your writing less readable if overused or constructed poorly.\n\n\n\n\n2. Definitions\n\nSentence: A grammatically complete unit of expression, containing a subject and verb, and conveying a complete thought.\nClause: A group of words containing a subject and a verb, forming the basic building block of a sentence.\nIndependent Clause: A clause that expresses a complete thought and can stand alone as a sentence.\nDependent Clause: A clause that contains a subject and verb but does not express a complete thought and cannot stand alone. It begins with a subordinating conjunction.\nSentence Fragment: An incomplete sentence that is missing a subject, a verb, or both, and therefore does not express a complete thought.\nSimple Sentence: A sentence consisting of only one independent clause.\nCompound Sentence: A sentence consisting of two or more independent clauses, joined by a coordinating conjunction (like and, but, or).\nComplex Sentence: A sentence consisting of one independent clause and at least one dependent clause.\nCompound-Complex Sentence: A sentence consisting of two or more independent clauses and at least one dependent clause.\nCoordinating Conjunction: A word that connects two independent clauses (e.g., For, And, Nor, But, Or, Yet, So - FANBOYS).\nSubordinating Conjunction: A word that introduces a dependent clause and connects it to an independent clause (e.g., because, if, although, when).\n\n\n\n3. Mistakes\n\nWriting sentence fragments: Treating a dependent clause or a phrase as a complete sentence. Why it’s wrong: A sentence must express a complete thought and have both a subject and a main verb to be grammatically correct. Fragments leave the reader waiting for more information.\nCreating a comma splice: Joining two independent clauses with only a comma, without a coordinating conjunction. Why it’s wrong: A comma alone is not strong enough to connect two complete thoughts. This error creates a run-on sentence. Use a comma and a conjunction (e.g., , but), a semicolon (;), or separate them into two sentences.\nForgetting the comma after an introductory dependent clause: Failing to place a comma after a dependent clause that starts a sentence. Why it’s wrong: The comma signals the end of the introductory element and the beginning of the main part of the sentence, which prevents confusion for the reader.\nUsing a comma in a complex sentence when the independent clause comes first: Placing a comma before a subordinating conjunction like because or while when it appears in the middle of a sentence. Why it’s wrong: No separation is needed when the main clause is presented first; the subordinating conjunction smoothly integrates the dependent clause.\nOverusing compound-complex sentences: Constructing long, convoluted sentences that are difficult to follow. Why it’s wrong: While grammatically correct, these sentences can obscure the main point and make the text less readable and engaging. Clarity should always be the priority.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "1. Effective Sentence Structure"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_2.html",
    "href": "Academic Writing and Argumentation/lec_2.html",
    "title": "2. Principles of Effective Writing",
    "section": "",
    "text": "1. Summary\n\n1.1 Be Formal\nFormal academic writing is characterized by an objective, professional, and impersonal tone. The goal is to present information and arguments in a clear and respectful manner, avoiding the casualness of everyday conversation. This involves deliberate choices in vocabulary, grammar, and punctuation.\n\n1.1.1 Avoid Contracted Forms Contractions are shortened forms of words where an apostrophe replaces one or more letters (e.g., don't, isn't, wasn't). These are standard in spoken language but are considered too informal for academic work. Always write out the full words to maintain a formal tone. For example, instead of writing “The data wasn’t conclusive,” you should write “The data was not conclusive.”\n1.1.2 Avoid Spoken Language Academic writing requires more precise and formal vocabulary than conversational language. Avoid using slang, colloquialisms, or overly simple words. For instance, instead of saying “The results were pretty good,” a more formal alternative would be “The results were encouraging.” Similarly, replace vague, informal quantities like “a huge number of connections” with the more specific and formal term “numerous connections.”\n1.1.3 Avoid Punctuation Showing Attitude Punctuation marks like exclamation points convey emotion (e.g., surprise, excitement), which is generally inappropriate for objective academic writing. The focus should be on the factual presentation of information. Instead of writing “Turnout was less than 20 percent!”, you can convey the same sense of surprise through careful word choice, such as “Surprisingly, turnout in the election was less than 20 percent.”\n\n\n\n1.2 Be Concise\nConciseness is the art of conveying your message using the fewest words necessary without sacrificing clarity or completeness. Wordy and convoluted sentences can obscure your main points. Streamlining your writing makes it more powerful and easier for the reader to understand.\n\n1.2.1 Avoid Phrasal Verbs A phrasal verb is a combination of a verb and a preposition or adverb (e.g., bring up, look into, go on). While common in speech, they can be informal or ambiguous. Whenever possible, replace them with a single, more formal verb. For example, instead of “The committee brought up this issue,” use “The committee raised this issue.”\n1.2.2 Avoid Negatives Sentences written in the positive form are often clearer and more direct than those written in the negative. Unnecessary negative constructions can make sentences more complex. For example, “not many” can be simplified to “few,” and “did not accept” can be written more directly as “rejected.”\n1.2.3 Avoid Redundant Pairs Redundant pairs are phrases that use two words with the same meaning. This adds unnecessary wordiness. For example, in “first and foremost,” both words mean the first in a series, so using just “First” is more concise. Other examples include “any and all” (use “any”) and “each and every” (use “each”).\n1.2.4 Avoid Redundant Modifiers A redundant modifier is an adverb or adjective that repeats an idea already contained within the word it modifies. For example, since finish implies completion, the phrase “completely finish” is redundant; simply use “finish.” Likewise, “basic fundamentals” is redundant because fundamentals are inherently basic; use “fundamentals.”\n1.2.5 Avoid Metaconcepts Metaconcepts are abstract nouns that describe concepts about concepts (e.g., process, strategy, approach, framework). These words can often be removed to make a sentence more direct without losing meaning. For instance, “The re-factoring strategy seemed to be ineffective” can be streamlined to “Re-factoring seemed to be ineffective.” Similarly, “The process of data generation is explained” is more direct as “Data generation is explained.”\n\n\n\n1.3 Be Precise\nPrecision means choosing the exact word to convey your intended meaning. It involves eliminating ambiguity and vagueness, ensuring that your reader understands your points exactly as you intend them.\n\n1.3.1 Avoid Vague Words Words like good, bad, thing, and big are subjective and lack specific meaning. In an academic context, you must use more descriptive and objective language. Instead of stating “The device performance is bad,” provide a more specific critique like “The device performance is substandard.” Instead of “This design is good,” explain why: “This design is effective.”\n1.3.2 Use Complete Lists In formal writing, avoid using abbreviations like “etc.” (et cetera) when presenting a complete, finite list. Using “etc.” can create ambiguity because the reader may not know what other items the list includes. For example, instead of “The periodic table divides elements into metals, non-metals, etc.,” you should write out the full list: “The periodic table divides elements into metals, non-metals, and semi-metals or metalloids.” The use of “etc.” is only appropriate when providing a few examples from a much larger, open-ended set.\n\n\n\n1.4 Be Cautious (Hedging)\nAcademic knowledge is constantly evolving, and very few claims are absolutely certain. Cautious language, or hedging, is the practice of qualifying your statements to reflect the level of certainty. It shows that you are aware of the limitations of your claims and is a hallmark of credible academic writing.\n\n1.4.1 Avoid Generalizations Sweeping statements using absolute words like everyone, always, or never are risky because a single counterexample can prove them false. It is more accurate and defensible to use qualified language. Instead of “Everyone has access to the Internet nowadays,” a more accurate statement is “Internet access is widespread nowadays.”\n1.4.2 Avoid Emotions Academic arguments should be based on logic and evidence, not personal feelings. Emotionally charged words introduce bias and weaken the objectivity of your writing. For example, calling an idea “stupid” is unprofessional. A more academic approach would be to state, “It is debatable to think that economic means can solve these problems.”\n1.4.3 Use Hedging Language To make your claims more accurate, use hedging words and phrases. These include modal verbs (may, might, can), adverbs (mostly, often, likely), and phrases (appears to be, suggests that). For example, instead of the absolute statement, “The virus is widespread in central Asia,” a more cautious version is “The virus appears to be widespread in central Asia.”\n\n\n\n1.5 Be Clear\nClarity in writing means structuring your sentences so that the reader can follow your ideas effortlessly. Clear writing is characterized by simple sentence structures, strong verbs, and a logical flow of information.\n\n1.5.1 Avoid Nominalization Nominalization is the process of turning a verb or an adjective into a noun (e.g., investigate becomes investigation, effective becomes effectiveness). Overusing nominalizations, especially as the subject of a sentence with a weak verb like “to be,” makes writing dense and abstract. To improve clarity, turn the noun back into its verb form. Instead of “An investigation of the material was performed by the team,” write “The team investigated the material.”\n1.5.2 Avoid Passive Voice (Usually) In the active voice, the subject of the sentence performs the action (e.g., “The researcher conducted the experiment”). In the passive voice, the subject receives the action (e.g., “The experiment was conducted by the researcher”). The active voice is generally more direct, concise, and vigorous. However, the passive voice is sometimes appropriate, such as when describing research methods (“The samples were heated to 100°C”) or when the actor is unknown or unimportant.\n1.5.3 Make Verbs Show Action Strong, active verbs make your writing more engaging and clear. Over-reliance on forms of the verb “to be” (is, are, was, were) can lead to dull and wordy prose. Revise sentences to use verbs that show direct action. For example, “The airline service that is provided by commercial carriers is extremely poor” is weaker than “Commercial air carriers tend to provide poor service.”\n1.5.4 Use Actors or Concrete Nouns for Subjects Sentences are easiest to understand when the subject is the “actor” performing the action.\n\nAvoid Expletives: Phrases like There is/are and It is are called expletives. They delay the true subject of the sentence. Instead of “There are three ways to solve this problem,” rewrite it as “This problem has three solutions.”\nAvoid Isolated Demonstrative Pronouns: Pronouns like this, that, these, and those can be ambiguous when they stand alone. To ensure clarity, follow the pronoun with a noun. Instead of “This is important to consider,” specify what “This” refers to: “This idea is important to consider.”\nAvoid Gerundial Phrases: A gerund (an “-ing” verb acting as a noun) phrase as a subject can be wordy. Recasting the sentence with a clear actor often improves clarity. For example, “Eating uncooked horse meat can cause health problems with students” is clearer as “If students eat uncooked horse meat, they can have health problems.”\n\n1.5.5 Place Subjects and Verbs Close Together For a sentence to be readable, the reader must be able to easily identify its core components: the subject and the verb. Separating them with long clauses or phrases forces the reader to hold information in their memory, making the sentence difficult to parse. Restructure sentences to keep the subject and its verb close together.\n\n\n\n1.6 Be Careful with I, We, and You\nThe use of personal pronouns in academic writing varies by discipline, but some general principles apply.\n\n1.6.1 How to Use “I” In many fields, it is now acceptable to use “I” to describe your own research actions or to guide the reader.\n\nUse “I” to state research steps: “I collected and compiled the results.”\nUse “I” to state your intentions: “In this chapter, I will review the literature.”\nDo not use “I” to state personal opinions. Phrases like “I think that…” weaken your argument because academic claims should be based on evidence, not belief. Instead of “I think it is likely that…”, write “Educators are likely to use…”.\n\n1.6.2 How to Use “We” The pronoun “we” should be used precisely.\n\nUse “we” to refer specifically to yourself and your co-authors: “As researchers, we found that…”\nDo not use “we” to refer vaguely to yourself and the reader or to society in general. This can sound presumptuous. Instead of “We can stop obesity in our society…”, state the agent of the action directly: “Moderate physical activity can stop obesity.”\n\n1.6.3 How to Use “You” The pronoun “you” directly addresses the reader and is considered too informal for most academic writing. It creates a conversational tone that undermines objectivity. Always replace “you” with a more formal, third-person construction. For example, instead of “You can see the results in Table 3,” write “Table 3 shows the results.”\n\n\n\n\n2. Mistakes\n\nUsing contractions like don't or isn't: This is an error because academic writing requires a formal tone. Why it’s wrong: Contractions are shortcuts used in informal, spoken language and are considered unprofessional in formal documents.\nMaking absolute generalizations with words like everyone or always: This is a mistake because such sweeping claims are rarely accurate and can be easily disproven. Why it’s wrong: A single counterexample can invalidate the claim, which undermines the author’s credibility and the overall strength of the argument.\nStarting sentences with weak expletives like There is or It is: This is a stylistic error that adds unnecessary words and delays the introduction of the true subject. Why it’s wrong: It creates weaker, less direct sentences by burying the main noun and verb, making the text less engaging and harder to read.\nUsing vague, subjective words like good, bad, or thing: This is an error because academic writing demands precision and objectivity. Why it’s wrong: These words rely on personal judgment and lack the specific, measurable, and objective detail needed to make a clear and defensible academic point.\nRelying on the passive voice unnecessarily: While the passive voice has specific uses, overusing it often makes writing wordy and evasive. Why it’s wrong: It can obscure who is performing the action, which can make the text less clear, less direct, and less authoritative.\nStating personal opinions with phrases like I believe or I think: This weakens an academic argument. Why it’s wrong: An argument’s validity should stem from the evidence and logical reasoning presented, not from the author’s personal conviction. These phrases shift the focus from the evidence to the author.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "2. Principles of Effective Writing"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_5.html",
    "href": "Academic Writing and Argumentation/lec_5.html",
    "title": "5. Avoiding Plagiarism, Referencing, Summarizing, Paraphrasing",
    "section": "",
    "text": "1. Summary\n\n1.1 Understanding Plagiarism\nPlagiarism is the act of presenting someone else’s work or ideas as your own without giving proper credit. In academic and professional writing, it is considered a serious offense with significant consequences, including failing an assignment, being reported to a disciplinary board, or even expulsion. A common guideline defines plagiarism as using more than three words verbatim from a source without proper referencing.\nIt’s important to distinguish between plagiarism and similarity. While plagiarism is the uncredited use of another’s work, similarity can occur legitimately when citing sources. Tools that detect similarity might flag names, titles, established terminology, numerical data, or common phrases that are difficult to reword. The key difference is attribution; properly referenced text may be similar, but it is not plagiarized.\n\n\n1.2 The Core Principles of Referencing\nReferencing is the fundamental method for avoiding plagiarism. It involves systematically acknowledging the sources of information you have used in your writing. Proper referencing allows your readers to locate the original sources, demonstrates the breadth of your research, and situates your work within the existing academic conversation. The two primary components of referencing are in-text citations and a final reference list.\n\n\n1.3 In-Text Citations (IEEE Style)\nAn in-text citation is a brief reference within the body of your text that points the reader to the full source details in the reference list. The IEEE (Institute of Electrical and Electronics Engineers) style is a numbered system commonly used in technical fields.\nKey characteristics of IEEE in-text citations include:\n\nNumbered System: Citations are numbered in the order they appear in the text, starting with [1].\nSquare Brackets: The citation number is always enclosed in square brackets, e.g., [2].\nFormatting: The citation number should appear on the text line, have a space before it, and come inside the sentence’s punctuation (e.g., “…as shown in the study [3].”).\nMultiple Sources: To cite multiple sources at once, separate the numbers with commas (e.g., [4], [5]) or use a hyphen for a range (e.g., [6]-[8]).\nEt al.: This Latin phrase, short for et alia (“and others”), is used when a source has more than two authors. You should list the first author’s last name followed by et al. For example, a work by Wood, Taylor, and Azzarello would be cited as “Wood et al. [7] claim that…”.\n\n\n\n1.4 Direct Quotations and Ellipsis\nA direct quotation is an exact, word-for-word reproduction of a phrase or sentence from a source. To use a direct quotation correctly, you must enclose the borrowed text in quotation marks and provide an in-text citation, including the page number if available (e.g., [7, p. 14]). Quotations are used to preserve the original author’s precise language or to provide strong evidence for an argument.\nAn ellipsis (a set of three dots, ...) is used within a quotation to indicate that you have omitted some unnecessary words from the original text. It is crucial that the omission does not alter the original meaning of the source material. For example: “the proposed circuit has improved signal attenuation ... and has been experiencing less performance degradation.”\n\n\n1.5 The Reference List\nThe reference list appears at the end of your document and provides the full publication details for every source cited in your text. Each entry is numbered to correspond with the in-text citations. This allows any reader to find the exact sources you consulted. The list should be ordered numerically, matching the sequence of citations in the paper.\n\n\n1.6 The Art of Summarizing\nSummarizing involves condensing the main ideas of a source into a concise overview written in your own words. Unlike a detailed paraphrase, a summary focuses only on the main points, omitting the supporting details. You should summarize when the finer details are irrelevant to your argument or when a source is not significant enough to warrant a more detailed explanation. A summary still requires a citation to the original source.\n\n\n1.7 Effective Paraphrasing\nParaphrasing is restating information or ideas from a source using your own vocabulary and sentence structure. A successful paraphrase demonstrates that you have fully understood the original text. It is different from a quotation because it does not use the author’s exact words, and it is different from a summary because it can be just as detailed as the original. Paraphrasing is often preferred over quoting because it improves the flow and readability of your writing while still grounding your arguments in credible sources.\n\n\n1.8 A 6-Step Guide to Paraphrasing\nTo ensure your paraphrase is a true representation of your own understanding and not just a minor rewording of the original, follow these six steps:\n\nRead the Original: Read the passage several times until you are confident you understand its meaning.\nNote Key Concepts: Identify the main ideas and any shared language—terms that are difficult or impossible to change, such as proper nouns, technical terminology, or numerical data.\nWrite from Memory: Set the original text aside and write your version of the idea. This forces you to use your own words and sentence structure.\nCompare: Compare your paraphrase with the original passage. Check that you have preserved the original meaning and have not used the same phrasing.\nRevise: Change any phrases or sentences that are still too similar to the original.\nCite: Add an in-text citation (e.g., [1]) to give credit to the original author.\n\n\n\n1.9 Using Reporting Verbs\nReporting verbs are used to introduce information from a source (e.g., “Smith [9] argues that…”). The choice of verb is important, as it can convey your stance on the source’s idea.  Instead of relying on overused, neutral verbs like “says” or “states,” select a stronger, more precise verb to accurately reflect the author’s position and critically evaluate the information. For example, instead of “The study says the result is positive,” you could write “The study celebrates the positive result” or “The study concedes the result is positive.” Using varied and accurate reporting verbs makes your writing more dynamic, precise, and analytical. For instance, writing “The Asian Police Alliance [34] blames the rise in drug trafficking on Western pop culture” is more impactful and specific than saying they say it is the cause.\n\n\n\n2. Mistakes\n\nPatchwriting: This involves changing only a few words in a sentence from a source or rearranging the sentence order slightly. Why it’s wrong: This is a form of plagiarism because it closely follows the original author’s vocabulary and sentence structure without using quotation marks. A proper paraphrase requires you to use your own words and sentence construction.\nIncorrect Citation Phrasing: Using awkward phrasing like “In reference [1], Jones discusses…” or “In Jones [2], a new approach is proposed.” Why it’s wrong: While not technically plagiarism, it is poor academic style. The preferred, more direct phrasing is “Jones [1] discusses…” or “Jones [2] proposed a new approach…”.\nMisrepresenting a Source with Ellipsis: Using an ellipsis (...) to omit words in a way that changes the author’s original meaning. For example, changing “The study found no significant evidence of a cure” to “The study found ... evidence of a cure.” Why it’s wrong: This is a serious form of academic dishonesty as it deliberately misleads the reader about the source’s findings.\nForgetting to Cite a Summary or Paraphrase: Assuming that because you used your own words, you don’t need to provide a citation. Why it’s wrong: The ideas or information still belong to the original author. Plagiarism includes using someone’s ideas, not just their words, without giving credit.\nMismatching In-Text Citations and the Reference List: Citing a source in your text (e.g., [5]) but forgetting to add the corresponding entry to the numbered reference list at the end of the paper. Why it’s wrong: This makes it impossible for a reader to find the source you are referencing, defeating the purpose of the citation.\nUsing Too Many Direct Quotations: Filling your paper with long, block quotations instead of paraphrasing the information. Why it’s wrong: Over-quoting suggests that you have not fully understood the material or are unable to explain it in your own words. It makes the writing choppy and less original.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "5. Avoiding Plagiarism, Referencing, Summarizing, Paraphrasing"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_4.html",
    "href": "Academic Writing and Argumentation/lec_4.html",
    "title": "4. Paragraphs, Structure, Transitions",
    "section": "",
    "text": "1. Summary\n\n1.1 Defining the Paragraph\nA paragraph is the fundamental basic building block of any longer text. It is defined as a group of sentences focused entirely on a single subject. The core principle of effective writing dictates that one paragraph should contain only one idea. If a new idea or subtopic emerges, a new paragraph must be started.\n\n\n\n1.2 Characteristics of an Effective Paragraph\nAn effective paragraph must possess five critical characteristics:\n\nUnified: It focuses exclusively on one main idea (the controlling idea). All sentences must directly develop this central idea without deviation.\nLogical: The sentences must flow smoothly, establishing clear relationships between concepts. This is often achieved through the known-new contract.\nWell-structured: It follows a recognized format, typically including a head, a body, and a conclusion.\nClear: The language and ideas are immediately understandable to the reader.\nConcise: It is efficient, using only necessary words and sentences to fully develop the idea.\n\n\n\n1.3 Paragraph Structure: The Burger Model\nAn effective paragraph is usually organized into three distinct parts, often visualized using the burger analogy:\n\nParagraph Head (Top Bun): Typically one or two sentences that introduce the topic and the writer’s stance. This is the topic sentence.\nSupporting Sentences (Meat and Fillings): These form the body of the paragraph. They expand, explain, and prove the main idea stated in the head. This section generally makes up two-thirds of the paragraph’s word count and requires at least three supporting points.\nConcluding Sentence (Bottom Bun): The final sentence that wraps up the discussion of that single idea, often rephrasing the head or summarizing the supporting points.\n\n\n\n\n1.4 The Paragraph Head (Topic Sentence)\nThe Paragraph Head (or topic sentence) is crucial as it states the primary purpose of the paragraph and often provides a smooth transition from the preceding paragraph.\nA well-written paragraph head is composed of two elements:\n\nThe Topic: What the paragraph is generally about.\nThe Controlling Idea: What the writer intends to say or prove about that topic. This limits the scope and dictates what the supporting sentences must discuss.\n\nFor example, if the topic is “Video games,” the controlling idea might be that “they are beneficial for several reasons.” The resulting topic sentence would be: “Video games are beneficial for social, psychological, and physical reasons.”\n\n\n1.5 Writing Supporting Sentences\nSupporting sentences are the evidence and explanation that develop the controlling idea. They usually follow a two-part approach:\n1. Explanation The writer must explain the controlling idea multiple times (usually three) using different approaches, such as providing:\n\nExamples: Specific instances that illustrate the point.\nReasons: Causes or justifications for the main idea.\nSteps: If the paragraph describes a process.\n\n2. Details Each explanation must be grounded in specific details to provide credibility and depth. Details can take several forms:\n\nFacts: Information generally accepted as truth.\nAnecdotes: Short, relevant stories or incidents based on experience.\nStatistics: Numerical data, often derived from surveys or studies.\nExpert’s Opinion: References to statements or theories from knowledgeable authorities.\n\n\n\n\n1.6 The Concluding Sentence\nThe concluding sentence is the last sentence in the paragraph and serves to signal the end of the discussion on that particular topic.\nCrucially, it should never introduce new details or ideas.\nThere are two main strategies for writing an effective concluding sentence:\n\nRephrasing: Repeating the controlling idea found in the paragraph head, but using entirely different language and syntax.\nSummarizing: Synthesizing the main points made in the supporting sentences to create a unified final statement.\n\n\n\n1.7 Ensuring Logical Flow: Transitions\nFor sentences to flow smoothly, they must connect logically. This is managed through two main techniques: the known-new contract and the use of transitions.\n\n1.7.1 The Known-New Contract (Topic and Stress)\nTo maintain logical flow (cohesion), sentences should adhere to the known-new contract:\n\nBeginning of the sentence (Topic/Known): Start with information the reader already possesses (i.e., information carried over from the previous sentence’s ending).\nEnd of the sentence (Stress/New): Place the most unfamiliar, important, or new information at the end of the sentence.\n\nThis creates a chain effect, where the new information (stress) of one sentence becomes the known information (topic) of the next.\n\n\n1.7.2 Direct Transitions\nDirect transitions are specific set phrases or words used to indicate the logical relationship between two sentences or ideas. They help guide the reader through the argument.\n\nOrdering: First, Second, Finally, Primarily.\nAdding: Furthermore, Moreover, In addition.\nCausation: Therefore, Consequently, As a result.\nContrast: However, Nevertheless, On the other hand.\n\n\n\n1.7.3 Indirect Transitions (Links)\nIndirect transitions provide cohesion by linking ideas or words subtly throughout the paragraph:\n\nWord-links: Simple repetition of key words or phrases (e.g., repeating “Michael Schlotzky” or “student”).\nIdea-links: Using synonyms, pronouns, or descriptive phrases to refer back to previously mentioned people, objects, or concepts (e.g., referring to “Michael Schlotzky” as “the young man” or “this truant”).\n\n\n\n\n\n2. Mistakes\n\nAnnouncing the topic instead of stating the main idea: A weak paragraph head often states what the paper will do (e.g., “This paper will discuss the difference between A and B”). Why it’s wrong: The topic sentence should directly state the main argument or conclusion (e.g., “A and B are different”) so the reader immediately understands the purpose of the paragraph.\nCreating a paragraph head that lacks a controlling idea: Some topic sentences state only the subject (“The difference between authorization and authentication”). Why it’s wrong: This fails to limit the scope of the paragraph, leaving the reader unsure of the argument the supporting sentences will develop.\nIncluding sentences that deviate from the main idea (lack of unification): Inserting information that is interesting but irrelevant to the controlling idea of the paragraph. Why it’s wrong: This confuses the reader, weakens the argument, and violates the fundamental rule of one paragraph, one idea.\nIntroducing new supporting details in the concluding sentence: Using the final sentence to provide a new piece of evidence, example, or fact. Why it’s wrong: The concluding sentence must summarize or rephrase existing content; new details belong in the body of the paragraph and require explanation and development.\nFailing to establish a known-new contract across sentences: Arranging sentences such that the beginning of a sentence introduces an entirely new concept unrelated to the stress of the previous sentence. Why it’s wrong: This makes the prose choppy and difficult to follow, breaking the logical chain of thought for the reader.\nUsing insufficient supporting sentences: Writing a paragraph with only one or two brief supporting sentences to prove the controlling idea. Why it’s wrong: The main idea remains underdeveloped, unsubstantiated, and unconvincing. An effective paragraph requires several well-detailed supporting sentences (at least three) to fully develop the argument.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "4. Paragraphs, Structure, Transitions"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_6.html",
    "href": "Academic Writing and Argumentation/lec_6.html",
    "title": "6. Descriptive Paragraph",
    "section": "",
    "text": "1. Summary\n\n1.1 Introduction to Descriptive Paragraphs\nA descriptive paragraph is a focused piece of writing that aims to create a clear and vivid picture of a subject in the reader’s mind. Its primary goal is to describe the main features of a person, object, place, or concept using clear, specific details. Rather than telling the reader something, it shows them by appealing to their senses and intellect, allowing them to form their own mental image of the topic.\n\n\n1.2 Common Applications\nDescriptive paragraphs are a fundamental tool in technical and academic writing. They are typically used in the following scenarios:\n\nDescribing an object: Explaining the physical or logical components of a piece of hardware, a tool, or any other tangible item.\nDescribing a process: Outlining the steps or stages of a procedure, workflow, or event in a logical sequence.\nProviding a classification or typology: Grouping items into categories based on shared characteristics and describing the features of each category, as seen in the malware example.\n\n\n\n1.3 The Structure of a Descriptive Paragraph\nA well-formed descriptive paragraph follows a clear and logical structure, ensuring the reader can easily understand the information presented. \n\nParagraph Head (Topic Sentence): This is the opening sentence that introduces the main subject of the paragraph. It should be direct and engaging, clearly stating what will be described without using announcing phrases like “This paragraph will describe…” or “I am going to tell you about…”.\nBody (Features and Details): The body of the paragraph is built around the main features or characteristics of the subject. Each feature is introduced and then supported by several details. These details must consist of relevant information—facts, explanations, or examples that are essential for the reader to understand the description. For instance, when describing a computer virus, a key feature is how it spreads, and a relevant detail would be its attachment to a file that executes when opened.\nConcluding Sentence: This is the final sentence of the paragraph. It provides closure by either summarizing the main features discussed or rephrasing the paragraph head in a new way, reinforcing the paragraph’s main idea.\n\n\n\n1.4 Key Writing Tips\nTo write an effective descriptive paragraph, especially in a technical or academic context, adhere to the following guidelines:\n\nUse Neutral Language: Rely on objective, neutral words that describe the subject accurately without arousing strong emotions. The goal is to inform, not to persuade.\nStrive for Clarity: Make your description as clear and unambiguous as possible. Avoid jargon where possible, and explain it if it’s necessary.\nAdd a Title: A concise title helps frame the topic for the reader.\nEnsure Grammatical Correctness: Check that all sentences are complete, containing both a subject and a verb.\nMaintain an Effective Academic Style: Your writing should be formal, concise, and logically structured.\nProofread Diligently: Ask a peer to proofread your first draft to catch errors you might have missed.\nLearn from Mistakes: Take note of frequent errors in your writing and make a conscious effort to avoid them in the future.\n\n\n\n\n2. Definitions\n\nDescriptive Paragraph: A paragraph focused on creating a clear, detailed picture of a person, place, object, or concept in the reader’s mind.\nParagraph Head: The topic sentence that introduces the subject of the paragraph.\nFeature: A main characteristic or distinct aspect of the subject being described.\nDetail: A specific piece of relevant information, such as a fact or an explanation, that elaborates on a feature.\nConcluding Sentence: The final sentence that summarizes the main points or restates the paragraph head to provide closure.\n\n\n\n3. Mistakes\n\nAnnouncing your topic directly: Using phrases like “I will now describe the CPU.” Why it’s wrong: This is considered poor style in academic writing. The paragraph head should introduce the topic naturally without explicitly stating the author’s intent.\nUsing vague or general language: Describing something as “good” or “interesting” without providing specific details. Why it’s wrong: Descriptive writing relies on precision. The reader cannot form a clear picture from terms that are subjective and lack concrete information.\nDisorganized information: Presenting features and details in a random, illogical order. Why it’s wrong: A lack of structure confuses the reader. Information should be organized logically (e.g., from general to specific, top to bottom, or by category) to be easily understood.\nOmitting a concluding sentence: Ending the paragraph abruptly after the last detail. Why it’s wrong: The concluding sentence is crucial for signaling that the description is complete and for reinforcing the main point, leaving the reader with a sense of closure.\nIncluding irrelevant information: Adding details that do not directly support the feature being described. Why it’s wrong: Extraneous information distracts the reader and weakens the paragraph’s focus and clarity.\nRelying on emotionally charged words: Using biased or subjective language instead of neutral, objective terms. Why it’s wrong: In technical and academic writing, the goal is objective clarity, not emotional persuasion. Emotional words can undermine the credibility of the description.\n\n\n\n4. Prompt for feedback on your TSA\nEvaluate the following single-paragraph assignment for strict compliance and quality. Be blunt,\ndirect, and unsparing. Do not praise. Identify every flaw. Then provide concrete, minimal edits\nand a corrected model paragraph.\n\nStudent’s paragraph:\n[PASTE THE STUDENT’S SINGLE PARAGRAPH HERE. ONE PARAGRAPH ONLY.]\n\nEvaluation constraints and scoring:\n1) Task match and scope\n- Must be exactly one descriptive paragraph about one of: a real-world object, a process, or a\nclassification/typology. If not, say “Fail: wrong task.”\n- No tables, bullet points, or headings inside the paragraph body. If present, say “Fail: format\nviolation.”\n\n2) Paragraph head (topic + controlling idea)\n- First 1–2 sentences must state the topic and a clear controlling idea without announcing (“This\nparagraph will…”). If missing/weak, rewrite one strong head sentence.\n- The head must preview the features (object: key attributes; process: major steps; classification:\nthe categories). If not, state exactly what is missing.\n\n3) Supporting sentences: explanation + details\n- At least 3 supporting sentences that explain the controlling idea and add relevant, concrete\ndetails: facts, examples, brief reasons, expert view, or simple statistics—kept concise and\nverifiable in tone. If details are vague or irrelevant, label them and replace with precise\nalternatives.\n- For processes: steps must be clear and sequential; for classifications: categories must be\ndistinct and exemplified; for objects: salient features must be described with measurable or\nobservable properties. If not, supply corrected content.\n\n4) Concluding sentence\n- Final sentence must restate the controlling idea or summarize the features; no new information.\nIf it adds new info or is missing, rewrite it correctly.\n\n5) Coherence and transitions\n- Enforce known–new contract: sentence openings should anchor known info; sentence endings\nshould introduce new info. Identify every violation and show one-line fixes.\n- Require explicit transitions every 2–3 sentences (e.g., First, Second, Finally; However;\nConsequently). Insert minimal, precise transitions where absent.\n\n6) Style, tone, and concision\n- Academic, neutral diction; no emotional language; no rhetorical questions. Flag and replace\nany inflated or vague phrasing.\n- Be concise and precise: remove redundancy, nominalizations that obscure meaning, and filler\nqualifiers. Show a tightened version with tracked minimal edits.\n- Grammar: every sentence must have a clear subject and finite verb; fix fragments, run-ons,\nand comma splices.\n\n7) Hard checks for the three descriptive options\n- If Object is described: identify three distinct, observable features with concrete detail. If fewer\nthan three or not concrete, fix.\n- If Process is described: identify and order three core steps with crisp, actionable phrasing. If out\nof order or blended, fix.\n- If Classification is described: present a clear set of categories; define each briefly; ensure\nmutual clarity. If overlapping or undefined, fix.\n\nDeliverables:\nA) Compliance verdicts: Pass/Fail for each criterion (1–7) with one-line justification.\nB) Line-by-line edits: show the student’s paragraph with minimal, necessary edits in brackets,\nreplacing weak words, tightening syntax, and inserting transitions; no rewrites beyond necessity.\nC) Rewritten model paragraph: produce a fully compliant, high-quality paragraph for the same\nchosen type and topic, using neutral academic style, strong head, three solid supports, correct\ntransitions, and a proper concluding sentence. Keep it under 150 words.\nD) Micro-lessons (max 3 bullets): one sentence each on the exact errors the student tends to\nmake and how to avoid them next time. Be specific and operational.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "6. Descriptive Paragraph"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_3.html",
    "href": "Academic Writing and Argumentation/lec_3.html",
    "title": "3. Sentence Problems, Punctuation",
    "section": "",
    "text": "1. Summary\n\n1.1 Sentence Problems and How to Fix Them\nCorrect sentence structure is essential for clear and effective communication. Common problems can make writing confusing or unprofessional, but they are easily fixed once identified.\n\n\n1.1.1 Sentence Fragments\nA sentence fragment is an incomplete thought punctuated as if it were a complete sentence. It lacks a subject, a verb, or both, and cannot stand on its own.\n\nFragment: Three dogs and a goat. (Missing a verb/action).\nComplete Sentence: Three dogs and a goat ate all the food. (Now includes the verb “ate”).\nFragment: Because I could not find my shoes. (This is a dependent clause, an incomplete thought).\nComplete Sentence: I felt sad because I could not find my shoes. (The fragment is now attached to a complete sentence).\n\n\n\n1.1.2 Choppy Sentences\nChoppy sentences are short, simple sentences that occur one after another. While grammatically correct, they can make writing sound abrupt and disconnected. The solution is to combine these short sentences into longer, more fluid ones using conjunctions and transitions.\n\nChoppy: Our results were inconsistent. The program obviously contains an error. We need to talk to Paul Davis. We will ask him to review the program.\nImproved: We will ask Paul Davis to review the program for errors because it produced inconsistent results.\n\n\n\n1.1.3 Run-on Sentences\nA run-on sentence occurs when two or more independent clauses (complete thoughts) are joined together improperly.\n\nThere are two main types:\n\nFused Sentences: Two independent clauses are joined with no punctuation at all.\n\nFused: The experiment failed it had been left unobserved for too long.\nCorrected: The experiment failed because it had been left unobserved for too long. (Using a subordinating conjunction).\nCorrected: The experiment had been left unobserved for too long, so it failed. (Using a comma and a coordinating conjunction).\n\nComma-Splice Sentences: Two independent clauses are joined with only a comma, which is not strong enough punctuation to connect them.\n\nComma Splice: The experiment failed, it had been left unobserved for too long.\nCorrected: The experiment failed because it had been left unobserved for too long.\nCorrected: The experiment had been left unobserved for too long, so it failed.\n\n\n\n\n1.1.4 Loose Sentences\nA loose sentence is a long, rambling sentence that contains too many clauses and phrases, making the main point difficult to understand. The key ideas are often buried in a series of additions. To fix this, break the sentence into shorter, more direct sentences that clearly state the essential information.\n\nLoose: We got the contract, according to which we must be ready by June 1 with the necessary personnel and equipment to get the job done, so with this in mind a staff meeting that all group managers are expected to attend, is scheduled for February 12.\nImproved: We must close the contract by June 1, so a mandatory staff meeting is scheduled for February 12.\n\n\n\n1.1.5 Inappropriate or Excessive Coordination\nThis error occurs when too many independent clauses are linked together with coordinating conjunctions (like and, so, but), creating a long, stringy sentence that doesn’t show the proper relationship between ideas. The fix is to break the sentence into smaller ones or use subordination to clarify the relationship.\n\nInappropriate: Roses are a popular flower, and they are difficult to grow, so many people choose to purchase them as cut flowers instead, but that can be expensive.\nImproved: Roses are a popular flower that are difficult to grow. So, many people buy cut roses, but that can be expensive.\n\n\n\n1.1.6 Inappropriate or Excessive Subordination\nThis happens when a sentence has too many dependent clauses, creating a confusing and tangled structure. The main idea gets lost among less important details. The solution is to restructure the sentence into several shorter sentences, giving the main ideas more prominence.\n\nExcessive: Although Bwana thought that he was prepared, he failed the examination, which meant that he had to repeat the course before he could graduate which he did not want to do because it would conflict with his summer job.\nImproved: Bwana thought that he was prepared, but he failed the examination. Therefore, he would have to repeat the course before he could graduate. He did not want to do that because it would conflict with his summer job.\n\n\n\n1.1.7 Non-Parallel Structures\nParallel structure means using the same grammatical form for items in a list or series. When this rule is broken, the sentence has a non-parallel structure, which can be awkward and confusing.\n\nNon-Parallel: I like to swim, to sail, and rowing. (The items are a mix of infinitives and a gerund).\nParallel: I like to swim, to sail, and to row. (All infinitives).\nParallel: I like swimming, sailing, and rowing. (All gerunds).\n\n\n\n1.1.8 that vs. which\nThe choice between that and which depends on whether the clause that follows is essential or non-essential to the meaning of the sentence.\n\nUse that for Restrictive (Essential) Clauses: A restrictive clause provides information that is essential to identify the noun it describes. You cannot remove it without changing the sentence’s core meaning. These clauses are not set off by commas.\n\nExample: This animal is the pink elephant that I love. (The clause that I love is essential; it specifies which pink elephant we are talking about).\n\nUse which for Non-Restrictive (Non-Essential) Clauses: A non-restrictive clause provides extra, non-essential information. It can be removed without changing the sentence’s basic meaning. These clauses are always set off by commas.\n\nExample: This animal is a pink elephant, which I love. (The clause which I love is extra information. The main point is that the animal is a pink elephant).\n\n\n\n\n1.2 Using Commas\nCommas are punctuation marks that serve two main purposes: to tell readers where to pause and to separate groups of words to ensure clarity.\n\n\n1.2.1 Commas with Clauses\n\nIndependent Clauses: Use a comma before a coordinating conjunction (For, And, Nor, But, Or, Yet, So - FANBOYS) when it joins two independent clauses.\n\nExample: The student explained her question, yet the instructor still didn't seem to understand.\n\nDependent Clauses: Do not use a comma when two clauses are joined by a subordinating conjunction (like if, since, as, when, although, while, after, before, until, because) and the independent clause comes first.\n\nExample: A cannibal does not eat clowns because they taste funny.\n\nIntroductory Dependent Clauses: Use a comma after a dependent clause when it comes before the independent clause.\n\nExample: Since clowns taste funny, a cannibal does not eat them.\n\n\n\n\n1.2.2 Commas with Transitions\nUse a comma after a transitional word or phrase (e.g., Therefore, However, For example).\n\nExample: Clowns taste funny. Therefore, a cannibal does not eat them.\nExample: Dogs have masters. However, cats have servants.\n\n\n\n1.2.3 Commas in Lists\n\nUse commas to separate three or more items in a list. The comma before the and is known as the Oxford comma and is often used for clarity.\n\nExample: My bath toys were a hairdryer, a toaster, and a radio.\n\nIf a list contains only two items, do not use a comma.\n\nExample: My bath toys were a hairdryer and a toaster.\n\n\n\n\n1.2.4 Commas for Quotations\n\nReporting Clause First: He said, \"If you cannot see the bright side of life, polish the dull side.\"\nQuotation First: \"If you can't see the bright side of life, polish the dull side,\" he said.\nQuotation Divided: \"If you can't see the bright side of life,\" he said, \"polish the dull side.\"\n\n\n\n1.2.5 Commas with Parenthetical Expressions and Appositives\n\nA parenthetical expression is an extra piece of information that can be removed without changing the sentence’s meaning or grammar. It should be set off by commas.\n\nExample: Clowns, as most researchers know, taste funny.\n\nAn appositive is a word or phrase that renames a nearby noun. It provides more information about the noun and is also set off by commas.\n\nExample: Clowns, those sweaty artists, taste funny.\n\nImportant Note: Overusing parenthetical expressions and appositives can make text less readable by separating the subject and verb. For clearer writing, consider placing them at the beginning of a sentence or in a separate clause.\n\nLess Effective: Dogs, unlike cats, have masters.\nMore Effective: Unlike cats, dogs have masters.\nLess Effective: Dogs, the humans' best friends, have masters.\nMore Effective: Dogs are the humans' best friends, so dogs have masters.\n\n\n\n\n1.2.6 Commas for Contrast\nUse a comma to separate contrasting parts of a sentence.\n\nExample: Cats have servants, not masters.\nExample: Dogs have masters, not servants.\n\n\n\n1.3 Bulleted and Numbered Lists\nLists are an effective way to organize information. The punctuation rules depend on whether the list items are complete sentences.\n\n\n1.3.1 Incomplete Sentence Items\nWhen list items are phrases or fragments that complete an introductory stem, use the following format: * Introduce the list with a colon. * Begin each item with a lowercase letter. * Place a semicolon after each item. * Use a period after the final item.\n\nExample: My parents clearly hated me because they gave me the following toys to play in the bathtub with:\n\na hairdryer;\na toaster;\na radio.\n\n\n\n\n1.3.2 Complete Sentence Items\nWhen each item in the list is a complete sentence, use this format: * Introduce the list with a colon. * Begin each item with a capital letter. * Place a period after each item.\n\nExample: Cannibals do not eat clowns due to the following reasons:\n\nClowns run fast.\nClowns taste funny.\nClowns are scary.\n\n\n\n\n\n2. Mistakes\n\nComma Splice: Using only a comma to connect two complete sentences (independent clauses). Why it’s wrong: A comma is not strong enough to join two separate thoughts. You should use a period, a semicolon, or a comma followed by a coordinating conjunction (like and, but, so).\nFused Sentence: Joining two complete sentences with no punctuation at all. Why it’s wrong: This creates a run-on sentence that is confusing and forces the reader to guess where one idea ends and the next begins.\nSentence Fragment: Punctuating an incomplete thought as if it were a full sentence. Why it’s wrong: A sentence must contain at least one independent clause with a subject and a verb to be grammatically complete.\nNon-Parallel Structure: Mixing grammatical forms when listing items in a series (e.g., running, to jump, and played). Why it’s wrong: This disrupts the rhythm and logic of the sentence, making it harder to read and understand. All items in a series should have the same grammatical structure.\nSeparating Subject and Verb with a Comma: Placing a single comma between the subject of a sentence and its main verb. Why it’s wrong: The subject and verb are the core of a sentence and should not be separated. An exception is when a non-essential phrase (set off by two commas) is inserted between them.\nConfusing that and which: Using which for an essential (restrictive) clause or that for a non-essential (non-restrictive) clause. Why it’s wrong: This can change the fundamental meaning of the sentence. that is used for information necessary to identify the noun, while which (with a comma) adds extra, non-essential information.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "3. Sentence Problems, Punctuation"
    ]
  },
  {
    "objectID": "Introduction to Programming/lec_2.html",
    "href": "Introduction to Programming/lec_2.html",
    "title": "2. Pointers, Strings, and Arrays in C",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 Memory, Values, and Addresses\nIn computing, a program’s data is stored in memory. It is helpful to visualize memory as a vast, single sequence of cells, much like a long row of mailboxes. Each cell has two key attributes:\n\nAn address: This is a unique numerical identifier for the cell’s location, similar to a mailbox number. Addresses are typically represented in hexadecimal format (e.g., 0x7ffc...).\nA value: This is the actual data stored inside the cell, like the letter inside a mailbox.\n\nEvery variable you declare in a program occupies one or more of these memory cells. The crucial concept is to distinguish between the address of a variable and the value it holds. For instance, an integer variable var1 with a value of 100 might be located at memory address 0xbff5a400.\n\n\n\n1.2 The Program Stack and Local Variables\nWhen a program runs, a region of memory called the stack is used to manage function calls. The stack operates on a last-in, first-out (LIFO) basis. Each time a function is called, a new block of memory, called a stack frame or activation record, is pushed onto the top of the stack.\nThis stack frame contains all the information needed for that specific function call, including:\n\nIts local variables (variables declared inside the function).\nThe function’s parameters.\nThe return address (where to resume execution after the function finishes).\n\nWhen the function completes, its entire stack frame is popped off the stack, and all of its local variables are destroyed. This process is automatic. This is why a local variable’s lifetime is limited to the execution of the function it was declared in.\n\n\n1.3 The Heap and Dynamic Memory Allocation\nSeparate from the stack is another memory region called the heap. The heap is used for dynamic memory allocation, which allows a program to request blocks of memory at runtime, when the exact size may not be known at compile time.\nUnlike stack variables, the lifetime of memory allocated on the heap is not tied to the scope of any function. The programmer has full control and responsibility for managing this memory.\n\nTo allocate memory on the heap, you use the malloc() function (short for memory allocate). It takes the number of bytes to allocate as an argument and returns a generic pointer (void*) to the start of that allocated block.\nTo release the memory once it’s no longer needed, you must explicitly call the free() function, passing it the same pointer.\n\nFailure to call free() results in a memory leak, where the program holds onto memory it no longer uses, which can exhaust available memory and crash the application.\n\n\n1.4 Pointers\nA pointer is a special type of variable designed to hold a memory address as its value. Instead of storing data like an integer or a character directly, it stores the location of other data. This makes pointers a powerful tool for indirect data manipulation, managing dynamic memory, and efficiently passing large data structures to functions.\nA pointer is declared by specifying the type of data it will point to, followed by an asterisk (*). For example, int* p; declares a pointer p that is intended to hold the address of an integer.\nThere are two fundamental operators for pointers:\n\nThe address-of operator (&): This unary operator, when placed before a variable name, returns its memory address. For example, &var1 gives the address where var1 is stored.\nThe dereference operator (*): This unary operator, when placed before a pointer variable, accesses the value at the address the pointer is holding. It essentially says, “go to the address stored in this pointer and get the value from there.”\n\nFor example, to make a pointer p point to an integer x, you would write p = &x;. To retrieve the value of x using the pointer, you would write *p.\nA pointer of type void* is a generic pointer that can hold the address of any data type but cannot be dereferenced directly. It must first be cast to a specific pointer type, like (int*), before the data it points to can be accessed.\n\n\n1.5 Arrays\nAn array is a data structure that stores a fixed-size, sequential collection of elements of the same data type. Imagine an array as a connected block of memory cells. You can access individual elements by their position, or index, which starts at 0.\nFor example, double balance[10]; declares an array named balance that can hold 10 elements of type double. The first element is balance[0] and the last is balance[9].\nA critical concept in C is the close relationship between arrays and pointers. The name of an array, when used in most expressions, decays into a pointer to its first element. This means that the expressions balance and &balance[0] are equivalent; both yield the memory address of the first element.\nBecause of this, you can use pointer arithmetic to navigate an array. If p is a pointer to the first element of an array, then *(p + i) is equivalent to array[i]. It’s important to note that pointer arithmetic is automatically scaled by the size of the data type. If p is an int*, p + 1 increments the address not by 1 byte, but by sizeof(int) bytes to point to the next integer in memory.\n\n\n1.6 Strings in C\nIn the C programming language, a string is not a built-in data type. Instead, a string is implemented as a one-dimensional array of characters that is terminated by a special character called the null terminator.\nThe null terminator, represented as \\0, is a character with the ASCII value 0. It serves as a marker to signal the end of the string. Standard library functions that work with strings (like printing or calculating length) rely on this null character to know where to stop processing.\nThere are two common ways to initialize a string:\n\nAs a character array: char greeting[] = {'H', 'e', 'l', 'l', 'o', '\\0'};. In this case, you must explicitly include the \\0 at the end.\nAs a string literal: char greeting[] = \"Hello\";. This is the more common method. When you use double quotes, the compiler automatically allocates enough space for the characters and appends the \\0 terminator for you. This is why “Hello” requires an array of 6 characters, not 5.\n\nFailure to properly null-terminate a character array will lead to undefined behavior when it is treated as a string, as functions will read past the end of the intended data into adjacent memory.\n\n\n1.7 Pointers to Functions\nJust as pointers can store the address of data, they can also store the address of functions. A function pointer can be used to call the function it points to indirectly. This is useful for implementing callbacks, creating function tables (e.g., for state machines), and passing functions as arguments to other functions.\nThe syntax for declaring a function pointer must match the function’s signature (return type and parameter types). For example, a pointer to a function that takes two integers and returns an integer is declared as: int (*my_func_ptr)(int, int);.\n\n\n\n2. Definitions\n\nPointer: A variable that stores the memory address of another variable or a location in memory.\nArray: A data structure consisting of a fixed-size, contiguous collection of elements of the same data type, accessed by an integer index.\nC-Style String: A sequence of characters stored in a character array and terminated by a null character (\\0).\nNull Terminator (\\0): A special character with an ASCII value of zero that marks the end of a C-style string.\nAddress-of Operator (&): A unary operator that returns the memory address of its operand (the variable it is applied to).\nDereference Operator (*): A unary operator that accesses the value stored at the memory address held by a pointer. It is used to “de-reference” the pointer to get to the data it points to.\nStack: A region of memory where local variables and function call information are stored in a last-in, first-out manner. Memory is managed automatically.\nHeap: A region of memory for dynamically allocated data, whose lifetime is controlled manually by the programmer using malloc() and free().\nDynamic Memory Allocation: The process of allocating memory from the heap at runtime.\nMemory Leak: A memory management error where a program allocates memory on the heap but fails to release it with free(), making it unusable for the remainder of the program’s execution.\nDangling Pointer: A pointer that refers to a memory location that has already been freed or is otherwise no longer valid (e.g., pointing to a local variable that has gone out of scope).\nPointer Arithmetic: The use of arithmetic operators on pointers, which is scaled by the size of the data type they point to. For example, incrementing an int pointer moves it forward by sizeof(int) bytes.\n\n\n\n3. Mistakes\n\nForgetting the Null Terminator: When manually building a string character by character in an array, it’s easy to forget to add the \\0 at the end. Why it’s wrong: Standard string functions will not know where the string ends and will continue reading into adjacent memory, causing bugs and potential crashes.\nDereferencing an Uninitialized Pointer: Declaring a pointer like int* p; and then immediately trying to use it like *p = 10;. Why it’s wrong: The pointer p holds a garbage memory address. Writing to this random location corrupts memory and leads to undefined behavior. A pointer must first be assigned a valid address.\nReturning a Pointer to a Local Variable: A function creates a local variable and returns its address. Why it’s wrong: The local variable exists on the function’s stack frame, which is destroyed upon the function’s return. The returned pointer becomes a “dangling pointer” that points to invalid memory.\nForgetting to free Dynamically Allocated Memory: Allocating memory with malloc but never calling free on the pointer. Why it’s wrong: This causes a memory leak. The program loses its only reference to the allocated heap memory, making it impossible to ever release it. Over time, this can exhaust all available memory.\nArray Out-of-Bounds Access: Trying to access an element beyond the defined size of an array, such as accessing arr[10] in an array declared as int arr[10];. Why it’s wrong: The valid indices are 0 through 9. Accessing arr[10] reads from or writes to memory that is not part of the array, which can corrupt other variables or cause the program to crash.\nConfusing Pointer Assignment with Value Assignment: Writing p = q; when you meant *p = *q;. Why it’s wrong: p = q; makes pointer p point to the same memory address as pointer q. In contrast, *p = *q; copies the value from the location pointed to by q to the location pointed to by p. These are fundamentally different operations.\n\n\n\n4. Examples\n\n4.1. Swap Two Integers using Pointers\nQuestion: Write a C function swap that takes pointers to two integers as arguments and swaps their values.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nvoid swap(int* a, int* b) {\n    // 1. Declare a temporary integer variable to hold one of the values.\n    int temp;\n\n    // 2. Dereference pointer 'a' to get its value and store it in 'temp'.\n    temp = *a;\n\n    // 3. Dereference pointer 'b' to get its value, then dereference 'a' again\n    //    to assign this value to the variable 'a' points to.\n    *a = *b;\n\n    // 4. Assign the value stored in 'temp' (the original value of *a) to the\n    //    variable that 'b' points to.\n    *b = temp;\n}\n\nint main() {\n    int x = 10;\n    int y = 20;\n    printf(\"Before swap: x = %d, y = %d\\n\", x, y);\n    swap(&x, &y); // Pass the addresses of x and y\n    printf(\"After swap: x = %d, y = %d\\n\", x, y);\n    return 0;\n}\nAnswer: The function uses a temporary variable to hold the value of the first integer. It then uses the dereference operator * to access and modify the values at the memory addresses passed into it, effectively swapping them in the main function’s scope. The output will be: Before swap: x = 10, y = 20 After swap: x = 20, y = 10\n\n\n\n4.2. Calculate String Length\nQuestion: Write a C function my_strlen that takes a constant character pointer (a string) and returns its length, excluding the null terminator. Do not use the standard strlen library function.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint my_strlen(const char* str) {\n    // 1. Initialize a counter for the length to 0.\n    int length = 0;\n\n    // 2. Use a while loop that continues as long as the character\n    //    at the current pointer location is not the null terminator ('\\0').\n    //    The expression *(str + length) is equivalent to str[length].\n    while (*(str + length) != '\\0') {\n        // 3. Increment the length counter for each non-null character.\n        length++;\n    }\n\n    // 4. Return the final count.\n    return length;\n}\n\nint main() {\n    char my_string[] = \"Hello, World!\";\n    int len = my_strlen(my_string);\n    printf(\"The length of the string is: %d\\n\", len);\n    return 0;\n}\nAnswer: The function iterates through the character array using pointer arithmetic, incrementing a counter until it encounters the \\0 character. The final count is the length of the string. The output will be: The length of the string is: 13\n\n\n\n4.3. Reverse a String in Place\nQuestion: Write a C function that takes a character array (string) and reverses it in place using pointers.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n#include &lt;string.h&gt; // For strlen to find the end\n\nvoid reverse_string(char* str) {\n    // 1. Create two pointers. 'start' points to the beginning of the string.\n    char* start = str;\n    \n    // 2. 'end' points to the last character of the string (before the null terminator).\n    char* end = str + strlen(str) - 1;\n    \n    char temp;\n\n    // 3. Loop as long as the start pointer is before the end pointer.\n    while (start &lt; end) {\n        // 4. Swap the characters pointed to by 'start' and 'end'.\n        temp = *start;\n        *start = *end;\n        *end = temp;\n\n        // 5. Move the 'start' pointer forward and the 'end' pointer backward.\n        start++;\n        end--;\n    }\n}\n\nint main() {\n    char my_string[] = \"Quarto\";\n    printf(\"Original string: %s\\n\", my_string);\n    reverse_string(my_string);\n    printf(\"Reversed string: %s\\n\", my_string);\n    return 0;\n}\nAnswer: The function uses two pointers, one at the beginning and one at the end of the string. It swaps the characters they point to and then moves the pointers toward the center until they meet or cross, effectively reversing the entire string. The output will be: Original string: Quarto Reversed string: otrauQ\n\n\n\n4.4. Sum Array Elements using a Pointer\nQuestion: Write a C function that calculates the sum of all elements in an integer array using only pointer arithmetic to iterate through the array. The function should take a pointer to the first element and the size of the array.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint sum_array(int* arr, int size) {\n    // 1. Initialize a sum variable to 0.\n    int sum = 0;\n    \n    // 2. Create a pointer 'ptr' and initialize it with the starting address of the array.\n    int* ptr = arr;\n    \n    // 3. Create a pointer 'end' that points to the memory location just after the last element.\n    //    This will serve as our loop termination condition.\n    int* end = arr + size;\n\n    // 4. Loop while the current pointer 'ptr' has not reached the 'end' pointer.\n    for (; ptr &lt; end; ptr++) {\n        // 5. Dereference the current pointer to get the integer value and add it to the sum.\n        sum += *ptr;\n    }\n\n    return sum;\n}\n\nint main() {\n    int numbers[] = {10, 20, 30, 40, 50};\n    int total = sum_array(numbers, 5);\n    printf(\"The sum of the array elements is: %d\\n\", total);\n    return 0;\n}\nAnswer: The function iterates through the array by incrementing a pointer from the start of the array to one element past the end. In each iteration, it dereferences the pointer to add the current element’s value to a running total. The output will be: The sum of the array elements is: 150\n\n\n\n4.5. Find the Maximum Value in an Array\nQuestion: Write a C function find_max that finds the largest integer in an array using pointers. The function should return a pointer to the element containing the maximum value.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint* find_max(int* arr, int size) {\n    // 1. Handle the edge case of an empty or invalid array.\n    if (arr == NULL || size &lt;= 0) {\n        return NULL;\n    }\n\n    // 2. Create a pointer to hold the address of the maximum element found so far.\n    //    Initialize it to point to the first element of the array.\n    int* max_ptr = arr;\n    \n    // 3. Loop through the array from the second element to the end.\n    for (int i = 1; i &lt; size; i++) {\n        // 4. Compare the value at the current position (arr[i]) with the value\n        //    at the current maximum's position (*max_ptr).\n        if (arr[i] &gt; *max_ptr) {\n            // 5. If the current element is larger, update max_ptr to point to it.\n            max_ptr = &arr[i];\n        }\n    }\n\n    // 6. Return the pointer to the largest element.\n    return max_ptr;\n}\n\nint main() {\n    int numbers[] = {1, 99, 23, 56, 88};\n    int* max_element_ptr = find_max(numbers, 5);\n    \n    if (max_element_ptr != NULL) {\n        printf(\"The maximum value in the array is: %d\\n\", *max_element_ptr);\n    }\n    \n    return 0;\n}\nAnswer: The function assumes the first element is the maximum, then iterates through the rest of the array. If it finds a larger element, it updates its max_ptr to point to that new maximum element. It returns the final pointer. The output will be: The maximum value in the array is: 99\n\n\n\n4.6. Create and Populate a Dynamic Array\nQuestion: Write a C program that asks the user for a size, dynamically allocates an integer array of that size on the heap, fills it with the numbers from 0 to size-1, prints the array, and then frees the memory.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt; // Required for malloc and free\n\nint main() {\n    int size;\n    printf(\"Enter the size of the array: \");\n    scanf(\"%d\", &size);\n\n    // 1. Allocate memory on the heap.\n    //    Calculate the total bytes needed: size * sizeof(int).\n    //    Cast the returned void* to an int*.\n    int* arr = (int*)malloc(size * sizeof(int));\n\n    // 2. Check if malloc was successful. It returns NULL on failure.\n    if (arr == NULL) {\n        printf(\"Memory allocation failed!\\n\");\n        return 1; // Exit with an error code\n    }\n\n    // 3. Populate the array using pointer arithmetic.\n    for (int i = 0; i &lt; size; i++) {\n        *(arr + i) = i; // Equivalent to arr[i] = i;\n    }\n\n    // 4. Print the array.\n    printf(\"Array elements: \");\n    for (int i = 0; i &lt; size; i++) {\n        printf(\"%d \", arr[i]);\n    }\n    printf(\"\\n\");\n\n    // 5. Free the dynamically allocated memory to prevent a memory leak.\n    free(arr);\n\n    return 0;\n}\nAnswer: The program uses malloc to request a block of memory from the heap based on user input. After checking for allocation success, it populates and prints the array. The crucial final step is calling free(arr) to return the memory to the system. If the user enters 5, the output will be: Enter the size of the array: 5 Array elements: 0 1 2 3 4\n\n\n\n4.7. Initialize and Print a 2D Array using Pointers\nQuestion: Declare a 2x3 integer array. Write a function that takes a pointer to this 2D array, its number of rows, and its number of columns to initialize it with sequential numbers. Write another function to print it using pointer notation.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\n// Note the function parameter: int (*arr) is a pointer to an array of 3 integers.\nvoid initialize_array(int (*arr), int rows, int cols) {\n    int count = 1;\n    // 1. Iterate through each row.\n    for (int i = 0; i &lt; rows; i++) {\n        // 2. Iterate through each column in the current row.\n        for (int j = 0; j &lt; cols; j++) {\n            // 3. Use pointer notation to access the element.\n            //    *(arr + i) is a pointer to the i-th row.\n            //    *(*(arr + i) + j) is the element at row i, col j.\n            *(*(arr + i) + j) = count++;\n        }\n    }\n}\n\nvoid print_array(int (*arr), int rows, int cols) {\n    for (int i = 0; i &lt; rows; i++) {\n        for (int j = 0; j &lt; cols; j++) {\n            // 4. Print the element using the same pointer notation.\n            printf(\"%d\\t\", *(*(arr + i) + j));\n        }\n        printf(\"\\n\");\n    }\n}\n\nint main() {\n    int my_array;\n    \n    initialize_array(my_array, 2, 3);\n    print_array(my_array, 2, 3);\n    \n    return 0;\n}\nAnswer: The key is the function signature int (*arr)[3], which correctly declares a pointer to a complete row (an array of 3 integers). Inside the functions, the expression *(*(arr + i) + j) is used. arr + i moves the pointer to the i-th row, *(arr + i) dereferences it to get a pointer to the first element of that row, adding j moves it to the j-th column, and the final dereference * gets the value. The output will be: 1 2 3\n4 5 6",
    "crumbs": [
      "Introduction to Programming",
      "2. Pointers, Strings, and Arrays in C"
    ]
  },
  {
    "objectID": "Introduction to Programming/lec_1.html",
    "href": "Introduction to Programming/lec_1.html",
    "title": "1. Compilation and Memory Management in C",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 The C Programming Language\nThe C programming language, developed by Dennis Ritchie and Brian Kernighan, is a foundational, general-purpose language celebrated for its efficiency and low-level control over system hardware. It is considered a middle-level language, bridging the gap between high-level languages that provide significant abstraction and low-level assembly languages that map directly to machine instructions. This unique position has earned it the nickname “universal assembly language.”\nA crucial concept in learning any language is the difference between syntax and semantics.\n\nSyntax refers to the set of rules that govern the structure and spelling of statements. For example, the rule that a statement must end with a semicolon is syntax.\nSemantics refers to the meaning of those statements—what the computer is instructed to do. While correct syntax is necessary for a program to compile, a deep understanding of semantics is essential for writing correct and efficient programs.\n\nKey characteristics of C include:\n\nCompiled Language: C source code must be translated by a compiler into machine code before it can be run.\nStatically Typed: Every variable has a specific data type (e.g., int, float) that is determined at compile time. However, C is not strongly typed, as it permits many kinds of type conversions.\nProcedural: Programs in C are built from procedures, also known as functions, which are blocks of code that perform specific tasks.\nSystem-Level Access: C allows for direct memory manipulation, giving the programmer the power to “exploit underlying features of the architecture.”\nUnsafe by Design: C trusts the programmer. It does not have built-in protections against common errors like accessing invalid memory locations. This “absence of restrictions” provides great power but also requires careful programming to avoid bugs and security flaws. It’s a best practice to always test code on your own machine to see how it behaves in a real environment.\n\n\n\n1.2 Essential Tools & The Compiler\nTo program in C, you only need two core tools: a text editor to write source code (e.g., VS Code, Notepad++) and a C compiler. An Integrated Development Environment (IDE) is a convenient package that bundles these tools with a debugger and other features, but it is not a requirement.\nThe most widely used C compiler is GCC (GNU Compiler Collection). Other common compilers include Clang and Microsoft Visual C++ (MSVC). To compile a program from a source file named program.c into an executable named program, you would use the following command in a terminal: gcc -Wall -o program program.c\n\ngcc: Invokes the compiler.\n-Wall: A critical flag that enables all compiler warnings. Heeding these warnings helps catch potential bugs.\n-o program: Specifies the name of the output (executable) file.\nprogram.c: The input source file.\n\n\n\n1.3 The Compilation and Linking Process\nA C program can be made of multiple source files (.c files), each known as a translation unit after being processed. Creating an executable from these files involves a multi-stage process:\n\nPreprocessing: The preprocessor scans the source code for directives (lines beginning with #). For instance, #include &lt;stdio.h&gt; copies the entire contents of the standard input/output header file into your source file.\nCompilation: The compiler translates the preprocessed code into assembly language, a human-readable representation of machine instructions.\nAssembly: The assembler converts the assembly code into pure machine code, creating an object file (with a .o or .obj extension). This file contains the code for its translation unit but is not yet runnable.\nLinking: The linker combines all object files into a single executable file. It resolves references between files (e.g., a function call in main.c to a function defined in utils.c) and incorporates necessary code from system libraries.\n\n\n\n\n\n\n\n\n\n\nFigure 1: The C compilation and linking process for multiple source files.\n\n\n\n\n\n\n\n1.4 Program Structure and Memory Model\nA running C program’s memory is organized into several distinct segments:\n\nCode Segment: Contains the program’s machine instructions. This area is typically read-only.\nStatic/Global Data Segment: Stores global and static variables, which exist for the program’s entire duration.\nHeap: A region for dynamic memory allocation. Data can be allocated on the heap at runtime (e.g., using malloc()) and must be manually deallocated (using free()). The heap grows upwards toward higher memory addresses.\nStack: Manages function calls using a Last-In, First-Out (LIFO) structure. When a function is called, a stack frame is pushed onto the stack. This frame holds the function’s parameters, return address, and local variables. When the function finishes, its frame is popped off. The stack grows downwards toward lower memory addresses.\n\n\n\n\n\n\n\n\n\n\nFigure 2: Program Memory Model showing the four main memory segments: Code, Static/Global Data, Heap, and Stack\n\n\n\n\n\n\n\n1.5 Variables, Types, Scope, and Storage Classes\nA variable is a named location in memory. More formally, a type defines a set of possible values a variable can hold, a set of operators that can be applied to it, and its relationships with other types.\nThe scope of a variable determines where in the code it is visible. C uses lexical scope, primarily defined by blocks (code enclosed in {}). A variable declared in an inner block can hide or shadow a variable with the same name from an outer block.\nStorage classes are keywords that define a variable’s lifetime (how long it exists) and linkage (its visibility across different files).\n\nauto: The default for local variables. They have a local lifetime (created and destroyed with their block) and are stored on the stack.\nstatic:\n\nLocal Static Variable: Has a static lifetime (exists for the whole program) but local scope (only visible inside its function). It is initialized only once and retains its value between function calls.\nGlobal Static Variable: Has a static lifetime and internal linkage, meaning it is only visible within the single file where it is declared.\n\nextern: A declaration that tells the compiler a global variable exists but is defined in another file. It is used to share variables across translation units. A standard global variable (without static) has external linkage by default.\n\n\n\n1.6 Debugging\nA debugger is a tool that allows you to run a program in a controlled manner to find and fix errors (bugs). It lets you pause execution, inspect the values of variables, and step through the code line by line. GDB (the GNU Debugger) is a powerful, command-line debugger for C.\nTo prepare a program for debugging, you must compile it with the -g flag, which includes debugging information in the executable: gcc -g -Wall -o program program.c\nCommon GDB commands include:\n\nrun (or r): Starts running your program.\nbreak &lt;line_number&gt; (or b): Sets a breakpoint, which pauses execution when it reaches that line.\nnext (or n): Executes the current line and moves to the next line in the same function. It steps over function calls.\nstep (or s): Executes the current line. If the line contains a function call, it steps into that function.\nprint &lt;variable&gt; (or p): Displays the current value of a variable.\ncontinue (or c): Resumes execution until the next breakpoint or the end of the program.\nquit (or q): Exits GDB.\n\n\n\n\n2. Definitions\n\nCompiler: A program that translates source code from a high-level language into low-level machine code.\nLinker: A program that combines object files and libraries into a single executable file.\nDebugger: A tool used to execute a program in a controlled way to find and diagnose errors.\nSource File: A text file (.c) containing human-readable programming instructions.\nObject File: A file (.o) containing machine code from a single source file; it is an intermediate step before linking.\nExecutable File: A file containing a complete machine code program that can be run by the operating system.\nTranslation Unit: A source file after the preprocessor has processed it; the basic unit of compilation.\nStack: A LIFO memory region for function calls, storing local variables, parameters, and return addresses.\nStack Frame: A block of memory on the stack created for a single function call.\nHeap: A memory region for dynamic allocation, managed manually by the programmer.\nSyntax vs. Semantics: Syntax is the grammatical structure of code; Semantics is its meaning and behavior.\nScope: The region of code where a variable is visible and accessible.\nLifetime: The duration for which a variable exists in memory.\nLinkage: The extent to which a variable or function can be shared across different files (translation units).\n\n\n\n4. Mistakes\n\nForgetting Semicolons (;): Every statement in C must end with a semicolon. Why it’s wrong: The semicolon is the statement terminator. Omitting it is a syntax error that prevents compilation.\nUsing Assignment (=) Instead of Comparison (==): In a condition like if (x = 5), the value 5 is assigned to x, and the expression itself evaluates to 5 (true), leading to incorrect logic. Why it’s wrong: The assignment operator changes a variable’s value, whereas the equality operator == is required to test if two values are the same.\nInteger Division Truncation: Dividing two integers results in an integer, with any fractional part discarded (e.g., 9 / 4 is 2). Why it’s wrong: This causes a loss of precision and leads to incorrect results in mathematical calculations that require floating-point accuracy.\nIgnoring Compiler Warnings: Treating warnings as non-critical and ignoring them. Why it’s wrong: Warnings often flag legally-valid code that is logically flawed or relies on undefined behavior (e.g., using an uninitialized variable). They are frequently indicators of hidden bugs.\nForgetting to Include Header Files: Using library functions like printf without #include &lt;stdio.h&gt;. Why it’s wrong: Header files provide function declarations, which tell the compiler the function’s signature (name, parameters, return type). Without this, the compiler cannot verify the function call and will issue an error.\nAccessing an Array Out of Bounds: Accessing an element outside the defined range of an array, such as arr[10] in an array declared as int arr[10] (valid indices are 0 through 9). Why it’s wrong: C does not perform bounds checking. This action reads from or writes to an arbitrary memory location, leading to undefined behavior that can corrupt data or crash the program.\n\n\n\n5. Examples\n\n5.1. Basic “Hello, World!” Program\nQuestion: Write, compile, and describe the output of a standard “Hello, World!” program in C.\n\n\nClick to see the solution\n\n\nWrite the C code and save it in a file named hello.c. The #include &lt;stdio.h&gt; directive includes the standard library for input/output functions like printf. The main function is the mandatory entry point for execution.\n#include &lt;stdio.h&gt;\n\nint main() {\n    printf(\"Hello, World!\\n\");\n    return 0; // Indicates successful execution\n}\nCompile the code using GCC, enabling warnings and specifying the output file name. sh     gcc -Wall -o hello hello.c\nRun the executable from the terminal. sh     ./hello\n\nAnswer: The program will print the following text to the console: Hello, World!\n\n\n\n5.2. Variable Declaration and Arithmetic\nQuestion: Write a C program that declares two integer variables, a and b, initializes them to 12 and 5, and then prints their sum, difference, product, and quotient.\n\n\nClick to see the solution\n\n\nInclude the standard I/O header for the printf function.\nDefine the main function.\nDeclare and initialize two int variables.\nUse printf for each operation. The %d format specifier acts as a placeholder for an integer value. The \\n character adds a newline for readability.\n#include &lt;stdio.h&gt;\n\nint main() {\n    int a = 12;\n    int b = 5;\n\n    printf(\"Sum: %d\\n\", a + b);\n    printf(\"Difference: %d\\n\", a - b);\n    printf(\"Product: %d\\n\", a * b);\n    printf(\"Quotient (Integer): %d\\n\", a / b); // Note: Integer division\n\n    return 0;\n}\n\nAnswer: The output of the program will be:\nSum: 17\nDifference: 7\nProduct: 60\nQuotient (Integer): 2\n\n\n\n5.3. Integer vs. Floating-Point Division\nQuestion: Write a program to show the difference between integer division and floating-point division using the numbers 9 and 4.\n\n\nClick to see the solution\n\n\nPerform integer division. Both operands are integers, so the result is truncated.\nPerform floating-point division. To trigger this, at least one of the operands must be a floating-point type. We can achieve this by writing 9.0 or by casting one of the integer variables to a float: (float)int_a.\nPrint both results using the correct format specifiers: %d for the integer result and %f for the float result.\n#include &lt;stdio.h&gt;\n\nint main() {\n    int int_a = 9;\n    int int_b = 4;\n\n    // Case 1: Integer division\n    int int_result = int_a / int_b;\n    printf(\"Integer Division (9 / 4): %d\\n\", int_result);\n\n    // Case 2: Floating-point division\n    float float_result = (float)int_a / int_b;\n    printf(\"Floating-Point Division ((float)9 / 4): %f\\n\", float_result);\n\n    return 0;\n}\n\nAnswer: The program’s output clearly shows the truncation:\nInteger Division (9 / 4): 2\nFloating-Point Division ((float)9 / 4): 2.250000\n\n\n\n5.4. Scope and Variable Shadowing\nQuestion: Predict the output of the following C code and explain the reasoning based on variable scope.\n#include &lt;stdio.h&gt;\n\nint main() {\n    int value = 100; // Outer 'value'\n\n    printf(\"1. At outer level, value is: %d\\n\", value);\n\n    { // Start of a new inner block\n        int value = 200; // Inner 'value', shadows the outer one\n        printf(\"2. Inside inner block, value is: %d\\n\", value);\n    } // Inner block ends, inner 'value' is destroyed\n\n    printf(\"3. Back at outer level, value is: %d\\n\", value);\n\n    return 0;\n}\n\n\nClick to see the solution\n\n\nFirst printf: This line is in the scope of the outer main block. It accesses the variable value declared in this scope, which is 100.\nSecond printf: This line is inside an inner block. A new, separate variable also named value is declared here and initialized to 200. Within this block, this inner variable shadows the outer one. Any reference to value here refers to the inner variable, so 200 is printed.\nEnd of Inner Block: When the closing brace } is reached, the inner block’s scope ends. All variables declared within it, including the inner value, are destroyed and cease to exist.\nThird printf: Execution is now back in the outer main block’s scope. The only value visible here is the original one, which was never modified. Its value is still 100.\n\nAnswer: The output will be:\n1. At outer level, value is: 100\n2. Inside inner block, value is: 200\n3. Back at outer level, value is: 100\n\n\n\n5.5. Using static to Retain State in a Function\nQuestion: Create a function that counts how many times it has been called. Use a static local variable for the counter. Demonstrate its behavior by calling it multiple times from main.\n\n\nClick to see the solution\n\n\nDefine a function count_calls.\nInside it, declare static int counter = 0;. The static keyword ensures that counter is initialized to 0 only once, when the program starts. Its value will be preserved across function calls.\nIncrement and print counter.\nIn main, call the function in a loop to see the counter increase.\n#include &lt;stdio.h&gt;\n\nvoid count_calls() {\n    // This variable is initialized only once and retains its value.\n    static int counter = 0;\n    counter++;\n    printf(\"Function has been called %d time(s).\\n\", counter);\n}\n\nint main() {\n    printf(\"Calling the function...\\n\");\n    count_calls();\n    count_calls();\n    count_calls();\n\n    return 0;\n}\n\nAnswer: The output shows that the counter’s state persists between calls:\nCalling the function...\nFunction has been called 1 time(s).\nFunction has been called 2 time(s).\nFunction has been called 3 time(s).\n\n\n\n5.6. Simple while Loop\nQuestion: Write a C program that uses a while loop to print the numbers from 5 down to 1.\n\n\nClick to see the solution\n\n\nInclude stdio.h.\nIn main, declare an integer counter variable and initialize it to 5.\nCreate a while loop with the condition that the counter must be greater than 0.\nInside the loop, print the counter’s current value.\nDecrement the counter (counter--). This step is essential to prevent an infinite loop.\n#include &lt;stdio.h&gt;\n\nint main() {\n    int counter = 5; // Initialize counter\n\n    while (counter &gt; 0) {\n        printf(\"%d\\n\", counter);\n        counter--; // Decrement counter to move toward the exit condition\n    }\n\n    return 0;\n}\n\nAnswer: The program will produce the following output:\n5\n4\n3\n2\n1\n\n\n\n5.7. Basic Debugging with GDB\nQuestion: The following program is supposed to calculate the sum of integers from 1 to 3, but it contains a bug. Explain how to use GDB to find it.\n// File: sum_bug.c\n#include &lt;stdio.h&gt;\n\nint main() {\n    int sum = 0;\n    int i;\n    for (i = 1; i &lt; 3; i++) { // Bug is here!\n        sum = sum + i;\n    }\n    printf(\"Sum is: %d\\n\", sum); // Expected: 6, Actual: 3\n    return 0;\n}\n\n\nClick to see the solution\n\n\nCompile with Debug Symbols: First, compile the program with the -g flag to include information GDB needs. sh     gcc -g -o sum_bug sum_bug.c\nStart GDB: Launch GDB with the executable file as an argument. sh     gdb ./sum_bug\nSet a Breakpoint: The interesting logic is inside the loop. Let’s set a breakpoint at the line where the sum is calculated (line 7) to watch how sum changes. gdb     (gdb) break 7\nRun the Program: Start the program inside GDB. It will run until it hits our breakpoint. gdb     (gdb) run\nInspect Variables: The program is now paused at line 7. Let’s check the values of i and sum. gdb     (gdb) print i     $1 = 1     (gdb) print sum     $2 = 0\nContinue Execution: Let the loop run one more time. gdb     (gdb) continue The program stops at the breakpoint again. Let’s inspect the variables now. gdb     (gdb) print i     $3 = 2     (gdb) print sum     $4 = 1\nContinue Again: gdb     (gdb) continue This time, the program finishes and prints “Sum is: 3”. It never stopped at the breakpoint for i = 3.\nIdentify the Bug: By stepping through the loop, we saw it execute for i = 1 and i = 2, but it terminated before i = 3. The bug is in the loop condition i &lt; 3. To include the number 3 in the sum, the condition must be i &lt;= 3.\n\nAnswer: GDB helps find the bug by allowing us to pause the program and observe that the loop terminates one iteration too early because of the incorrect condition i &lt; 3. The fix is to change it to i &lt;= 3.",
    "crumbs": [
      "Introduction to Programming",
      "1. Compilation and Memory Management in C"
    ]
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_2.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_2.html",
    "title": "2. Inner Product, Dot Product, Orthogonality, and Projections",
    "section": "",
    "text": "1. Summary\n\n1.1 The Inner Product\nAn inner product is a generalized concept that defines a way to multiply two vectors to produce a scalar (a single number). It is a function that takes two vectors and returns a single value, and it allows us to introduce geometric concepts like length and angle into abstract vector spaces. The standard dot product is the most common example of an inner product. For a function to be considered an inner product, it must satisfy four key properties for any vectors \\(\\vec{u}\\), \\(\\vec{v}\\), \\(\\vec{w}\\) and any scalar \\(c\\):\n\nSymmetry: The order of vectors doesn’t matter. \\(\\langle \\vec{u}, \\vec{v} \\rangle = \\langle \\vec{v}, \\vec{u} \\rangle\\).\nLinearity: A scalar multiple can be factored out. \\(\\langle c\\vec{u}, \\vec{v} \\rangle = c\\langle \\vec{u}, \\vec{v} \\rangle\\).\nAdditivity: The product distributes over vector addition. \\(\\langle \\vec{u} + \\vec{w}, \\vec{v} \\rangle = \\langle \\vec{u}, \\vec{v} \\rangle + \\langle \\vec{w}, \\vec{v} \\rangle\\).\nPositive Definiteness: The inner product of a vector with itself is always non-negative, and it is zero if and only if the vector is the zero vector. \\(\\langle \\vec{v}, \\vec{v} \\rangle \\ge 0\\) and \\(\\langle \\vec{v}, \\vec{v} \\rangle = 0 \\iff \\vec{v} = \\vec{0}\\).\n\nA vector space equipped with an inner product is called an inner product space.\n\n\n1.2 The Dot Product\nThe dot product (also known as the Euclidean inner product) is the standard way to combine two vectors to produce a scalar. It has two primary definitions: an algebraic one and a geometric one. Both yield the same result.\n\n\n1.3 Algebraic Definition of the Dot Product\nThe algebraic definition is calculated by multiplying the corresponding components of two vectors and summing the results. For two vectors \\(\\vec{u} = (u_1, u_2, \\dots, u_n)\\) and \\(\\vec{v} = (v_1, v_2, \\dots, v_n)\\) in \\(\\mathbb{R}^n\\), the dot product is: \\[ \\vec{u} \\cdot \\vec{v} = u_1v_1 + u_2v_2 + \\dots + u_nv_n = \\sum_{i=1}^{n} u_i v_i \\] For example, in 3D space, if \\(\\vec{a} = (a_1, a_2, a_3)\\) and \\(\\vec{b} = (b_1, b_2, b_3)\\), then \\(\\vec{a} \\cdot \\vec{b} = a_1b_1 + a_2b_2 + a_3b_3\\).\n\n\n1.4 Geometric Definition and Connection to the Law of Cosines\nThe geometric definition relates the dot product to the magnitudes (lengths) of the vectors and the angle between them. For two vectors \\(\\vec{v}\\) and \\(\\vec{w}\\), with an angle \\(\\theta\\) between them: \\[ \\vec{v} \\cdot \\vec{w} = ||\\vec{v}|| \\cdot ||\\vec{w}|| \\cos(\\theta) \\] Here, \\(||\\vec{v}||\\) denotes the magnitude of vector \\(\\vec{v}\\). This definition is powerful because it connects a simple algebraic operation to a fundamental geometric property (the angle) and helps us understand how “aligned” two vectors are.  This formula can be derived directly from the Law of Cosines. Consider a triangle formed by vectors \\(\\vec{v}\\), \\(\\vec{w}\\), and their difference \\(\\vec{v}-\\vec{w}\\). The Law of Cosines states: \\[ ||\\vec{v}-\\vec{w}||^2 = ||\\vec{v}||^2 + ||\\vec{w}||^2 - 2||\\vec{v}||||\\vec{w}||\\cos(\\theta) \\] Expanding the left side using the dot product gives \\(||\\vec{v}-\\vec{w}||^2 = (\\vec{v}-\\vec{w})\\cdot(\\vec{v}-\\vec{w}) = ||\\vec{v}||^2 - 2(\\vec{v}\\cdot\\vec{w}) + ||\\vec{w}||^2\\). By equating the two expressions, we arrive at the geometric definition of the dot product.\nThe sign of the dot product tells us about the angle \\(\\theta\\):\n\nIf \\(\\vec{v} \\cdot \\vec{w} &gt; 0\\), then \\(\\cos(\\theta) &gt; 0\\), so the angle is acute (\\(0^\\circ \\le \\theta &lt; 90^\\circ\\)).\nIf \\(\\vec{v} \\cdot \\vec{w} &lt; 0\\), then \\(\\cos(\\theta) &lt; 0\\), so the angle is obtuse (\\(90^\\circ &lt; \\theta \\le 180^\\circ\\)).\nIf \\(\\vec{v} \\cdot \\vec{w} = 0\\), then \\(\\cos(\\theta) = 0\\), so the angle is right (\\(\\theta = 90^\\circ\\)).\n\n\n\n1.5 Orthogonality\nTwo non-zero vectors are orthogonal (perpendicular) if and only if their dot product is zero. This is one of the most important applications of the dot product. \\[ \\vec{v} \\perp \\vec{w} \\iff \\vec{v} \\cdot \\vec{w} = 0 \\]\n\n\n1.6 Vector Norm and Its Properties\nThe dot product defines the norm (or length) of a vector, which is called the induced norm. The norm of a vector \\(\\vec{v}\\) is the square root of the dot product of the vector with itself. \\[ ||\\vec{v}|| = \\sqrt{\\vec{v} \\cdot \\vec{v}} \\] From the algebraic definition, for \\(\\vec{v} = (v_1, v_2, v_3)\\), this is the familiar distance formula: \\(||\\vec{v}|| = \\sqrt{v_1^2 + v_2^2 + v_3^2}\\). This norm satisfies several key properties:\n\nNon-negativity: \\(||\\vec{v}|| \\ge 0\\).\nPoint-separating: \\(||\\vec{v}|| = 0 \\iff \\vec{v} = \\vec{0}\\).\nAbsolute homogeneity: \\(||c\\vec{v}|| = |c| \\cdot ||\\vec{v}||\\).\nTriangle Inequality: \\(||\\vec{u} + \\vec{v}|| \\le ||\\vec{u}|| + ||\\vec{v}||\\). This states that the length of the sum of two vectors is less than or equal to the sum of their individual lengths.\n\n\n\n1.7 Key Inequalities and Identities\nThe properties of the inner product lead to several fundamental results:\n\nCauchy-Schwarz Inequality: This inequality provides an upper bound on the magnitude of the dot product of two vectors: \\(|\\vec{v} \\cdot \\vec{w}| \\le ||\\vec{v}|| \\cdot ||\\vec{w}||\\). It is one of the most important inequalities in mathematics.\nParallelogram Law: This law relates the lengths of the sides of a parallelogram to the lengths of its diagonals: \\(||\\vec{a} + \\vec{b}||^2 + ||\\vec{a} - \\vec{b}||^2 = 2(||\\vec{a}||^2 + ||\\vec{b}||^2)\\).\n\n\n\n1.8 Projections\nProjections describe how much of one vector points in the direction of another, essentially casting a “shadow”.\n\n1.8.1 Scalar Projection\nThe scalar projection of vector \\(\\vec{v}\\) onto vector \\(\\vec{w}\\) is the signed length of the component of \\(\\vec{v}\\) that lies in the direction of \\(\\vec{w}\\). \\[ \\text{comp}_{\\vec{w}}(\\vec{v}) = \\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{w}||} \\] This value is a scalar. It is positive if the projection points in the same direction as \\(\\vec{w}\\) and negative if it points in the opposite direction.\n\n\n1.8.2 Vector Projection\nThe vector projection is the actual vector that represents the shadow. It has the magnitude of the scalar projection and the direction of \\(\\vec{w}\\).  \\[ \\text{proj}_{\\vec{w}}(\\vec{v}) = \\left( \\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{w}||^2} \\right) \\vec{w} = \\left( \\frac{\\vec{v} \\cdot \\vec{w}}{\\vec{w} \\cdot \\vec{w}} \\right) \\vec{w} \\] The term in parentheses is a scalar that scales the vector \\(\\vec{w}\\).\n\n\n\n1.9 Decomposing a Vector\nAny vector \\(\\vec{v}\\) can be uniquely decomposed into two orthogonal components relative to another non-zero vector \\(\\vec{w}\\): 1. A component parallel to \\(\\vec{w}\\): \\(\\vec{v}_{||} = \\text{proj}_{\\vec{w}}(\\vec{v})\\). 2. A component orthogonal to \\(\\vec{w}\\): \\(\\vec{v}_{\\perp} = \\vec{v} - \\vec{v}_{||}\\). The sum of these two components gives back the original vector: \\(\\vec{v} = \\vec{v}_{||} + \\vec{v}_{\\perp}\\).\n\n\n1.10 Direction Cosines\nFor a vector \\(\\vec{a} = (a_1, a_2, a_3)\\) in 3D space, the angles it forms with the positive x, y, and z axes are denoted \\(\\alpha\\), \\(\\beta\\), and \\(\\gamma\\), respectively. The cosines of these angles are called direction cosines and can be found using the dot product:\n\n\\(\\cos(\\alpha) = \\frac{\\vec{a} \\cdot \\vec{i}}{||\\vec{a}||} = \\frac{a_1}{||\\vec{a}||}\\)\n\\(\\cos(\\beta) = \\frac{\\vec{a} \\cdot \\vec{j}}{||\\vec{a}||} = \\frac{a_2}{||\\vec{a}||}\\)\n\\(\\cos(\\gamma) = \\frac{\\vec{a} \\cdot \\vec{k}}{||\\vec{a}||} = \\frac{a_3}{||\\vec{a}||}\\) These cosines are related by the identity: \\[ \\cos^2(\\alpha) + \\cos^2(\\beta) + \\cos^2(\\gamma) = 1 \\]\n\n\n\n\n2. Definitions\n\nInner Product: A function that takes two vectors and produces a scalar, satisfying the properties of symmetry, linearity, additivity, and positive definiteness.\nInner Product Space: A vector space that has an inner product defined on it.\nDot Product: The most common type of inner product, calculated as the sum of the products of corresponding vector components (\\(\\sum u_i v_i\\)).\nOrthogonal Vectors: Two vectors whose dot product is zero, indicating they are perpendicular to each other.\nNorm (Vector Length): The magnitude of a vector, calculated as the square root of the dot product of the vector with itself (\\(||\\vec{v}|| = \\sqrt{\\vec{v} \\cdot \\vec{v}}\\)).\nScalar Projection: The signed length of the projection of one vector onto another, resulting in a scalar value.\nVector Projection: The vector that represents the “shadow” of one vector onto another. It is parallel to the vector being projected upon.\nCauchy-Schwarz Inequality: A fundamental theorem stating that the absolute value of the dot product of two vectors is less than or equal to the product of their norms.\nTriangle Inequality: A property of norms stating that the norm of a sum of two vectors is no greater than the sum of their individual norms.\nParallelogram Law: An identity relating the sum of the squares of the lengths of a parallelogram’s sides to the sum of the squares of its diagonals.\n\n\n\n3. Formulas\n\nAlgebraic Dot Product: \\(\\vec{u} \\cdot \\vec{v} = \\sum_{i=1}^{n} u_i v_i\\)\nGeometric Dot Product: \\(\\vec{v} \\cdot \\vec{w} = ||\\vec{v}|| \\cdot ||\\vec{w}|| \\cos(\\theta)\\)\nAngle Between Vectors: \\(\\theta = \\arccos\\left(\\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{v}|| \\cdot ||\\vec{w}||}\\right)\\)\nVector Norm: \\(||\\vec{v}|| = \\sqrt{\\vec{v} \\cdot \\vec{v}}\\)\nScalar Projection: \\(\\text{comp}_{\\vec{w}}(\\vec{v}) = \\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{w}||}\\)\nVector Projection: \\(\\text{proj}_{\\vec{w}}(\\vec{v}) = \\left(\\frac{\\vec{v} \\cdot \\vec{w}}{\\vec{w} \\cdot \\vec{w}}\\right) \\vec{w}\\)\nCauchy-Schwarz Inequality: \\(|\\vec{v} \\cdot \\vec{w}| \\le ||\\vec{v}|| \\cdot ||\\vec{w}||\\)\nTriangle Inequality: \\(||\\vec{u} + \\vec{v}|| \\le ||\\vec{u}|| + ||\\vec{v}||\\)\nParallelogram Law: \\(||\\vec{a} + \\vec{b}||^2 + ||\\vec{a} - \\vec{b}||^2 = 2(||\\vec{a}||^2 + ||\\vec{b}||^2)\\)\nDirection Cosines Identity: \\(\\cos^2(\\alpha) + \\cos^2(\\beta) + \\cos^2(\\gamma) = 1\\)\n\n\n\n4. Mistakes\n\nDot product gives a vector: The result of a dot product is always a scalar (a single number), not another vector. Why it’s wrong: The operation is defined as a sum of products of components, which always resolves to a single numerical value.\nAssuming \\(\\vec{a} \\cdot \\vec{b} = \\vec{a} \\cdot \\vec{c}\\) implies \\(\\vec{b} = \\vec{c}\\): This is not true. Why it’s wrong: This is known as the cancellation law, and it does not hold for dot products. The dot product involves the angle between vectors. If \\(\\vec{a}\\) is perpendicular to the vector \\((\\vec{b}-\\vec{c})\\), then \\(\\vec{a}\\cdot(\\vec{b}-\\vec{c})=0\\), which means \\(\\vec{a}\\cdot\\vec{b} = \\vec{a}\\cdot\\vec{c}\\) even if \\(\\vec{b} \\ne \\vec{c}\\).\nConfusing vector projection with scalar projection: One is a vector, the other is a scalar (a length). Why it’s wrong: The formulas are distinct. The vector projection formula results in a vector by scaling the direction vector, while the scalar projection formula only calculates the signed length.\nUsing \\(||\\vec{w}||\\) in the denominator for vector projection: The denominator in the vector projection formula is \\(||\\vec{w}||^2\\) (or \\(\\vec{w} \\cdot \\vec{w}\\)). Why it’s wrong: The term \\(\\frac{\\vec{v} \\cdot \\vec{w}}{||\\vec{w}||^2}\\) is the scalar needed to correctly scale the direction vector \\(\\vec{w}\\) to get the projected vector. Using just \\(||\\vec{w}||\\) produces a vector with the wrong magnitude.\nForgetting the square root when calculating the norm: The norm is \\(||\\vec{v}|| = \\sqrt{\\vec{v} \\cdot \\vec{v}}\\), not just \\(\\vec{v} \\cdot \\vec{v}\\). Why it’s wrong: \\(\\vec{v} \\cdot \\vec{v}\\) gives the squared length. To find the actual length, you must take the square root, consistent with the Pythagorean theorem.\nAssuming \\(||\\vec{u}+\\vec{v}|| = ||\\vec{u}||+||\\vec{v}||\\) always: This is only true if the vectors \\(\\vec{u}\\) and \\(\\vec{v}\\) point in the same direction (i.e., one is a non-negative scalar multiple of the other). Why it’s wrong: This is a misunderstanding of the Triangle Inequality, which states \\(||\\vec{u} + \\vec{v}|| \\le ||\\vec{u}|| + ||\\vec{v}||\\). The equality case is rare.\n\n\n\n5. Examples\n\n5.1. Using Dot Product Properties\nQuestion: Given that vectors \\(\\vec{a}\\), \\(\\vec{b}\\), and \\(\\vec{c}\\) all have a length of 3 and that their sum is the zero vector (\\(\\vec{a} + \\vec{b} + \\vec{c} = \\vec{0}\\)), find the value of \\(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}\\).\n\n\nClick to see the solution\n\n\nStart with the given vector sum: \\[ \\vec{a} + \\vec{b} + \\vec{c} = \\vec{0} \\]\nTake the dot product of the equation with itself: Since the vector is the zero vector, its dot product with itself is 0. \\[ (\\vec{a} + \\vec{b} + \\vec{c}) \\cdot (\\vec{a} + \\vec{b} + \\vec{c}) = 0 \\]\nExpand the dot product using its distributive property: \\[ \\vec{a}\\cdot\\vec{a} + \\vec{a}\\cdot\\vec{b} + \\vec{a}\\cdot\\vec{c} + \\vec{b}\\cdot\\vec{a} + \\vec{b}\\cdot\\vec{b} + \\vec{b}\\cdot\\vec{c} + \\vec{c}\\cdot\\vec{a} + \\vec{c}\\cdot\\vec{b} + \\vec{c}\\cdot\\vec{c} = 0 \\]\nSimplify using norm notation and the symmetry of the dot product: Recall that \\(\\vec{v}\\cdot\\vec{v} = ||\\vec{v}||^2\\) and \\(\\vec{u}\\cdot\\vec{v} = \\vec{v}\\cdot\\vec{u}\\). \\[ ||\\vec{a}||^2 + ||\\vec{b}||^2 + ||\\vec{c}||^2 + 2(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}) = 0 \\]\nSubstitute the given magnitudes: We know \\(||\\vec{a}|| = ||\\vec{b}|| = ||\\vec{c}|| = 3\\). \\[ 3^2 + 3^2 + 3^2 + 2(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}) = 0 \\] \\[ 9 + 9 + 9 + 2(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}) = 0 \\] \\[ 27 + 2(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}) = 0 \\]\nSolve for the desired expression: \\[ 2(\\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a}) = -27 \\] \\[ \\vec{a} \\cdot \\vec{b} + \\vec{b} \\cdot \\vec{c} + \\vec{c} \\cdot \\vec{a} = -\\frac{27}{2} \\]\n\nAnswer: The value is -13.5.\n\n\n\n5.2. Find the Angle Between Two Vectors\nQuestion: Find the angle \\(\\theta\\) between vectors \\(\\vec{a} = \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\end{pmatrix}\\) and \\(\\vec{b} = \\begin{pmatrix} -5 \\\\ -1 \\\\ -1 \\end{pmatrix}\\).\n\n\nClick to see the solution\n\n\nCalculate the dot product \\(\\vec{a} \\cdot \\vec{b}\\): \\[ \\vec{a} \\cdot \\vec{b} = (1)(-5) + (-1)(-1) + (1)(-1) = -5 + 1 - 1 = -5 \\]\nCalculate the magnitude of \\(\\vec{a}\\): \\[ ||\\vec{a}|| = \\sqrt{1^2 + (-1)^2 + 1^2} = \\sqrt{1 + 1 + 1} = \\sqrt{3} \\]\nCalculate the magnitude of \\(\\vec{b}\\): \\[ ||\\vec{b}|| = \\sqrt{(-5)^2 + (-1)^2 + (-1)^2} = \\sqrt{25 + 1 + 1} = \\sqrt{27} = 3\\sqrt{3} \\]\nUse the angle formula: \\[ \\cos(\\theta) = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{a}|| \\cdot ||\\vec{b}||} = \\frac{-5}{\\sqrt{3} \\cdot 3\\sqrt{3}} = \\frac{-5}{3 \\cdot 3} = -\\frac{5}{9} \\]\nSolve for \\(\\theta\\): \\[ \\theta = \\arccos\\left(-\\frac{5}{9}\\right) \\approx 123.75^\\circ \\]\n\nAnswer: The angle is approximately \\(123.75^\\circ\\).\n\n\n\n5.3. Proving Orthogonality\nQuestion: Prove that for any three vectors \\(\\vec{a}\\), \\(\\vec{b}\\), and \\(\\vec{c}\\), the vector \\(\\vec{v} = \\vec{b}(\\vec{a}\\cdot\\vec{c}) - \\vec{c}(\\vec{a}\\cdot\\vec{b})\\) is perpendicular to vector \\(\\vec{a}\\).\n\n\nClick to see the solution\n\n\nRecall the condition for orthogonality: Two vectors are perpendicular if their dot product is zero. We need to show that \\(\\vec{a} \\cdot \\vec{v} = 0\\).\nSet up the dot product: \\[ \\vec{a} \\cdot \\vec{v} = \\vec{a} \\cdot [\\vec{b}(\\vec{a}\\cdot\\vec{c}) - \\vec{c}(\\vec{a}\\cdot\\vec{b})] \\]\nApply the distributive property of the dot product: \\[ \\vec{a} \\cdot \\vec{v} = \\vec{a} \\cdot (\\vec{b}(\\vec{a}\\cdot\\vec{c})) - \\vec{a} \\cdot (\\vec{c}(\\vec{a}\\cdot\\vec{b})) \\]\nFactor out the scalar terms: Remember that \\((\\vec{a}\\cdot\\vec{c})\\) and \\((\\vec{a}\\cdot\\vec{b})\\) are scalars. We can rearrange the scalar multiples. \\[ \\vec{a} \\cdot \\vec{v} = (\\vec{a} \\cdot \\vec{b})(\\vec{a}\\cdot\\vec{c}) - (\\vec{a} \\cdot \\vec{c})(\\vec{a}\\cdot\\vec{b}) \\]\nSimplify the expression: The two terms are identical, so their difference is zero. \\[ \\vec{a} \\cdot \\vec{v} = 0 \\]\nConclusion: Since the dot product is zero, the vectors \\(\\vec{a}\\) and \\(\\vec{v}\\) are perpendicular.\n\nAnswer: The dot product simplifies to 0, which proves the vectors are perpendicular.\n\n\n\n5.4. Find an Unknown Component for Orthogonality\nQuestion: Find the value(s) of \\(x\\) such that the vectors \\(\\vec{u} = (x, -1, 3)\\) and \\(\\vec{v} = (x, 5, 1)\\) are orthogonal.\n\n\nClick to see the solution\n\n\nSet the dot product to zero: For the vectors to be orthogonal, their dot product must be zero. \\[ \\vec{u} \\cdot \\vec{v} = (x)(x) + (-1)(5) + (3)(1) = 0 \\]\nSimplify the equation: \\[ x^2 - 5 + 3 = 0 \\] \\[ x^2 - 2 = 0 \\]\nSolve for \\(x\\): \\[ x^2 = 2 \\] \\[ x = \\pm\\sqrt{2} \\]\n\nAnswer: The values for \\(x\\) are \\(\\sqrt{2}\\) and \\(-\\sqrt{2}\\).\n\n\n\n5.5. Calculate Vector and Scalar Projection\nQuestion: Find the vector and scalar projection of \\(\\vec{a} = (1, -2, 4)\\) onto \\(\\vec{b} = (2, 1, -2)\\).\n\n\nClick to see the solution\n\n\\begin{tikzpicture}\n    % 3D axes\n    \\draw[-&gt;] (0,0,0) -- (5,0,0) node[anchor=north east]{$x$};\n    \\draw[-&gt;] (0,0,0) -- (0,5,0) node[anchor=north west]{$y$};\n    \\draw[-&gt;] (0,0,0) -- (0,0,5) node[anchor=south]{$z$};\n\n    % Vectors\n    \\draw[-&gt;, thick, blue] (0,0,0) -- (1,-2,4) node[anchor=west] {$\\vec{a}$};\n    \\draw[-&gt;, thick, red] (0,0,0) -- (2,1,-2) node[anchor=north] {$\\vec{b}$};\n\\end{tikzpicture}\n\nCalculate the dot product \\(\\vec{a} \\cdot \\vec{b}\\): \\[ \\vec{a} \\cdot \\vec{b} = (1)(2) + (-2)(1) + (4)(-2) = 2 - 2 - 8 = -8 \\]\nCalculate the magnitude of \\(\\vec{b}\\) for the scalar projection: \\[ ||\\vec{b}|| = \\sqrt{2^2 + 1^2 + (-2)^2} = \\sqrt{4 + 1 + 4} = \\sqrt{9} = 3 \\]\nApply the scalar projection formula: \\[ \\text{comp}_{\\vec{b}}(\\vec{a}) = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||} = \\frac{-8}{3} \\]\nCalculate the squared magnitude of \\(\\vec{b}\\) for the vector projection: \\[ ||\\vec{b}||^2 = 3^2 = 9 \\quad (\\text{or } \\vec{b} \\cdot \\vec{b} = 9) \\]\nApply the vector projection formula: \\[ \\text{proj}_{\\vec{b}}(\\vec{a}) = \\left(\\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||^2}\\right) \\vec{b} = \\left(\\frac{-8}{9}\\right) (2, 1, -2) \\]\nDistribute the scalar: \\[ \\text{proj}_{\\vec{b}}(\\vec{a}) = \\left(-\\frac{16}{9}, -\\frac{8}{9}, \\frac{16}{9}\\right) \\]\n\nAnswer: The scalar projection is \\(-\\frac{8}{3}\\) and the vector projection is \\(\\left(-\\frac{16}{9}, -\\frac{8}{9}, \\frac{16}{9}\\right)\\).\n\n\n\n5.6. Decompose a Vector\nQuestion: Decompose the vector \\(\\vec{a} = (5, 1, -3)\\) into two vectors, one parallel (\\(\\vec{a}_{||}\\)) and one orthogonal (\\(\\vec{a}_{\\perp}\\)) to \\(\\vec{b} = (1, 2, 2)\\).\n\n\nClick to see the solution\n\n\nFind the parallel component by calculating the vector projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\): \\[ \\vec{a} \\cdot \\vec{b} = (5)(1) + (1)(2) + (-3)(2) = 5 + 2 - 6 = 1 \\] \\[ \\vec{b} \\cdot \\vec{b} = 1^2 + 2^2 + 2^2 = 1 + 4 + 4 = 9 \\] \\[ \\vec{a}_{||} = \\text{proj}_{\\vec{b}}(\\vec{a}) = \\left(\\frac{1}{9}\\right) (1, 2, 2) = \\left(\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9}\\right) \\]\nFind the orthogonal component by subtracting the parallel component from the original vector: \\[ \\vec{a}_{\\perp} = \\vec{a} - \\vec{a}_{||} = (5, 1, -3) - \\left(\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9}\\right) \\]\nPerform the vector subtraction: \\[ \\vec{a}_{\\perp} = \\left(5 - \\frac{1}{9}, 1 - \\frac{2}{9}, -3 - \\frac{2}{9}\\right) = \\left(\\frac{45-1}{9}, \\frac{9-2}{9}, \\frac{-27-2}{9}\\right) = \\left(\\frac{44}{9}, \\frac{7}{9}, -\\frac{29}{9}\\right) \\]\n(Optional) Verify orthogonality: Check that \\(\\vec{a}_{\\perp} \\cdot \\vec{b} = 0\\). \\[ \\left(\\frac{44}{9}, \\frac{7}{9}, -\\frac{29}{9}\\right) \\cdot (1, 2, 2) = \\frac{44}{9} + \\frac{14}{9} - \\frac{58}{9} = \\frac{58-58}{9} = 0 \\]\n\nAnswer: The parallel component is \\(\\vec{a}_{||} = (\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9})\\) and the orthogonal component is \\(\\vec{a}_{\\perp} = (\\frac{44}{9}, \\frac{7}{9}, -\\frac{29}{9})\\).\n\n\n\n5.7. Finding a Vector from Multiple Conditions\nQuestion: Find the coordinates of a vector \\(\\vec{c}\\) that has a length of 1, is perpendicular to \\(\\vec{a} = (1, -1, 1)\\), and forms an angle of \\(\\arccos(\\sqrt{2/27})\\) with vector \\(\\vec{b} = (5, 1, 1)\\). How many solutions are there?\n\n\nClick to see the solution\n\nLet \\(\\vec{c} = (x, y, z)\\). We can translate the given information into a system of equations: 1. Length is 1: \\(||\\vec{c}||^2 = x^2 + y^2 + z^2 = 1\\) 2. Perpendicular to \\(\\vec{a}\\): \\(\\vec{a} \\cdot \\vec{c} = (1)x + (-1)y + (1)z = x - y + z = 0 \\implies y = x + z\\) 3. Angle with \\(\\vec{b}\\): \\(\\cos(\\theta) = \\frac{\\vec{b} \\cdot \\vec{c}}{||\\vec{b}||||\\vec{c}||} = \\sqrt{\\frac{2}{27}}\\). \\(||\\vec{b}|| = \\sqrt{5^2+1^2+1^2} = \\sqrt{27}\\). Since \\(||\\vec{c}||=1\\), this simplifies to \\(\\frac{\\vec{b}\\cdot\\vec{c}}{\\sqrt{27}} = \\sqrt{\\frac{2}{27}}\\). This gives \\(\\vec{b}\\cdot\\vec{c} = \\sqrt{2}\\), so \\(5x + y + z = \\sqrt{2}\\).\nNow we solve the system: 1. Substitute (2) into (3): \\(5x + (x+z) + z = \\sqrt{2} \\implies 6x + 2z = \\sqrt{2} \\implies 3x + z = \\frac{\\sqrt{2}}{2} \\implies z = \\frac{\\sqrt{2}}{2} - 3x\\). 2. Express y in terms of x: Substitute the new expression for z into (2): \\(y = x + (\\frac{\\sqrt{2}}{2} - 3x) = \\frac{\\sqrt{2}}{2} - 2x\\). 3. Substitute x, y, z into the length equation (1): \\(x^2 + (\\frac{\\sqrt{2}}{2} - 2x)^2 + (\\frac{\\sqrt{2}}{2} - 3x)^2 = 1\\). 4. Expand and solve the quadratic for x: \\(x^2 + (\\frac{2}{4} - 2\\sqrt{2}x + 4x^2) + (\\frac{2}{4} - 3\\sqrt{2}x + 9x^2) = 1\\). \\(x^2 + \\frac{1}{2} - 2\\sqrt{2}x + 4x^2 + \\frac{1}{2} - 3\\sqrt{2}x + 9x^2 = 1\\). \\(14x^2 - 5\\sqrt{2}x + 1 = 1 \\implies 14x^2 - 5\\sqrt{2}x = 0\\). \\(x(14x - 5\\sqrt{2}) = 0\\). This gives two solutions for \\(x\\): \\(x_1=0\\) and \\(x_2 = \\frac{5\\sqrt{2}}{14}\\). 5. Find y and z for each x: * Solution 1: If \\(x_1 = 0\\): \\(z_1 = \\frac{\\sqrt{2}}{2} - 3(0) = \\frac{\\sqrt{2}}{2}\\). \\(y_1 = \\frac{\\sqrt{2}}{2} - 2(0) = \\frac{\\sqrt{2}}{2}\\). \\(\\vec{c}_1 = (0, \\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2})\\). * Solution 2: If \\(x_2 = \\frac{5\\sqrt{2}}{14}\\): \\(z_2 = \\frac{\\sqrt{2}}{2} - 3(\\frac{5\\sqrt{2}}{14}) = \\frac{7\\sqrt{2}}{14} - \\frac{15\\sqrt{2}}{14} = -\\frac{8\\sqrt{2}}{14} = -\\frac{4\\sqrt{2}}{7}\\). \\(y_2 = \\frac{\\sqrt{2}}{2} - 2(\\frac{5\\sqrt{2}}{14}) = \\frac{7\\sqrt{2}}{14} - \\frac{10\\sqrt{2}}{14} = -\\frac{3\\sqrt{2}}{14}\\). \\(\\vec{c}_2 = (\\frac{5\\sqrt{2}}{14}, -\\frac{3\\sqrt{2}}{14}, -\\frac{4\\sqrt{2}}{7})\\).\nAnswer: There are two solutions. \\(\\vec{c}_1 = (0, \\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2})\\) and \\(\\vec{c}_2 = (\\frac{5\\sqrt{2}}{14}, -\\frac{3\\sqrt{2}}{14}, -\\frac{4\\sqrt{2}}{7})\\).",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "2. Inner Product, Dot Product, Orthogonality, and Projections"
    ]
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_1.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_1.html",
    "title": "1. Vectors, Vector Spaces, Linear Independence, Basis, and Dimension",
    "section": "",
    "text": "1. Summary\n\n1.1 Introduction to Vectors\nA vector is a fundamental mathematical object that possesses both magnitude (or length) and direction. It’s distinct from a scalar, which is a simple numerical value (like temperature or speed) that has magnitude but no direction. Think of a vector as an instruction to travel a certain distance in a specific direction.\nVectors can be represented in several ways:\n\n1.1.1 Geometric Representation\nAs a directed line segment, or an arrow, in space. The arrow’s length represents the magnitude, and the direction it points represents its direction. A key property is that a vector is independent of its starting position; two arrows with the same length and direction represent the same vector, regardless of where they are in space. This makes them “free-floating” instructions.\n\n\n\n1.1.2 Algebraic Representation\nAs an ordered list of numbers, called components. For instance, in a 2D plane (denoted \\(\\mathbb{R}^2\\)), a vector is represented by two components \\((x, y)\\), and in 3D space (\\(\\mathbb{R}^3\\)), by three components \\((x, y, z)\\). These components correspond to the vector’s projection onto the coordinate axes. By convention in linear algebra, vectors are often written as column vectors: \\[ \\vec{v} = \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] A row vector is written as \\((x, y)\\). The two are not interchangeable, but one can be converted to the other using the transpose operation: \\(\\begin{pmatrix} x \\\\ y \\end{pmatrix}^T = (x, y)\\).\n\n\n1.1.3 Vector Notation\nVectors can be denoted by bold lowercase letters (e.g., v), a letter with an arrow above it (e.g., \\(\\vec{v}\\)), or by their start and end points (e.g., \\(\\vec{AB}\\), representing the vector from point A to point B). Points are denoted by capital letters (e.g., A, B). Scalars are denoted by regular lowercase letters (e.g., c, k, \\(\\alpha\\)).\n\n\n\n1.2 Basic Vector Operations\nStandard arithmetic operations are defined for vectors, allowing them to be manipulated algebraically.\n\n1.2.1 Vector Addition\nTo add two vectors, you add their corresponding components. Geometrically, this is represented by the tip-to-tail method: place the tail of the second vector at the tip of the first. The resulting vector (the sum) goes from the tail of the first vector to the tip of the second, forming a triangle. \\[ \\vec{u} + \\vec{v} = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix} + \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} u_1 + v_1 \\\\ u_2 + v_2 \\end{pmatrix} \\] \n\n\n1.2.2 Scalar Multiplication\nTo multiply a vector by a scalar, you multiply each of its components by that scalar. This operation scales the vector, changing its magnitude. If the scalar is positive, the direction remains the same. If negative, the direction is reversed. A scalar of 2 doubles the vector’s length; a scalar of -0.5 halves its length and flips its direction. \\[ c\\vec{v} = c\\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} cv_1 \\\\ cv_2 \\end{pmatrix} \\]\n\n\n1.2.3 Vector Subtraction\nSubtraction is defined as adding the negative of a vector. That is, \\(\\vec{u} - \\vec{v}\\) is the same as \\(\\vec{u} + (-1)\\vec{v}\\). Geometrically, the vector \\(\\vec{u} - \\vec{v}\\) is the vector that points from the tip of \\(\\vec{v}\\) to the tip of \\(\\vec{u}\\). \\[ \\vec{u} - \\vec{v} = \\begin{pmatrix} u_1 \\\\ u_2 \\end{pmatrix} - \\begin{pmatrix} v_1 \\\\ v_2 \\end{pmatrix} = \\begin{pmatrix} u_1 - v_1 \\\\ u_2 - v_2 \\end{pmatrix} \\]\n\n\n\n1.3 Vector Magnitude and Normalization\n\n1.3.1 Norm of a Vector\nThe norm (or magnitude/length) of a vector is a non-negative scalar value representing its length. It is calculated using the Pythagorean theorem on its components. The norm of a vector \\(\\vec{v}\\) is denoted as \\(||\\vec{v}||\\). \\[ ||\\vec{v}|| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2} \\]\n\n\n1.3.2 Unit Vectors\nA unit vector is any vector with a norm of 1. It is useful for representing a pure direction without any magnitude. To normalize a non-zero vector (i.e., to find the unit vector in its direction), you divide the vector by its own norm. \\[ \\hat{u} = \\frac{\\vec{v}}{||\\vec{v}||} \\]\n\n\n1.3.3 Standard Unit Vectors\nIn Cartesian coordinate systems, there are special unit vectors that point along the axes. In \\(\\mathbb{R}^3\\), these are:\n\n\\(\\vec{i} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\\) (along the x-axis)\n\\(\\vec{j} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\\) (along the y-axis)\n\\(\\vec{k} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\\) (along the z-axis) Any vector in \\(\\mathbb{R}^3\\) can be written as a sum of these: \\(\\begin{pmatrix} a \\\\ b \\\\ c \\end{pmatrix} = a\\vec{i} + b\\vec{j} + c\\vec{k}\\).\n\n\n\n1.3.4 Distance Between Points\nThe straight-line distance between two points, say \\(P\\) and \\(Q\\), can be found by first calculating the vector \\(\\vec{PQ}\\) that connects them (\\(\\vec{PQ} = Q - P\\)) and then finding the norm of that vector. \\[ d(P, Q) = ||\\vec{PQ}|| = ||Q - P|| = \\sqrt{(q_1-p_1)^2 + (q_2-p_2)^2 + \\dots} \\]\n\n\n\n1.4 Vector Spaces and Subspaces\n\n1.4.1 Vector Space\nA vector space is a collection of objects (called vectors) for which the operations of vector addition and scalar multiplication are defined and satisfy a set of ten rules, known as axioms. These axioms ensure that vectors behave consistently and predictably. Key axioms include closure (adding two vectors or multiplying by a scalar results in a vector still within the space), the existence of a zero vector (\\(\\vec{0}\\)), and the existence of an additive inverse (e.g., \\(-\\vec{v}\\)) for every vector.\n\nExamples of Vector Spaces:\n\n\\(\\mathbb{R}^n\\): The set of all n-dimensional vectors with real number components. This is the most common example.\n\\(P_n\\): The set of all polynomials of degree at most \\(n\\). For example, \\(3x^2 - x + 5\\) is a vector in \\(P_2\\).\nThe set of all continuous functions.\n\nNon-Example: The set of all vectors in the first quadrant of \\(\\mathbb{R}^2\\) (where \\(x \\ge 0, y \\ge 0\\)) is not a vector space because it fails closure under scalar multiplication. Multiplying a vector in the first quadrant by -1 results in a vector in the third quadrant, which is outside the set.\n\n\n\n1.4.2 Subspace\nA subspace is a subset of a larger vector space that is itself a vector space. To verify if a subset is a subspace, a simplified test called the Subspace Test is used. A subset \\(H\\) is a subspace if it meets three conditions:\n\nIt contains the zero vector.\nIt is closed under addition (if \\(\\vec{u}\\) and \\(\\vec{v}\\) are in \\(H\\), then \\(\\vec{u} + \\vec{v}\\) must also be in \\(H\\)).\nIt is closed under scalar multiplication (if \\(\\vec{u}\\) is in \\(H\\) and \\(c\\) is any scalar, then \\(c\\vec{u}\\) must also be in \\(H\\)).\n\n\nKey Examples of Subspaces:\n\nAny line or plane passing through the origin in \\(\\mathbb{R}^3\\) is a subspace of \\(\\mathbb{R}^3\\).\nThe null space of a matrix A, which is the set of all solutions to the homogeneous equation \\(A\\vec{x} = \\vec{0}\\), is always a subspace.\n\n\n\n\n1.4.3 Centroid of a Triangle\nFor a triangle with vertices at points A, B, and C, the centroid (or center of mass) is the unique point G such that the vectors from G to each vertex sum to the zero vector: \\(\\vec{GA} + \\vec{GB} + \\vec{GC} = \\vec{0}\\). The position vector of the centroid is the average of the position vectors of its vertices: \\(\\vec{OG} = \\frac{1}{3}(\\vec{OA} + \\vec{OB} + \\vec{OC})\\). The centroid is always located inside the triangle.\n\n\n\n1.5 Linear Combinations, Span, and Basis\n\n1.5.1 Linear Combination and Span\nA linear combination is a new vector formed by adding together scalar multiples of other vectors. For example, \\(\\vec{w} = c_1\\vec{v}_1 + c_2\\vec{v}_2\\) is a linear combination of \\(\\vec{v}_1\\) and \\(\\vec{v}_2\\). The span of a set of vectors is the set of all possible linear combinations that can be formed from them. The span of a set of vectors always forms a vector space (or a subspace). For instance, the span of two non-collinear vectors in \\(\\mathbb{R}^3\\) is a plane passing through the origin. \n\n\n1.5.2 Linear Independence\nA set of vectors is linearly independent if no vector in the set can be written as a linear combination of the others. This means that none of the vectors are redundant; each one contributes a unique direction. The only way to form the zero vector from a linear combination of linearly independent vectors is if all the scalar coefficients are zero (the trivial solution).\n\n\n1.5.3 Linear Dependence\nA set of vectors is linearly dependent if at least one vector can be expressed as a linear combination of the others. This indicates redundancy in the set. Geometrically, two vectors are linearly dependent if they lie on the same line, and three vectors are linearly dependent if they lie on the same plane.\n\n\n1.5.4 Basis and Dimension\nA basis of a vector space is a set of vectors that is both linearly independent and spans the entire space. A basis provides a minimal set of “building blocks” for the space. While a vector space can have many different bases, the number of vectors in every basis for that space is always the same. This unique number is called the dimension of the vector space. For example, the dimension of \\(\\mathbb{R}^3\\) is 3, because a standard basis for it is the set of three vectors: \\(\\{\\vec{i}, \\vec{j}, \\vec{k}\\}\\).\n\n\n\n\n2. Definitions\n\nVector: A mathematical object that has both magnitude (length) and direction.\nScalar: A quantity that is fully described by a magnitude alone (a single number).\nNorm: The length or magnitude of a vector, denoted by \\(||\\vec{v}||\\).\nUnit Vector: A vector with a norm of 1, often used to represent direction.\nStandard Unit Vectors: The vectors \\(\\vec{i}, \\vec{j}, \\vec{k}\\) that form the basis for the Cartesian coordinate system.\nVector Space: A collection of vectors and a field of scalars that satisfy a set of ten axioms, defining a consistent system for vector addition and scalar multiplication.\nSubspace: A subset of a vector space that is itself a vector space under the same operations.\nNull Space: The set of all vectors \\(\\vec{x}\\) that are solutions to the homogeneous equation \\(A\\vec{x} = \\vec{0}\\). The null space of a matrix is always a subspace.\nCentroid: The point in a triangle where the medians intersect; its position vector is the average of the vertices’ position vectors.\nLinear Combination: A sum of vectors, each multiplied by a scalar coefficient.\nSpan: The set of all possible linear combinations of a given set of vectors. The span of a set of vectors is always a subspace.\nLinearly Independent: A set of vectors where no vector can be written as a linear combination of the others.\nLinearly Dependent: A set of vectors where at least one vector can be written as a linear combination of the others.\nBasis: A set of vectors that is both linearly independent and spans the vector space. It is a minimal generating set for the space.\nDimension: The number of vectors in any basis for a vector space.\n\n\n\n3. Formulas\n\nVector Addition: \\(\\vec{u} + \\vec{v} = \\begin{pmatrix} u_1 + v_1 \\\\ u_2 + v_2 \\end{pmatrix}\\)\nScalar Multiplication: \\(c\\vec{v} = \\begin{pmatrix} cv_1 \\\\ cv_2 \\end{pmatrix}\\)\nVector Subtraction: \\(\\vec{u} - \\vec{v} = \\begin{pmatrix} u_1 - v_1 \\\\ u_2 - v_2 \\end{pmatrix}\\)\nNorm of a Vector in \\(\\mathbb{R}^n\\): \\(||\\vec{v}|| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\\)\nDistance between Points P and Q: \\(d(P, Q) = ||Q - P||\\)\nNormalization (Unit Vector): \\(\\hat{u} = \\frac{\\vec{v}}{||\\vec{v}||}\\)\nPosition Vector of Centroid G: \\(\\vec{OG} = \\frac{1}{3}(\\vec{OA} + \\vec{OB} + \\vec{OC})\\)\nProjection of vector \\(\\vec{a}\\) onto vector \\(\\vec{b}\\): \\(\\text{proj}_{\\vec{b}}\\vec{a} = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||^2} \\vec{b}\\)\nReflection of vector \\(\\vec{a}\\) over a line defined by vector \\(\\vec{b}\\): \\(\\text{ref}_{\\vec{b}}\\vec{a} = 2 \\cdot \\text{proj}_{\\vec{b}}\\vec{a} - \\vec{a}\\)\n\n\n\n4. Mistakes\n\nAdding a scalar and a vector: An operation like \\(5 + \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\\) is undefined. Why it’s wrong: Scalars and vectors are fundamentally different types of mathematical objects and cannot be directly added. You can only perform scalar multiplication.\nAssuming any set of n vectors in \\(\\mathbb{R}^n\\) is a basis: For example, the set \\(\\{\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 2 \\end{pmatrix}\\}\\) is not a basis for \\(\\mathbb{R}^2\\). Why it’s wrong: A basis must be linearly independent. In this case, the second vector is just twice the first, so they are linearly dependent and only span a line, not the entire plane.\nConfusing a subspace with any subset: A line in \\(\\mathbb{R}^2\\) that does not pass through the origin is a subset, but not a subspace. Why it’s wrong: A subspace must contain the zero vector and be closed under addition and scalar multiplication. A line not through the origin fails the zero vector test.\nMixing up linear independence and spanning: A set of vectors can be linearly independent but not span the entire space. For example, \\(\\{\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\\}\\) is a linearly independent set in \\(\\mathbb{R}^3\\), but it only spans the xy-plane, not all of \\(\\mathbb{R}^3\\).\nIncorrectly calculating the dot product: The dot product of two vectors results in a scalar, not another vector. Why it’s wrong: The definition of the dot product is \\(\\vec{u} \\cdot \\vec{v} = u_1v_1 + u_2v_2 + \\dots\\), which is a sum of products, resulting in a single number.\nForgetting to take the square root for the norm: The norm is the length, which is the square root of the sum of squared components. A common mistake is to forget the square root, which calculates the squared norm \\(||\\vec{v}||^2\\).\n\n\n\n5. Examples\n\n5.1. Vector Equality\nQuestion: Given points \\(A(-1, 1)\\), \\(B(3, 5)\\), \\(C(x, y)\\), and \\(D(2x, 1)\\), find the values of \\(x\\) and \\(y\\) such that the vector \\(\\vec{AB}\\) is equal to the vector \\(\\vec{CD}\\).\n\n\nClick to see the solution\n\n\nCalculate the components of vector \\(\\vec{AB}\\): \\[ \\vec{AB} = B - A = \\begin{pmatrix} 3 - (-1) \\\\ 5 - 1 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix} \\]\nCalculate the components of vector \\(\\vec{CD}\\) in terms of \\(x\\) and \\(y\\): \\[ \\vec{CD} = D - C = \\begin{pmatrix} 2x - x \\\\ 1 - y \\end{pmatrix} = \\begin{pmatrix} x \\\\ 1 - y \\end{pmatrix} \\]\nSet the two vectors equal to each other: For two vectors to be equal, their corresponding components must be equal. \\[ \\begin{pmatrix} 4 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} x \\\\ 1 - y \\end{pmatrix} \\]\nSolve the resulting system of equations:\n\nFrom the first component: \\(x = 4\\).\nFrom the second component: \\(4 = 1 - y \\implies y = 1 - 4 \\implies y = -3\\).\n\n\nAnswer: The coordinates are \\(x=4, y=-3\\).\n\n\n\n5.2. Subspace Test (Failure)\nQuestion: Show that the set \\(S\\) of all vectors in the first quadrant of \\(\\mathbb{R}^2\\) (i.e., all vectors \\(\\begin{pmatrix} x \\\\ y \\end{pmatrix}\\) where \\(x \\ge 0\\) and \\(y \\ge 0\\)) does not form a vector space.\n\n\nClick to see the solution\n\n\nTo be a vector space, \\(S\\) must satisfy all subspace conditions. We only need to find one condition that fails. Let’s check closure under scalar multiplication.\nChoose a vector in the set \\(S\\). Let’s pick \\(\\vec{v} = \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix}\\). Since \\(3 \\ge 0\\) and \\(5 \\ge 0\\), this vector is in \\(S\\).\nChoose a scalar that might cause a problem. Let’s pick a negative scalar, \\(c = -2\\).\nPerform the scalar multiplication: \\[ c\\vec{v} = -2 \\begin{pmatrix} 3 \\\\ 5 \\end{pmatrix} = \\begin{pmatrix} -6 \\\\ -10 \\end{pmatrix} \\]\nCheck if the resulting vector is in \\(S\\). The new vector has components \\(x=-6\\) and \\(y=-10\\). Since both are less than 0, this vector is not in the first quadrant and therefore not in the set \\(S\\).\nConclusion: The set \\(S\\) is not closed under scalar multiplication, so it cannot be a subspace (and thus not a vector space).\n\nAnswer: The set is not a vector space because it fails closure under scalar multiplication.\n\n\n\n5.3. Centroid of a Triangle\nQuestion: Consider a triangle with vertices \\(A(-1, 0, 0)\\), \\(B(2, 0, \\sqrt{7})\\), and \\(C(3, \\sqrt{2}, \\sqrt{7})\\). Find the coordinates of the centroid \\(G\\).\n\n\nClick to see the solution\n\n\nIdentify the position vectors for each vertex, which are the same as their coordinates: \\[ \\vec{OA} = \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad \\vec{OB} = \\begin{pmatrix} 2 \\\\ 0 \\\\ \\sqrt{7} \\end{pmatrix}, \\quad \\vec{OC} = \\begin{pmatrix} 3 \\\\ \\sqrt{2} \\\\ \\sqrt{7} \\end{pmatrix} \\]\nUse the formula for the position vector of the centroid, \\(\\vec{OG}\\): \\[ \\vec{OG} = \\frac{1}{3}(\\vec{OA} + \\vec{OB} + \\vec{OC}) \\]\nAdd the vertex vectors: \\[ \\vec{OA} + \\vec{OB} + \\vec{OC} = \\begin{pmatrix} -1+2+3 \\\\ 0+0+\\sqrt{2} \\\\ 0+\\sqrt{7}+\\sqrt{7} \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ \\sqrt{2} \\\\ 2\\sqrt{7} \\end{pmatrix} \\]\nMultiply by \\(\\frac{1}{3}\\) to get the final coordinates: \\[ \\vec{OG} = \\frac{1}{3} \\begin{pmatrix} 4 \\\\ \\sqrt{2} \\\\ 2\\sqrt{7} \\end{pmatrix} = \\begin{pmatrix} 4/3 \\\\ \\sqrt{2}/3 \\\\ 2\\sqrt{7}/3 \\end{pmatrix} \\]\n\nAnswer: The centroid is at \\((4/3, \\sqrt{2}/3, 2\\sqrt{7}/3)\\).\n\n\n\n5.4. Checking for a Basis\nQuestion: Determine if the set of vectors \\(B = \\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 2 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 0 \\\\ 0 \\\\ 3 \\end{pmatrix} \\right\\}\\) forms a basis for \\(\\mathbb{R}^3\\).\n\n\nClick to see the solution\n\n\nA set is a basis if it is linearly independent and spans the space. For \\(\\mathbb{R}^3\\), we need 3 vectors that satisfy these conditions.\nCheck for linear independence: Set up the equation \\(c_1\\vec{v}_1 + c_2\\vec{v}_2 + c_3\\vec{v}_3 = \\vec{0}\\). \\[ c_1\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + c_2\\begin{pmatrix} 0 \\\\ 2 \\\\ 0 \\end{pmatrix} + c_3\\begin{pmatrix} 0 \\\\ 0 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\] \\[ \\begin{pmatrix} c_1 \\\\ 2c_2 \\\\ 3c_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\] This clearly implies that \\(c_1 = 0\\), \\(2c_2 = 0 \\implies c_2 = 0\\), and \\(3c_3 = 0 \\implies c_3 = 0\\). Since the only solution is the trivial solution (\\(c_1=c_2=c_3=0\\)), the vectors are linearly independent.\nCheck if the vectors span \\(\\mathbb{R}^3\\): Since we have 3 linearly independent vectors in a 3-dimensional space, they automatically form a basis and span the space. Any vector \\(\\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix}\\) can be written as a linear combination: \\[ x\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} + \\frac{y}{2}\\begin{pmatrix} 0 \\\\ 2 \\\\ 0 \\end{pmatrix} + \\frac{z}{3}\\begin{pmatrix} 0 \\\\ 0 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} x \\\\ y \\\\ z \\end{pmatrix} \\] Since any vector can be formed, the set spans \\(\\mathbb{R}^3\\).\n\nAnswer: Yes, the set is a basis for \\(\\mathbb{R}^3\\).\n\n\n\n5.5. Linear Dependence\nQuestion: Determine if the vectors \\(\\vec{u} = (1, 2)\\) and \\(\\vec{v} = (3, 6)\\) are linearly dependent.\n\n\nClick to see the solution\n\n\nCheck if one vector is a scalar multiple of the other. For two vectors, this is the easiest way to check for linear dependence.\nSet up the equation \\(\\vec{v} = c\\vec{u}\\): \\[ \\begin{pmatrix} 3 \\\\ 6 \\end{pmatrix} = c \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\]\nSolve for c from the components:\n\nFrom the first component: \\(3 = c \\cdot 1 \\implies c = 3\\).\nFrom the second component: \\(6 = c \\cdot 2 \\implies c = 3\\).\n\nConclusion: Since we found a consistent scalar \\(c=3\\) such that \\(\\vec{v} = 3\\vec{u}\\), the vectors are scalar multiples of each other.\n\nAnswer: The vectors are linearly dependent.\n\n\n\n5.6. Vector Projection\nQuestion: Given \\(\\vec{a} = (2, 2, -1)\\) and \\(\\vec{b} = (0, 4, 3)\\), compute the projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\).\n\n\nClick to see the solution\n\n\nCalculate the dot product \\(\\vec{a} \\cdot \\vec{b}\\): \\[ \\vec{a} \\cdot \\vec{b} = (2)(0) + (2)(4) + (-1)(3) = 0 + 8 - 3 = 5 \\]\nCalculate the squared norm of \\(\\vec{b}\\): \\[ ||\\vec{b}||^2 = 0^2 + 4^2 + 3^2 = 0 + 16 + 9 = 25 \\]\nApply the projection formula: \\[ \\text{proj}_{\\vec{b}}\\vec{a} = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||^2} \\vec{b} = \\frac{5}{25} \\begin{pmatrix} 0 \\\\ 4 \\\\ 3 \\end{pmatrix} \\]\nSimplify the result: \\[ \\text{proj}_{\\vec{b}}\\vec{a} = \\frac{1}{5} \\begin{pmatrix} 0 \\\\ 4 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 4/5 \\\\ 3/5 \\end{pmatrix} \\]\n\nAnswer: The projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\) is \\(\\begin{pmatrix} 0 \\\\ 4/5 \\\\ 3/5 \\end{pmatrix}\\).\n\n\n\n5.7. Vector Reflection\nQuestion: Using the vectors from the previous example, compute the reflection of \\(\\vec{a} = (2, 2, -1)\\) over the line defined by vector \\(\\vec{b} = (0, 4, 3)\\).\n\n\nClick to see the solution\n\n\nRecall the projection vector from the previous example: \\[ \\text{proj}_{\\vec{b}}\\vec{a} = \\begin{pmatrix} 0 \\\\ 4/5 \\\\ 3/5 \\end{pmatrix} \\]\nApply the reflection formula: \\(\\text{ref}_{\\vec{b}}\\vec{a} = 2 \\cdot \\text{proj}_{\\vec{b}}\\vec{a} - \\vec{a}\\): \\[ \\text{ref}_{\\vec{b}}\\vec{a} = 2 \\begin{pmatrix} 0 \\\\ 4/5 \\\\ 3/5 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 2 \\\\ -1 \\end{pmatrix} \\]\nPerform the scalar multiplication: \\[ = \\begin{pmatrix} 0 \\\\ 8/5 \\\\ 6/5 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 2 \\\\ -1 \\end{pmatrix} \\]\nPerform the vector subtraction: \\[ = \\begin{pmatrix} 0 - 2 \\\\ 8/5 - 10/5 \\\\ 6/5 - (-5/5) \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -2/5 \\\\ 11/5 \\end{pmatrix} \\]\n\nAnswer: The reflection of \\(\\vec{a}\\) over \\(\\vec{b}\\) is \\(\\begin{pmatrix} -2 \\\\ -2/5 \\\\ 11/5 \\end{pmatrix}\\).",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "1. Vectors, Vector Spaces, Linear Independence, Basis, and Dimension"
    ]
  },
  {
    "objectID": "Discrete Mathematics/lec_3.html",
    "href": "Discrete Mathematics/lec_3.html",
    "title": "3. Predicates, Quantifiers, and De Morgan’s Laws",
    "section": "",
    "text": "1. Summary\n\n1.1 From Propositions to Predicates\nIn logic, a proposition is a declarative statement that is definitively either true or false, but not both. For instance, “The number 4 is an even number” is a true proposition. However, we often need to work with statements whose truth value depends on a variable, such as “x is an even number.”\nThis is where predicates come in. A predicate is a statement containing one or more variables, which becomes a proposition once the variables are replaced with specific values. We can represent the predicate “x is an even number” as \\(P(x)\\). When we set \\(x=4\\), \\(P(4)\\) becomes the true proposition “4 is an even number.” The set of all possible values a variable can take is called the domain. The truth of a predicate statement critically depends on its domain.\n\n\n1.2 Quantifiers: Generalizing Predicates\nQuantifiers are symbols that allow us to make general claims about the truth of a predicate over its entire domain, without having to test every single value. There are two primary quantifiers.\n\n\n1.2.1 The Universal Quantifier (\\(\\forall\\))\nThe universal quantifier, denoted by the symbol \\(\\forall\\), stands for “for all” or “for any.” The statement \\(\\forall x P(x)\\) asserts that the predicate \\(P(x)\\) is true for every single element \\(x\\) in the domain.\n\nExample: If the domain is the set of all even numbers, the statement \\(\\forall x (\\text{\"x is divisible by 2\"})\\) is true.\nConnection to Logic: For a finite domain \\(\\{x_1, x_2, \\dots, x_n\\}\\), the universal statement \\(\\forall x P(x)\\) is logically equivalent to the conjunction (AND) of the predicate for each element: \\(P(x_1) \\land P(x_2) \\land \\dots \\land P(x_n)\\). A universal statement is only true if all parts are true.\n\n\n\n1.2.2 The Existential Quantifier (\\(\\exists\\))\nThe existential quantifier, denoted by the symbol \\(\\exists\\), stands for “there exists” or “for some.” The statement \\(\\exists x P(x)\\) asserts that there is at least one element \\(x\\) in the domain for which the predicate \\(P(x)\\) is true.\n\nExample: If the domain is the set of all integers, the statement \\(\\exists x (x^2 = 9)\\) is true, because we can find at least one value (namely, 3 or -3) that makes it true.\nConnection to Logic: For a finite domain \\(\\{x_1, x_2, \\dots, x_n\\}\\), the existential statement \\(\\exists x P(x)\\) is logically equivalent to the disjunction (OR) of the predicate for each element: \\(P(x_1) \\lor P(x_2) \\lor \\dots \\lor P(x_n)\\). An existential statement is true if at least one part is true.\n\n\n\n\n1.3 Free and Bound Variables\nIn a logical formula, a variable can be either bound or free.\n\nA variable is bound if it is within the scope of a quantifier. In the expression \\(\\forall x (x &gt; y)\\), the variable x is bound by the universal quantifier.\nA variable is free if it is not bound by any quantifier. In the same expression, \\(\\forall x (x &gt; y)\\), the variable y is free.\n\nA formula with no free variables is a proposition; its truth value can be determined (given a domain). A formula with free variables is a predicate; its truth value depends on the values assigned to the free variables.\n\n\n1.4 Interpretation and Counterexamples\n\nAn interpretation is an assignment of a specific domain and meanings to the predicates in a formula that makes the formula TRUE.\nA counterexample is an interpretation that makes the formula FALSE. Finding even a single case in the domain that violates a universal statement serves as a counterexample. For instance, to disprove \\(\\forall x (\\text{\"x is an odd number\"})\\) for the domain of integers, we only need to provide one counterexample, like the number 2, which is an integer but not odd.\n\n\n\n1.5 De Morgan’s Laws for Quantifiers\nDe Morgan’s Laws provide a crucial relationship between negation and quantifiers, allowing us to move the negation symbol (¬) inside a quantifier by flipping the quantifier.\n\nNegating a Universal Quantifier: The negation of “for all x, P(x) is true” is “there exists an x for which P(x) is false.” \\[ \\neg \\forall x P(x) \\equiv \\exists x \\neg P(x) \\] Analogy: To disprove the claim “All students passed the exam,” you only need to find one student who did not pass.\nNegating an Existential Quantifier: The negation of “there exists an x for which P(x) is true” is “for all x, P(x) is false.” \\[ \\neg \\exists x P(x) \\equiv \\forall x \\neg P(x) \\] Analogy: To disprove the claim “There is a dragon in the castle,” you must check every room and confirm that all of them are dragon-free.\n\n\n\n1.6 Properties of Quantifiers\nQuantifiers interact with logical connectives like AND (&) and OR (∨) in specific ways.\n\nUniversal Quantifier and AND: A universal quantifier can be distributed over &. The statement “all x have property P and property R” is the same as “all x have property P” AND “all x have property R”. \\[ \\forall x (P(x) \\land R(x)) \\equiv \\forall x P(x) \\land \\forall x R(x) \\]\nExistential Quantifier and OR: An existential quantifier can be distributed over ∨. The statement “there is an x that has property P or property R” is the same as “there is an x with property P” OR “there is an x with property R”. \\[ \\exists x (P(x) \\lor R(x)) \\equiv \\exists x P(x) \\lor \\exists x R(x) \\]\nImportant Note: A universal quantifier cannot be distributed over ∨, and an existential quantifier cannot be distributed over &.\n\n\n\n1.7 Nested Quantifiers\nNested quantifiers occur when one quantifier is within the scope of another, such as \\(\\forall x \\exists y (x+y=0)\\). The order of quantifiers is critical.\n\nSame Quantifiers: If the quantifiers are the same, their order does not matter. \\[ \\forall x \\forall y P(x, y) \\equiv \\forall y \\forall x P(x, y) \\] \\[ \\exists x \\exists y P(x, y) \\equiv \\exists y \\exists x P(x, y) \\]\nMixed Quantifiers: If the quantifiers are different, their order does matter and can completely change the meaning of the statement. \\[ \\exists x \\forall y P(x, y) \\rightarrow \\forall y \\exists x P(x, y) \\] The statement on the left implies the one on the right, but the reverse is not true. Let’s analyze \\(\\exists x \\forall y\\) versus \\(\\forall y \\exists x\\):\n\n\\(\\exists x \\forall y P(x,y)\\): “There exists a single x that works for all y.” This is a very strong claim. For example, if \\(P(x,y)\\) is “\\(x \\geq y\\)” in the domain of natural numbers, this is false. There is no single natural number that is greater than or equal to all other natural numbers.\n\\(\\forall y \\exists x P(x,y)\\): “For any given y, we can find some x that works.” The choice of x can depend on y. For the same example, “\\(x \\geq y\\)”, this is true. For any natural number y, we can always find an x (e.g., x=y or x=y+1) that is greater than or equal to it.\n\n\n\n\n1.8 Special Quantifiers\nFor convenience, we use extensions of the standard quantifiers.\n\nUniqueness Quantifier (\\(\\exists!\\)): The statement \\(\\exists!x P(x)\\) means “there exists a unique (one and only one) x such that \\(P(x)\\) is true.”\nRestricted Quantifiers: We often restrict the domain of a quantifier to a certain condition.\n\nRestricted Universal: \\(\\forall x &gt; 0, P(x)\\) means “for all x that are greater than 0, \\(P(x)\\) is true.” This is formally written as an implication: \\[ \\forall x (x &gt; 0 \\rightarrow P(x)) \\]\nRestricted Existential: \\(\\exists x &gt; 0, P(x)\\) means “there exists an x greater than 0 such that \\(P(x)\\) is true.” This is formally written as a conjunction: \\[ \\exists x (x &gt; 0 \\land P(x)) \\]\n\n\n\n\n\n2. Definitions\n\nSet: An unordered collection of distinct elements.\nProposition: A declarative sentence that is unambiguously true or false.\nPredicate: A sentence containing variables that becomes a proposition when the variables are assigned specific values from a domain.\nDomain: The set of all possible values that a variable in a predicate can assume.\nUniversal Quantifier (\\(\\forall\\)): A logical symbol meaning “for all” or “for every,” asserting that a predicate is true for all elements in the domain.\nExistential Quantifier (\\(\\exists\\)): A logical symbol meaning “there exists” or “for some,” asserting that a predicate is true for at least one element in the domain.\nBound Variable: A variable that falls within the scope of a quantifier.\nFree Variable: A variable in a logical formula that is not bound by a quantifier.\nInterpretation: An assignment of a domain and meanings to predicates that makes a formula TRUE.\nCounterexample: An assignment of a domain and meanings to predicates that makes a formula FALSE.\n\n\n\n3. Formulas\n\nDe Morgan’s Law for \\(\\forall\\): \\(\\neg \\forall x P(x) \\equiv \\exists x \\neg P(x)\\)\nDe Morgan’s Law for \\(\\exists\\): \\(\\neg \\exists x P(x) \\equiv \\forall x \\neg P(x)\\)\nDistribution of \\(\\forall\\) over \\(\\land\\): \\(\\forall x (P(x) \\land R(x)) \\equiv \\forall x P(x) \\land \\forall x R(x)\\)\nDistribution of \\(\\exists\\) over \\(\\lor\\): \\(\\exists x (P(x) \\lor R(x)) \\equiv \\exists x P(x) \\lor \\exists x R(x)\\)\nCommutativity of Same Quantifiers:\n\n\\(\\forall x \\forall y P(x, y) \\equiv \\forall y \\forall x P(x, y)\\)\n\\(\\exists x \\exists y P(x, y) \\equiv \\exists y \\exists x P(x, y)\\)\n\nImplication of Mixed Quantifiers: \\(\\exists x \\forall y P(x, y) \\rightarrow \\forall y \\exists x P(x, y)\\)\nUniqueness Quantifier Definition: \\(\\exists!x P(x) \\equiv \\exists x (P(x) \\land \\forall y (P(y) \\rightarrow y=x))\\)\nRestricted Universal Quantifier: The statement “For all \\(x\\) such that \\(R(x)\\), \\(P(x)\\) holds” is written as \\(\\forall x (R(x) \\rightarrow P(x))\\).\nRestricted Existential Quantifier: The statement “There exists an \\(x\\) such that \\(R(x)\\) and \\(P(x)\\)” is written as \\(\\exists x (R(x) \\land P(x))\\).\n\n\n\n4. Mistakes\n\nConfusing the order of mixed quantifiers: Treating \\(\\forall x \\exists y P(x,y)\\) and \\(\\exists y \\forall x P(x,y)\\) as equivalent. Why it’s wrong: The order changes the meaning entirely. \\(\\exists y \\forall x\\) implies a single y must work for all x, a much stronger condition than \\(\\forall x \\exists y\\), where y can be chosen differently for each x.\nIncorrectly distributing quantifiers: Assuming that \\(\\forall x (P(x) \\lor R(x))\\) is the same as \\(\\forall x P(x) \\lor \\forall x R(x)\\). Why it’s wrong: Consider the domain of integers where \\(P(x)\\) is “x is even” and \\(R(x)\\) is “x is odd”. Every integer is either even or odd, so \\(\\forall x (P(x) \\lor R(x))\\) is true. However, it’s not true that all integers are even, and it’s not true that all integers are odd, so \\(\\forall x P(x) \\lor \\forall x R(x)\\) is false.\nApplying the wrong logical connective for restricted quantifiers: Using & with a restricted universal quantifier, like \\(\\forall x (x&gt;0 \\land P(x))\\). Why it’s wrong: This would mean “for all x, x is positive AND P(x) is true,” which is a much stronger and usually incorrect statement. A universal restriction requires an implication (→). Similarly, using → with a restricted existential quantifier is wrong because it can be trivially true if the condition is false.\nUsing an incorrect De Morgan’s Law: Negating \\(\\forall x P(x)\\) to become \\(\\forall x \\neg P(x)\\). Why it’s wrong: This mistake ignores the rule that the quantifier must flip. The correct negation is \\(\\exists x \\neg P(x)\\). Negating “everyone passed” does not mean “everyone failed”; it means “at least one person failed.”\nForgetting the Domain: Evaluating the truth of a statement without considering the specified domain. Why it’s wrong: The statement \\(\\forall x (x &gt; 0)\\) is true if the domain is positive integers but false if the domain is all integers. The domain is fundamental to the meaning of a quantified statement.\n\n\n\n5. Examples\n\n5.1. Translating Logic to English\nQuestion: Let the domain be all people. Let \\(P(x)\\) be “x likes oranges” and \\(R(x)\\) be “x knows C++”. Translate the statement \\(\\forall x (R(x) \\rightarrow P(x))\\) into English.\n\n\nClick to see the solution\n\n\nIdentify the main quantifier and structure: The main structure is a universal quantifier \\(\\forall x\\) applied to an implication \\(R(x) \\rightarrow P(x)\\).\nTranslate the universal quantifier: \\(\\forall x\\) means “For every person x…”.\nTranslate the implication: \\(R(x) \\rightarrow P(x)\\) means “If x knows C++, then x likes oranges”.\nCombine the parts: “For every person x, if x knows C++, then x likes oranges.”\nRefine into natural English: This can be stated more naturally.\n\nAnswer: Everyone who knows C++ also likes oranges.\n\n\n\n5.2. Determining Truth Value\nQuestion: Let the domain be all real numbers. Determine the truth value of the statement \\(\\forall x \\exists y (x + y = 0)\\).\n\n\nClick to see the solution\n\n\nRead the statement: The statement says “For any real number x, there exists some real number y such that their sum is 0.”\nTest the logic: Let’s pick an arbitrary real number for x, say \\(x=5\\). Can we find a y such that \\(5+y=0\\)? Yes, \\(y=-5\\).\nGeneralize the test: For any arbitrary real number x, we can choose \\(y = -x\\). Since the negative of any real number is also a real number, we can always find such a y.\nConclusion: Since we can find a suitable y for every possible x, the statement is true.\n\nAnswer: TRUE.\n\n\n\n5.3. Applying De Morgan’s Laws\nQuestion: Rewrite the statement \\(\\neg \\forall x \\exists y ((x &gt; 0) \\land (y &lt; 0))\\) so that no negation is outside a quantifier or a logical connective.\n\n\nClick to see the solution\n\n\nApply De Morgan’s Law to the outermost quantifier (\\(\\forall x\\)): Move the negation inside by flipping \\(\\forall\\) to \\(\\exists\\). \\[ \\exists x \\neg (\\exists y ((x &gt; 0) \\land (y &lt; 0))) \\]\nApply De Morgan’s Law to the next quantifier (\\(\\exists y\\)): Move the negation inside by flipping \\(\\exists\\) to \\(\\forall\\). \\[ \\exists x \\forall y \\neg ((x &gt; 0) \\land (y &lt; 0)) \\]\nApply De Morgan’s Law to the logical connective (\\(\\land\\)): The negation of a conjunction is the disjunction of the negations: \\(\\neg(A \\land B) \\equiv \\neg A \\lor \\neg B\\). \\[ \\exists x \\forall y (\\neg(x &gt; 0) \\lor \\neg(y &lt; 0)) \\]\nSimplify the final inequalities: \\(\\neg(x &gt; 0)\\) is \\(x \\le 0\\), and \\(\\neg(y &lt; 0)\\) is \\(y \\ge 0\\). \\[ \\exists x \\forall y ((x \\le 0) \\lor (y \\ge 0)) \\]\n\nAnswer: \\(\\exists x \\forall y ((x \\le 0) \\lor (y \\ge 0))\\)\n\n\n\n5.4. Finding Domains for Truth and Falsity\nQuestion: Find a non-empty domain for x and y where the statement \\(\\exists x \\forall y (xy = y)\\) is true, and a domain where it is false.\n\n\nClick to see the solution\n\n\nAnalyze the statement: It says “There exists a single number x such that for every number y in the domain, multiplying x by y results in y.” This means x must be the multiplicative identity.\nFind a domain where it is TRUE:\n\nThe multiplicative identity is 1. If the number 1 is in our domain, we can choose \\(x=1\\).\nLet’s test if \\(x=1\\) works for all y. If we choose the domain to be the set of all integers, then for \\(x=1\\), it is true that \\(1 \\cdot y = y\\) for any integer y.\nSo, a valid domain is the set of integers, real numbers, or any set containing 1. A simpler domain is just \\(\\{1\\}\\). If the domain is \\(\\{1\\}\\), then \\(x=1\\) and \\(y=1\\), and \\(1 \\cdot 1 = 1\\), which is true.\n\nFind a domain where it is FALSE:\n\nFor the statement to be false, there must be no such x in the domain.\nThis means the domain should not contain the multiplicative identity (1).\nLet’s choose the domain to be the set \\(\\{2, 3\\}\\).\nTest \\(x=2\\): Does \\(2y=y\\) for all \\(y \\in \\{2, 3\\}\\)? No, \\(2 \\cdot 3 = 6 \\neq 3\\).\nTest \\(x=3\\): Does \\(3y=y\\) for all \\(y \\in \\{2, 3\\}\\)? No, \\(3 \\cdot 2 = 6 \\neq 2\\).\nSince neither possible value for x works for all y, the statement is false in this domain.\n\n\nAnswer: * TRUE Domain: The set of all real numbers, \\(\\mathbb{R}\\). * FALSE Domain: The set \\(\\{2, 3\\}\\).\n\n\n\n5.5. Nested Quantifiers with Counterexample\nQuestion: Let the domain be the set of integers \\(\\{0, 1, 2\\}\\). Determine the truth value of \\(\\forall x \\forall y ((x \\ne y) \\rightarrow \\forall z ((z=x) \\lor (z=y)))\\).\n\n\nClick to see the solution\n\n\nAnalyze the statement: “For any two distinct elements x and y from the domain, every element z in the domain must be equal to either x or y.”\nIdentify the condition: The statement has an implication. It only makes a claim when the hypothesis (\\(x \\ne y\\)) is true. We need to find a pair x, y from \\(\\{0, 1, 2\\}\\) where \\(x \\ne y\\).\nSelect a counterexample pair: Let’s choose \\(x=0\\) and \\(y=1\\). The hypothesis \\(x \\ne y\\) is true.\nTest the conclusion for this pair: The conclusion is \\(\\forall z ((z=x) \\lor (z=y))\\), which for our chosen pair means \\(\\forall z \\in \\{0, 1, 2\\}, ((z=0) \\lor (z=1))\\).\nEvaluate the conclusion: Is it true that every z in \\(\\{0, 1, 2\\}\\) is either 0 or 1?\n\nFor \\(z=0\\): \\((0=0 \\lor 0=1)\\) is TRUE.\nFor \\(z=1\\): \\((1=0 \\lor 1=1)\\) is TRUE.\nFor \\(z=2\\): \\((2=0 \\lor 2=1)\\) is FALSE.\n\nFinal Conclusion: Since the conclusion is false for \\(z=2\\), the universal statement \\(\\forall z ((z=0) \\lor (z=1))\\) is false. Because we found a pair (\\(x=0, y=1\\)) for which the hypothesis is true but the conclusion is false, the original implication-based statement is false.\n\nAnswer: FALSE.\n\n\n\n5.6. Rewriting a Restricted Quantifier\nQuestion: Rewrite the statement “There exists an integer i in the set \\(\\{1, ..., 10\\}\\) such that \\(P(i)\\)” using standard quantifiers and logical connectives.\n\n\nClick to see the solution\n\n\nIdentify the type of restricted quantifier: This is a restricted existential quantifier.\nRecall the formal definition: A statement of the form “There exists an x with property \\(R(x)\\) such that \\(P(x)\\)” is written as \\(\\exists x (R(x) \\land P(x))\\).\nApply the definition:\n\nThe variable is i.\nThe restricting property \\(R(i)\\) is “\\(i \\in \\{1, ..., 10\\}\\)”.\nThe main property \\(P(i)\\) is just \\(P(i)\\).\n\nCombine the parts: Substitute into the formal structure.\n\nAnswer: \\(\\exists i (i \\in \\{1, ..., 10\\} \\land P(i))\\)\n\n\n\n5.7. Truth Value of Uniqueness Quantifier\nQuestion: Let the domain be the set of real numbers. Determine the truth value of \\(\\exists!x ((x &gt; 0) \\land (x^2 = 16))\\).\n\n\nClick to see the solution\n\n\nAnalyze the statement: The uniqueness quantifier \\(\\exists!x\\) means “There exists one and only one x”. The predicate is “\\(x\\) is positive AND \\(x^2 = 16\\)”.\nFind all values that satisfy the predicate: We need to find all real numbers x that satisfy both conditions.\nSolve the equation: The solutions to \\(x^2 = 16\\) are \\(x = 4\\) and \\(x = -4\\).\nApply the condition: We must also satisfy the condition \\(x &gt; 0\\).\n\nFor \\(x=4\\): Is \\(4 &gt; 0\\)? Yes. So \\(x=4\\) is a solution.\nFor \\(x=-4\\): Is \\(-4 &gt; 0\\)? No. So \\(x=-4\\) is not a solution.\n\nCount the solutions: We found exactly one value, \\(x=4\\), that satisfies the entire predicate.\nConclusion: Since there is one and only one solution, the uniqueness statement is true.\n\nAnswer: TRUE.",
    "crumbs": [
      "Discrete Mathematics",
      "3. Predicates, Quantifiers, and De Morgan's Laws"
    ]
  },
  {
    "objectID": "Computer Architecture/lec_2.html",
    "href": "Computer Architecture/lec_2.html",
    "title": "2. Hierarchy of Memories, Moore’s Law, Parallelism, Pipelining, and Design Principles",
    "section": "",
    "text": "1. Summary\n\n1.1 The Hierarchy of Memories\nIn computer architecture, the memory hierarchy is a fundamental concept that organizes a computer’s storage into a pyramid-like structure. This organization is necessary to balance three competing factors: speed, capacity, and cost. Processors are extremely fast, but high-speed memory is expensive and thus has a small capacity. Conversely, large-capacity storage is affordable but much slower. The memory hierarchy solves this problem by creating layers of memory, where each level is smaller, faster, and more expensive per byte than the level below it. The closer a memory level is to the CPU, the faster the CPU can access it.\nThe typical levels of the memory hierarchy, from fastest to slowest, are:\n\nCPU Registers: These are the fastest and smallest memory units, located directly inside the CPU. They hold the data that the CPU is actively manipulating at any given moment, such as the results of arithmetic operations. Access is virtually instantaneous, occurring within a single CPU clock cycle.\nCache Memory: This is a small, very fast memory that sits between the CPU and the main system memory. It stores frequently accessed data and instructions, allowing the CPU to retrieve them much faster than from the main memory. This process of storing data in a cache is known as caching. Caches are typically divided into levels (L1, L2, L3), with L1 being the smallest and fastest.\nSystem Memory (RAM - Random Access Memory): This is the computer’s main working memory, where the operating system, applications, and data in current use are kept so that they can be quickly reached by the computer’s processor. It is significantly larger than cache but also slower.\nStorage Devices (Secondary Storage): This includes devices like Solid-State Drives (SSDs) and Flash Memory. They provide long-term, high-capacity storage for data and programs. This is the slowest but largest level of the hierarchy and is used to store data persistently.\n\n\nAn important distinction within the hierarchy is between volatile and non-volatile memory.\n\nVolatile Memory (Registers, Cache, RAM) requires power to maintain the stored information. It loses all its data when the power is turned off.\nNon-Volatile Memory (SSDs, HDDs, Flash Memory) retains its stored information even when not powered.\n\n\n\n1.2 Design Simplification via Abstraction\nAbstraction is a core principle in computer architecture used to manage complexity. It involves hiding the complex details of a system while exposing only the essential features. This allows designers and programmers to work with a simplified model of a component without needing to understand its intricate internal workings.\nFor example, a CPU can be viewed at several levels of abstraction:\n\nHighest Level (Simplest): A programmer views the CPU as a single, opaque block that executes instructions. They interact with it through a defined instruction set without needing to know how the instructions are physically carried out.\nIntermediate Level: An architect sees the CPU as a collection of major functional components, such as the Control Unit (CU), Arithmetic Logic Unit (ALU), and registers. This level describes what the components do and how they connect.\nLowest Level (Most Detailed): An engineer sees the CPU as a detailed diagram of logic gates, transistors, and wires that implement its functions. This level describes how the components are built.\n\nBy using abstraction, a complex system like a computer can be designed, built, and programmed in manageable layers.\n\n\n1.3 Moore’s Law and Its Stagnation\nMoore’s Law is an observation made by Intel co-founder Gordon Moore in 1965. It states that the number of transistors on an integrated circuit (IC) doubles approximately every two years. For decades, this trend also meant that CPU execution speed doubled every 18-24 months, leading to exponential growth in computing power.\nHowever, since around 2008, the growth in single-thread performance and CPU clock speed has significantly slowed down, leading to what is often called the stagnation of Moore’s Law. This is not because transistor density has stopped increasing, but because of two fundamental physical limits:\n\nHeat Dissipation: As transistors become smaller and more densely packed, the heat they generate becomes a major problem. Increasing clock speed further leads to higher power consumption and excessive heat, which can damage the chip and requires complex cooling solutions. This is known as the power wall.\nSpeed of Light Limitation: Signals within a CPU chip travel at nearly the speed of light. As chips get faster and more complex, the time it takes for a signal to travel across the chip becomes a significant limiting factor in how quickly the chip can operate.\n\nBecause of these limitations, the industry has shifted its focus from making single processors faster to adding more processors (or cores) to a single chip. This has led to the rise of multicore and multiprocessor systems, where performance is increased through parallelism rather than raw clock speed.\n\n\n1.4 Performance via Parallelism\nParallelism, or parallel processing, involves using multiple processing units to execute multiple tasks or parts of a single task simultaneously. This contrasts with a uniprocessor system, which executes instructions sequentially (one after another). A computer with multiple CPUs or a single CPU with multiple cores is a parallel system.\nThe goal of multiprocessing is to speed up computation by dividing work among multiple cores. This is highly effective for tasks that can be broken down into independent sub-tasks. However, a major challenge is instruction dependency, where one instruction needs the result of a previous one before it can execute. Such dependencies force a sequential execution and limit the benefits of parallelism, a concept formalized by Amdahl’s Law.\n\n\n1.5 Performance via Pipelining\nPipelining is another technique to improve performance, but it works differently from parallelism. Instead of using multiple processors, pipelining uses a single processor and breaks down the execution of an instruction into several stages. It then overlaps these stages for different instructions, much like an assembly line. This increases the instruction throughput (the number of instructions completed per unit of time).\nA classic five-stage pipeline includes:\n\nInstruction Fetch (IF): Fetch the next instruction from memory.\nInstruction Decode (ID): Decode the instruction to determine the required action.\nExecute (EX): Perform the calculation using the ALU.\nMemory Access (MEM): Read from or write to system memory if required.\nWrite Back (WB): Write the result back to a CPU register.\n\nWhile one instruction is in the Execute stage, the next one is being decoded, and the one after that is being fetched. Pipelining improves performance by increasing instruction throughput on a single processor, while parallelism improves performance by running multiple instructions truly simultaneously on different hardware units.\n\n\n1.6 Performance via Speculation (Prediction)\nSpeculative execution is an optimization technique where a processor makes an educated guess about the future execution path of a program and begins executing instructions from that predicted path before it’s certain the path will be taken. This is most commonly used for branch prediction.\nWhen the CPU encounters a conditional branch (e.g., an if statement), instead of waiting to see which branch is taken (which would stall the pipeline), the branch predictor guesses the outcome. The CPU then speculatively executes instructions along the predicted path. * If the prediction was correct, the results are kept, and time was saved by avoiding a pipeline stall. * If the prediction was incorrect, the speculative results are discarded, and the CPU starts executing from the correct path. This incurs a performance penalty, but since modern predictors are highly accurate (often &gt;95%), the overall performance gain is significant.\n\n\n1.7 Other Fundamental Ideas\n\nDependability via Redundancy: This principle involves adding spare components (e.g., extra CPUs, memory units, or power supplies) to a system to increase its reliability. If a primary component fails, a redundant one can take over, ensuring the system continues to operate without interruption. This is critical in applications like spacecraft, servers, and other mission-critical systems.\nMake the Common Case Fast: This is a design philosophy that prioritizes optimizing the performance of the most frequent operations or use cases. By focusing engineering resources on making common tasks as fast as possible, the overall system performance is improved, even if less common tasks are not as highly optimized.\nFinite State Machines (FSM): An FSM is a mathematical model of computation used to design both hardware and software systems. It consists of a finite number of states and the transitions between them, which are triggered by inputs. FSMs are a powerful and convenient tool for modeling the behavior of systems like network protocols, compilers, and hardware components like processor caches.\n\n\n\n\n2. Definitions\n\nComputer Architecture: The design and fundamental operational structure of a computer system. It defines the system’s parts and their interrelationships, including the instruction set, microarchitecture, and overall system design.\nCPU (Central Processing Unit): The primary component of a computer that executes instructions. It contains the Control Unit and the Arithmetic Logic Unit.\nALU (Arithmetic Logic Unit): The part of the CPU that performs arithmetic (e.g., addition, subtraction) and logic (e.g., AND, OR, NOT) operations.\nControl Unit (CU): The part of the CPU that directs the operation of the processor. It fetches instructions, decodes them, and tells the other parts of the computer system how to carry them out.\nRegister: A small, extremely fast memory location located directly inside the CPU used to hold a single piece of data (like a number or an instruction) during processing.\nCache Memory: A small amount of very fast, volatile memory that stores frequently accessed data from the main memory, reducing the average time to access data by avoiding slower RAM access.\nSystem Memory (RAM): The main volatile hardware memory in a computing device where the operating system, application programs, and data in current use are kept for quick access by the processor.\nVolatile Memory: Memory that requires constant power to maintain stored information; its contents are lost when power is turned off.\nNon-Volatile Memory: Memory that can retain stored information even after power is removed.\nAbstraction: The technique of hiding complex implementation details and showing only the necessary features of an object or system to simplify its use and design.\nMoore’s Law: The observation that the number of transistors in an integrated circuit doubles about every two years, which historically led to exponential growth in computing power.\nParallelism: The simultaneous execution of multiple instructions or tasks on multiple processing units (cores) to achieve faster computation.\nPipelining: A technique where a single processor overlaps the execution of multiple instructions by breaking each into stages and processing them in an assembly-line fashion to increase instruction throughput.\nSpeculative Execution: An optimization technique where a processor performs a task before it is known whether the task is actually needed, most often used for branch prediction.\nRedundancy: The inclusion of extra components in a system that are not strictly necessary for its basic functioning, intended to increase reliability in case of component failure.\nFinite State Machine (FSM): A computational model consisting of a finite number of states and transitions between them in response to inputs, used to model the behavior of dynamic systems.\n\n\n\n3. Mistakes\n\nConfusing Parallelism and Pipelining: Thinking these are the same concept. Why it’s wrong: Parallelism involves using multiple, independent processing units (like multiple cores) to execute different tasks truly simultaneously. Pipelining involves a single processing unit breaking instructions into stages and overlapping these stages to increase throughput. Pipelining is about making one “assembly line” more efficient, while parallelism is about setting up multiple assembly lines.\nBelieving Moore’s Law Still Guarantees Faster Clock Speeds: Assuming that the doubling of transistors automatically translates to a doubling of CPU clock frequency. Why it’s wrong: While historically correlated, clock speeds have stagnated since the mid-2000s due to the physical limitations of power consumption and heat dissipation. Moore’s Law now primarily results in more cores on a chip rather than faster individual cores.\nAssuming All Memory Access Is Equally Fast: Ignoring the vast performance differences between registers, cache, RAM, and SSDs. Why it’s wrong: The memory hierarchy exists precisely because there is a trade-off between speed and cost. An algorithm that frequently accesses data from RAM or disk will be orders of magnitude slower than one that is designed to keep its working data in the much faster cache.\nIgnoring the Cost of a Branch Misprediction: Believing that speculative execution is a “free” performance boost without any drawbacks. Why it’s wrong: When a branch is mispredicted, the entire pipeline must be flushed of the incorrect, speculatively executed instructions, and the correct instructions must be fetched and started from scratch. This incurs a significant performance penalty. The technique is only effective because modern predictors are correct most of the time.\nThinking More Cores Always Means a Faster Program: Assuming that doubling the number of CPU cores will cut a program’s execution time in half. Why it’s wrong: This is only true for perfectly parallelizable tasks (often called “embarrassingly parallel”). Most programs have sequential parts that cannot be run in parallel and require synchronization between threads, which limits the speedup gained from adding more cores.\nTreating Cache as Manually Managed Memory: Assuming a programmer needs to explicitly write code to move data into and out of the L1/L2 cache. Why it’s wrong: Caching is an automatic process managed by the hardware. The CPU’s memory controller automatically fetches data into the cache based on access patterns (like locality of reference). While programmers can write “cache-friendly” code, they do not manage the cache directly.\n\n\n\n4. Examples\n\n4.1. Memory Hierarchy Ordering\nQuestion: A program needs to access a piece of data. Arrange the following memory types in order from the location that would provide the fastest access to the one that would provide the slowest access: L2 Cache, SSD, System RAM, CPU Register.\n\n\nClick to see the solution\n\n\nIdentify the fastest level: The memory physically located inside the CPU’s core is the fastest. CPU registers fit this description.\nConsider the cache levels: Cache memory is the next fastest level, acting as a high-speed buffer between the CPU and RAM. L2 cache is extremely fast.\nPlace the main memory: System RAM is the primary working memory but is significantly slower than on-chip cache because the signals must travel off the CPU chip to a separate set of memory modules.\nPlace the storage device: Secondary storage like an SSD is the slowest level in this list. It is an I/O device, and accessing it is orders of magnitude slower than accessing RAM.\n\nAnswer: The correct order from fastest to slowest is: CPU Register, L2 Cache, System RAM, SSD.\n\n\n\n4.2. Pipelining Throughput\nQuestion: A non-pipelined processor takes 5 clock cycles to execute one instruction. A 5-stage pipelined processor has a clock cycle time of 1 ns and can complete one stage per cycle. Ignoring any pipeline stalls or hazards, how long would it take the pipelined processor to execute 10 instructions?\n\n\nClick to see the solution\n\n\nCalculate the time for the first instruction: The first instruction must pass through all 5 stages to complete. Since each stage takes one 1 ns clock cycle, the first instruction takes 5 stages * 1 ns/stage = 5 ns to exit the pipeline.\nCalculate the time for subsequent instructions: Once the pipeline is full (after the first instruction has reached the final stage), a new instruction will complete every clock cycle. Therefore, the remaining (10 - 1) = 9 instructions will each take only 1 additional clock cycle (1 ns) to emerge from the pipeline.\nSum the times: Total time = (Time for first instruction) + (Time for the remaining 9 instructions) = 5 ns + (9 * 1 ns) = 14 ns.\n\nAnswer: It would take 14 ns to execute 10 instructions.\n\n\n\n4.3. Identifying Parallelism vs. Pipelining\nQuestion: A server is running a video encoding application. The application is designed to process multiple frames of the video at the same time. The server’s CPU has 16 cores, and the application spawns 16 separate threads, with each thread independently encoding a different frame on its own core. Is this an example of performance via parallelism or pipelining?\n\n\nClick to see the solution\n\n\nAnalyze the resource allocation: The system is using multiple, distinct hardware processing units (16 cores).\nAnalyze the task distribution: Multiple independent tasks (encoding different frames) are being executed at the exact same time on these different cores.\nCompare with definitions: This perfectly matches the definition of parallelism, which uses multiple processors to handle different tasks concurrently. It is not pipelining, which is an optimization to overlap instruction stages on a single processor core.\n\nAnswer: This is an example of performance via parallelism.\n\n\n\n4.4. Applying Moore’s Law\nQuestion: In 2024, a high-end consumer CPU has 16 cores. Based on the modern interpretation of Moore’s Law (where the transistor budget is used for more cores), what would be a reasonable expectation for the core count of a similar-class high-end CPU in 2028 (4 years later)?\n\n\nClick to see the solution\n\n\nRecall Moore’s Law: The number of transistors doubles roughly every 2 years. In the multicore era, this often translates to a doubling of cores on the highest-end chips.\nCalculate the number of doubling periods: The time frame is 4 years, which consists of two 2-year periods.\nApply the doubling for each period:\n\nAfter the first 2 years (by 2026), the core count would be expected to double from 16 to 32.\nAfter the second 2 years (by 2028), the core count would be expected to double again from 32 to 64.\n\n\nAnswer: A reasonable expectation would be a CPU with 64 cores.\n\n\n\n4.5. Levels of Abstraction\nQuestion: Describe a web browser application (like Chrome or Firefox) at three different levels of abstraction, from highest (simplest) to lowest (most detailed).\n\n\nClick to see the solution\n\n\nHighest Level (The User’s View): At this level, the web browser is a simple application with a graphical user interface. The user interacts with an address bar to type URLs, clicks on links, and views rendered web pages. The underlying complexity of network requests, HTML parsing, and JavaScript execution is completely hidden. The browser is a tool to access information on the internet.\nIntermediate Level (The Web Developer’s View): A web developer sees the browser as a collection of engines and APIs. They work with the rendering engine (which processes HTML/CSS), the JavaScript engine (which executes code), the networking stack (for HTTP requests), and various APIs for storage, graphics, etc. They understand how these components interact to turn their code into a functional web page, but they do not need to know the specific algorithms used by the rendering engine.\nLowest Level (The Browser Engineer’s View): An engineer working on the browser itself sees the most detailed view. They are concerned with the C++ code that implements the rendering engine, optimizing the just-in-time (JIT) compiler in the JavaScript engine, managing memory allocation efficiently, and implementing network protocols according to RFC standards. This is the most complex view, where the application’s core logic is built.\n\nAnswer: The three levels are User (highest abstraction), Web Developer (intermediate abstraction), and Browser Engineer (lowest abstraction).\n\n\n\n4.6. Speculative Execution Scenario\nQuestion: Consider the following piece of code inside a loop that runs thousands of times. Explain how a CPU with speculative execution and an adaptive branch predictor would handle the if statement to optimize performance over time. if (data[i] &lt; 0) { handle_negative_value(); } else { handle_positive_value(); }\n\n\nClick to see the solution\n\n\nEncounter the Branch: The first time the loop runs, the CPU’s branch predictor may not have any history for this if statement, so it might make a static guess (e.g., predict the else branch is always taken).\nSpeculatively Execute and Learn: The CPU executes the predicted path. When the actual result of the comparison is known, it compares it to the prediction.\n\nIf the guess was correct, it reinforces its prediction.\nIf the guess was wrong (a misprediction), it flushes the pipeline, executes the correct path, and updates its prediction history to note that the guess was wrong.\n\nAdapt Over Time: Let’s say the data array contains mostly positive numbers. After the first few iterations, the branch predictor’s history will show that the condition data[i] &lt; 0 is almost always false. The predictor will adapt and strongly predict the else branch.\nOptimize Performance: For the remaining thousands of iterations, the CPU will speculatively execute handle_positive_value() each time. Since this prediction is correct most of the time, the pipeline continues without stalling, leading to a significant performance improvement. It only pays the misprediction penalty on the rare occasions when a negative value is encountered.\n\nAnswer: The CPU’s adaptive branch predictor learns the program’s behavior over time. It will predict that the else block is the most likely path and speculatively execute it, avoiding pipeline stalls on the vast majority of loop iterations.\n\n\n\n4.7. Finite State Machine Design\nQuestion: Design a simple Finite State Machine (FSM) for a traffic light at a simple intersection. It should cycle through Green, Yellow, and Red states. The only input is a timer.\n\n\nClick to see the solution\n\n\nDefine the States:\n\nGreen: The initial state. The light is green, allowing traffic to pass.\nYellow: The light is yellow, warning that the light is about to turn red.\nRed: The light is red, stopping traffic.\n\nDefine the Transitions: The transitions are all triggered by a timer expiring.\n\nGreen to Yellow: This transition occurs when the FSM is in the Green state and the green_timer_expired input becomes true.\nYellow to Red: This transition occurs when the FSM is in the Yellow state and the yellow_timer_expired input becomes true.\nRed to Green: This transition occurs when the FSM is in the Red state and the red_timer_expired input becomes true, completing the cycle.\n\n\n\nAnswer: The FSM has three states: Green, Yellow, and Red. It transitions sequentially from Green to Yellow, Yellow to Red, and Red back to Green, with each transition triggered by the expiration of a timer associated with the current state.",
    "crumbs": [
      "Computer Architecture",
      "2. Hierarchy of Memories, Moore's Law, Parallelism, Pipelining, and Design Principles"
    ]
  },
  {
    "objectID": "Mathematical Analysis I/lec_2.html",
    "href": "Mathematical Analysis I/lec_2.html",
    "title": "2. Functions and Their Graphs, Elementary Functions and Properties",
    "section": "",
    "text": "QUIZ | FLASHCARDS\n\n1. Summary\n\n1.1 Core Concepts of Functions\nA function is a rule that assigns a single, unique output to every input. The set of all permissible inputs is called the domain, and the set of all resulting outputs is the range. If a function f takes an input x to produce an output y, we write \\(y = f(x)\\).\n\nImplicit Domain: When a function is defined by a formula without a specified domain, the domain is assumed to be the largest set of real numbers for which the formula gives real-valued outputs. For example, for \\(f(x) = \\frac{1}{x-2}\\), the domain is all real numbers except \\(x=2\\).\nGraph of a Function: The graph is a visual representation consisting of all points \\((x, f(x))\\) on the Cartesian plane. The value \\(f(x)\\) represents the height of the graph at point \\(x\\). The formal definition of the graph is the set \\(\\{(x, f(x)) | x \\in D\\}\\), where \\(D\\) is the domain.\n\n\n\n\n1.2 Special Step Functions: Floor and Ceiling\n\nFloor Function (Greatest Integer Function): Denoted \\(\\lfloor x \\rfloor\\), this function rounds a number down to the greatest integer less than or equal to \\(x\\). For example, \\(\\lfloor 3.7 \\rfloor = 3\\) and \\(\\lfloor -2.1 \\rfloor = -3\\).\nCeiling Function (Least Integer Function): Denoted \\(\\lceil x \\rceil\\), this function rounds a number up to the smallest integer greater than or equal to \\(x\\). For example, \\(\\lceil 3.7 \\rceil = 4\\) and \\(\\lceil -2.1 \\rceil = -2\\).\n\n\n\n\n1.3 Function Behavior: Monotonicity\nA function is monotone on an interval if it consistently increases or decreases.\n\nIncreasing: \\(f(x_1) \\le f(x_2)\\) whenever \\(x_1 &lt; x_2\\).\nStrictly Increasing: \\(f(x_1) &lt; f(x_2)\\) whenever \\(x_1 &lt; x_2\\).\nDecreasing: \\(f(x_1) \\ge f(x_2)\\) whenever \\(x_1 &lt; x_2\\).\nStrictly Decreasing: \\(f(x_1) &gt; f(x_2)\\) whenever \\(x_1 &lt; x_2\\).\n\nA function that is strictly monotone (either strictly increasing or strictly decreasing) on its domain is guaranteed to be one-to-one.\n\n\n1.4 Combining Functions\nFunctions can be combined arithmetically or through composition. For arithmetic combinations, the domain is the intersection of the individual domains.\n\nArithmetic Operations: \\((f+g)(x) = f(x)+g(x)\\); \\((f-g)(x) = f(x)-g(x)\\); \\((fg)(x) = f(x)g(x)\\); and \\((f/g)(x) = f(x)/g(x)\\), with the added domain restriction that \\(g(x) \\neq 0\\).\nComposition: The composition \\((f \\circ g)(x)\\) is defined as \\(f(g(x))\\). The input \\(x\\) must be in the domain of \\(g\\), and the output \\(g(x)\\) must be in the domain of \\(f\\). The order of composition is critical, as \\((f \\circ g)(x)\\) is generally not equal to \\((g \\circ f)(x)\\).\n\n\n\n\n1.5 Inverse Functions\n\nOne-to-One Function: A function is one-to-one if no two distinct inputs produce the same output. This can be verified visually with the horizontal line test—if no horizontal line intersects the graph more than once, the function is one-to-one.\nInverse Function: If a function \\(f\\) is one-to-one, it has an inverse function, denoted \\(f^{-1}\\), that “reverses” its action. If \\(f(a) = b\\), then \\(f^{-1}(b) = a\\). The domain of \\(f^{-1}\\) is the range of \\(f\\), and the range of \\(f^{-1}\\) is the domain of \\(f\\). The graph of \\(f^{-1}\\) is a reflection of the graph of \\(f\\) across the line \\(y=x\\).\n\n\n\n1.6 Function Symmetry: Even and Odd Functions\nFor a function to be even or odd, its domain must be symmetric about the origin (if \\(x\\) is in the domain, \\(-x\\) must also be).\n\nEven Function: \\(f\\) is even if \\(f(-x) = f(x)\\). Its graph is symmetric with respect to the y-axis (e.g., \\(f(x) = x^2\\), \\(f(x) = \\cos x\\)).\nOdd Function: \\(f\\) is odd if \\(f(-x) = -f(x)\\). Its graph is symmetric with respect to the origin (e.g., \\(f(x) = x^3\\), \\(f(x) = \\sin x\\)).\n\nAny function with a symmetric domain can be uniquely decomposed into the sum of an even and an odd function:\n\nEven Part: \\(f_{\\text{even}}(x) = \\frac{f(x) + f(-x)}{2}\\)\nOdd Part: \\(f_{\\text{odd}}(x) = \\frac{f(x) - f(-x)}{2}\\)\n\n\n\n1.7 Elementary Functions\n\n1.7.1 Power, Polynomial, and Rational Functions\n\nPower Function: A function of the form \\(f(x) = x^a\\), where \\(a\\) is a real number. This includes integer powers (\\(x^2\\)), roots (\\(x^{1/2} = \\sqrt{x}\\)), and reciprocals (\\(x^{-1} = 1/x\\)).\nPolynomial Function: A sum of power functions with non-negative integer exponents: \\(p(x) = a_n x^n + \\dots + a_1 x + a_0\\). The highest exponent \\(n\\) is the degree of the polynomial.\nRational Function: A ratio of two polynomials, \\(f(x) = \\frac{p(x)}{q(x)}\\). Its domain excludes any values of \\(x\\) for which \\(q(x)=0\\).\n\n\n\n1.7.2 Exponential and Logarithmic Functions\n\nExponential Function: \\(f(x) = a^x\\), where the base \\(a &gt; 0\\) and \\(a \\neq 1\\). Its domain is all real numbers, and its range is \\((0, \\infty)\\).\nLogarithmic Function: \\(f(x) = \\log_a(x)\\), the inverse of the exponential function. The expression \\(\\log_a(x)\\) gives the exponent to which the base \\(a\\) must be raised to obtain \\(x\\). Its domain is \\((0, \\infty)\\), and its range is all real numbers.\n\n\n\n1.7.3 Trigonometric Functions and Their Inverses\nTrigonometric functions relate an angle \\(\\theta\\) to the coordinates \\((x, y)\\) of a point on a circle of radius \\(r\\). They are periodic, meaning their values repeat.\n\nDefinitions: \\(\\sin \\theta = y/r\\), \\(\\cos \\theta = x/r\\), \\(\\tan \\theta = y/x\\), etc.\nPeriodicity: The period of \\(\\sin x, \\cos x, \\sec x, \\csc x\\) is \\(2\\pi\\). The period of \\(\\tan x\\) and \\(\\cot x\\) is \\(\\pi\\).\nInverse Trigonometric Functions: Because they are not one-to-one, we must restrict the domain of trigonometric functions to create their inverses (e.g., \\(\\arcsin x\\), \\(\\arccos x\\)). For example, \\(\\arcsin x\\) is defined for inputs in \\([-1, 1]\\) and produces an angle in \\([-\\pi/2, \\pi/2]\\).\n\n\n\n\n1.7.4 Hyperbolic Functions and Their Inverses\nHyperbolic functions are combinations of exponential functions and are analogous to trigonometric functions.\n\nDefinitions: \\(\\sinh x = \\frac{e^x - e^{-x}}{2}\\) and \\(\\cosh x = \\frac{e^x + e^{-x}}{2}\\). The other four are defined similarly to their trigonometric counterparts (e.g., \\(\\tanh x = \\sinh x / \\cosh x\\)).\nInverse Hyperbolic Functions: These are the inverses of the hyperbolic functions (with domain restrictions where needed, like for \\(\\cosh x\\)). They can be expressed using natural logarithms. For instance, \\(\\text{arsinh}(x) = \\ln(x + \\sqrt{x^2+1})\\).\n\n\n\n\n\n2. Definitions\n\nFunction: A rule assigning each input from a domain to exactly one output.\nDomain: The set of all possible input values for a function.\nRange: The set of all possible output values of a function.\nOne-to-One Function: A function where each output corresponds to a unique input.\nInverse Function (\\(f^{-1}\\)): A function that reverses the mapping of a one-to-one function.\nEven Function: A function satisfying \\(f(-x) = f(x)\\), symmetric about the y-axis.\nOdd Function: A function satisfying \\(f(-x) = -f(x)\\), symmetric about the origin.\nPeriodic Function: A function that repeats its values at regular intervals (the period).\nPolynomial: A function expressed as a sum of non-negative integer powers of a variable.\nDegree of a Polynomial: The highest exponent of the variable in a polynomial.\nRational Function: A function that is the ratio of two polynomials.\nExponential Function: A function of the form \\(f(x) = a^x\\) where \\(a\\) is a positive constant.\nLogarithmic Function: The inverse of an exponential function, \\(f(x) = \\log_a(x)\\).\nHyperbolic Functions: Functions defined as combinations of \\(e^x\\) and \\(e^{-x}\\), such as \\(\\sinh x\\) and \\(\\cosh x\\).\nComposition of Functions: An operation \\((f \\circ g)(x) = f(g(x))\\) where one function is applied to the result of another.\n\n\n\n3. Formulas\n\nEven Part of a Function: \\(f_{\\text{even}}(x) = \\frac{f(x) + f(-x)}{2}\\)\nOdd Part of a Function: \\(f_{\\text{odd}}(x) = \\frac{f(x) - f(-x)}{2}\\)\nComposition: \\((f \\circ g)(x) = f(g(x))\\)\nPythagorean Identities:\n\n\\(\\sin^2 x + \\cos^2 x = 1\\)\n\\(1 + \\tan^2 x = \\sec^2 x\\)\n\\(1 + \\cot^2 x = \\csc^2 x\\)\n\nAngle Addition Formulas:\n\n\\(\\sin(x \\pm y) = \\sin x \\cos y \\pm \\cos x \\sin y\\)\n\\(\\cos(x \\pm y) = \\cos x \\cos y \\mp \\sin x \\sin y\\)\n\nHyperbolic Identity: \\(\\cosh^2 x - \\sinh^2 x = 1\\)\nHyperbolic Definitions:\n\n\\(\\sinh x = \\frac{e^x - e^{-x}}{2}\\)\n\\(\\cosh x = \\frac{e^x + e^{-x}}{2}\\)\n\nInverse Trig Complementary Angles: \\(\\arcsin x + \\arccos x = \\frac{\\pi}{2}\\)\nLogarithmic Forms of Inverse Hyperbolic Functions:\n\n\\(\\text{arsinh}(x) = \\ln(x + \\sqrt{x^2+1})\\)\n\\(\\text{arcosh}(x) = \\ln(x + \\sqrt{x^2-1})\\) for \\(x \\ge 1\\)\n\\(\\text{artanh}(x) = \\frac{1}{2} \\ln\\left(\\frac{1+x}{1-x}\\right)\\) for \\(|x| &lt; 1\\)\n\nChange of Logarithm Base: \\(\\log_b a = \\frac{\\ln a}{\\ln b}\\)\n\n\n\n4. Mistakes\n\nConfusing Inverse Notation for a Reciprocal: Interpreting \\(f^{-1}(x)\\) as \\(1/f(x)\\). Why it’s wrong: The \\(-1\\) superscript denotes an inverse function, which “undoes” the function’s operation. For example, \\(\\sin^{-1}(x)\\) is \\(\\arcsin(x)\\), whereas \\((\\sin x)^{-1}\\) is \\(1/\\sin x = \\csc x\\).\nAssuming Function Composition is Commutative: Thinking that \\(f(g(x))\\) is always the same as \\(g(f(x))\\). Why it’s wrong: The order of operations matters. Applying function \\(g\\) then function \\(f\\) is a different sequence of transformations than applying \\(f\\) then \\(g\\).\nIncorrectly Simplifying Logarithms: Applying rules that don’t exist, such as writing \\(\\ln(a+b)\\) as \\(\\ln(a) + \\ln(b)\\). Why it’s wrong: Logarithm rules apply to products, quotients, and powers, not sums or differences. The correct rule is \\(\\ln(ab) = \\ln(a) + \\ln(b)\\).\nMixing Up Trigonometric and Hyperbolic Identities: Believing that \\(\\sinh^2 x + \\cosh^2 x = 1\\). Why it’s wrong: While analogous, the main hyperbolic identity has a minus sign: \\(\\cosh^2 x - \\sinh^2 x = 1\\). This difference stems from their definitions using exponential functions.\nIgnoring the Domain and Range of Inverse Trig Functions: Calculating \\(\\arcsin(\\sin(2\\pi))\\) as \\(2\\pi\\). Why it’s wrong: The range of \\(\\arcsin(x)\\) is restricted to \\([-\\pi/2, \\pi/2]\\). The correct evaluation is \\(\\sin(2\\pi) = 0\\), and \\(\\arcsin(0) = 0\\). The formula \\(\\arcsin(\\sin(x)) = x\\) is only valid for \\(x\\) within the restricted range.\nForgetting to Find the Domain of a Composite Function Correctly: To find the domain of \\(f(g(x))\\), only considering the domain of the final simplified function. Why it’s wrong: The domain must satisfy two conditions: \\(x\\) must be in the domain of the inner function \\(g\\), and the output \\(g(x)\\) must be in the domain of the outer function \\(f\\).\n\n\n\n5. Examples\n\n5.1. Domain of a Composite Function\nQuestion: Let \\(f(x) = \\sqrt{x-4}\\) and \\(g(x) = x^2\\). Find the domain of \\((f \\circ g)(x)\\).\n\n\nClick to see the solution\n\n\nWrite the composite function: \\[ (f \\circ g)(x) = f(g(x)) = f(x^2) = \\sqrt{x^2 - 4} \\]\nDetermine the domain condition for the outer function f: The input to \\(f(u) = \\sqrt{u-4}\\) must be greater than or equal to 4. So, \\(u \\ge 4\\).\nApply this condition to the inner function g(x): The output of \\(g(x)\\), which is \\(x^2\\), becomes the input for \\(f\\). Therefore, we must have: \\[ x^2 \\ge 4 \\]\nSolve the inequality: Taking the square root of both sides gives \\(|x| \\ge 2\\). This means \\(x \\ge 2\\) or \\(x \\le -2\\).\nCheck the domain of g(x): The domain of \\(g(x)=x^2\\) is all real numbers, so this adds no further restrictions.\n\nAnswer: The domain is \\((-\\infty, -2] \\cup [2, \\infty)\\).\n\n\n\n5.2. Decomposing a Function into Even and Odd Parts\nQuestion: Decompose the function \\(f(x) = e^x\\) into its even and odd parts.\n\n\nClick to see the solution\n\n\nFind \\(f(-x)\\): \\[ f(-x) = e^{-x} \\]\nUse the formula for the even part: \\[ f_{\\text{even}}(x) = \\frac{f(x) + f(-x)}{2} = \\frac{e^x + e^{-x}}{2} \\]\nRecognize the result: This is the definition of the hyperbolic cosine. \\[ f_{\\text{even}}(x) = \\cosh(x) \\]\nUse the formula for the odd part: \\[ f_{\\text{odd}}(x) = \\frac{f(x) - f(-x)}{2} = \\frac{e^x - e^{-x}}{2} \\]\nRecognize the result: This is the definition of the hyperbolic sine. \\[ f_{\\text{odd}}(x) = \\sinh(x) \\]\n\nAnswer: The even part is \\(\\cosh(x)\\) and the odd part is \\(\\sinh(x)\\). (Thus, \\(e^x = \\cosh x + \\sinh x\\)).\n\n\n\n5.3. Proving a Trigonometric Identity\nQuestion: Prove the identity \\(\\frac{\\sin(2x)}{1 + \\cos(2x)} = \\tan(x)\\).\n\n\nClick to see the solution\n\n\nRecall the double-angle formulas:\n\n\\(\\sin(2x) = 2 \\sin x \\cos x\\)\n\\(\\cos(2x) = \\cos^2 x - \\sin^2 x\\). Another useful form is \\(2\\cos^2 x - 1\\).\n\nSubstitute the formulas into the left-hand side: Using the form \\(\\cos(2x) = 2\\cos^2 x - 1\\) will be helpful for simplifying the denominator. \\[ \\frac{2 \\sin x \\cos x}{1 + (2\\cos^2 x - 1)} \\]\nSimplify the denominator: \\[ \\frac{2 \\sin x \\cos x}{2\\cos^2 x} \\]\nCancel common terms: Cancel the 2 and one factor of cos x from the numerator and denominator. \\[ \\frac{\\sin x}{\\cos x} \\]\nRecognize the result: This is the definition of \\(\\tan x\\). The left side equals the right side.\n\nAnswer: The identity is proven.\n\n\n\n5.4. Finding an Inverse Function\nQuestion: Find the inverse of the function \\(f(x) = 5e^{2x} - 3\\).\n\n\nClick to see the solution\n\n\nReplace \\(f(x)\\) with \\(y\\): \\[ y = 5e^{2x} - 3 \\]\nSwap \\(x\\) and \\(y\\): \\[ x = 5e^{2y} - 3 \\]\nSolve for \\(y\\) by isolating the exponential term: \\[ x + 3 = 5e^{2y} \\] \\[ \\frac{x+3}{5} = e^{2y} \\]\nTake the natural logarithm of both sides: \\[ \\ln\\left(\\frac{x+3}{5}\\right) = \\ln(e^{2y}) \\] \\[ \\ln\\left(\\frac{x+3}{5}\\right) = 2y \\]\nIsolate \\(y\\): \\[ y = \\frac{1}{2} \\ln\\left(\\frac{x+3}{5}\\right) \\]\nReplace \\(y\\) with \\(f^{-1}(x)\\): \\[ f^{-1}(x) = \\frac{1}{2} \\ln\\left(\\frac{x+3}{5}\\right) \\]\n\nAnswer: The inverse function is \\(f^{-1}(x) = \\frac{1}{2} \\ln\\left(\\frac{x+3}{5}\\right)\\).\n\n\n\n5.5. Using Inverse Trigonometric Relationships\nQuestion: Find the exact value of \\(\\tan(\\arccos(\\frac{3}{5}))\\).\n\n\nClick to see the solution\n\n\nSet up the problem: Let \\(\\theta = \\arccos(\\frac{3}{5})\\). This means \\(\\cos(\\theta) = \\frac{3}{5}\\) and \\(\\theta\\) is in the interval \\([0, \\pi]\\).\nVisualize with a right triangle: Since \\(\\cos(\\theta)\\) is positive, \\(\\theta\\) is in Quadrant I. We can draw a right triangle where the adjacent side is 3 and the hypotenuse is 5.\n\n\n\nFind the missing side: Use the Pythagorean theorem to find the opposite side (\\(o\\)). \\[ 3^2 + o^2 = 5^2 \\] \\[ 9 + o^2 = 25 \\] \\[ o^2 = 16 \\implies o = 4 \\]\nCalculate the tangent: The problem is now to find \\(\\tan(\\theta)\\). From the triangle, \\(\\tan(\\theta) = \\frac{\\text{opposite}}{\\text{adjacent}}\\). \\[ \\tan(\\theta) = \\frac{4}{3} \\]\n\nAnswer: \\(\\frac{4}{3}\\).\n\n\n\n5.6. Converting Inverse Hyperbolic Functions\nQuestion: Express \\(\\text{artanh}(1/2)\\) in terms of a natural logarithm.\n\n\nClick to see the solution\n\n\nRecall the logarithmic formula for artanh(x): \\[ \\text{artanh}(x) = \\frac{1}{2} \\ln\\left(\\frac{1+x}{1-x}\\right) \\]\nSubstitute \\(x = 1/2\\) into the formula: \\[ \\text{artanh}(1/2) = \\frac{1}{2} \\ln\\left(\\frac{1+1/2}{1-1/2}\\right) \\]\nSimplify the fraction inside the logarithm: \\[ \\frac{1+1/2}{1-1/2} = \\frac{3/2}{1/2} = 3 \\]\nWrite the final expression: \\[ \\text{artanh}(1/2) = \\frac{1}{2} \\ln(3) \\]\n\nAnswer: \\(\\frac{1}{2} \\ln(3)\\) or \\(\\ln(\\sqrt{3})\\).\n\n\n\n5.7. Proving an Inverse Trig Identity\nQuestion: Prove that \\(\\arcsin(-x) = -\\arcsin(x)\\).\n\n\nClick to see the solution\n\n\nStart with the definition: Let \\(\\theta = \\arcsin(-x)\\). By definition, this means:\n\n\\(\\sin(\\theta) = -x\\)\n\\(-\\frac{\\pi}{2} \\le \\theta \\le \\frac{\\pi}{2}\\)\n\nManipulate the equation: Multiply both sides of \\(\\sin(\\theta) = -x\\) by -1 to get: \\[ -\\sin(\\theta) = x \\]\nUse the property of the sine function: Sine is an odd function, so \\(-\\sin(\\theta) = \\sin(-\\theta)\\). \\[ \\sin(-\\theta) = x \\]\nConsider the range: Since \\(-\\frac{\\pi}{2} \\le \\theta \\le \\frac{\\pi}{2}\\), multiplying by -1 reverses the inequalities, giving \\(\\frac{\\pi}{2} \\ge -\\theta \\ge -\\frac{\\pi}{2}\\). The angle \\(-\\theta\\) is also in the valid range for the output of arcsin.\nTake the arcsin of both sides: From \\(\\sin(-\\theta) = x\\), we can conclude that: \\[ -\\theta = \\arcsin(x) \\]\nSubstitute back: We started with \\(\\theta = \\arcsin(-x)\\). Substitute this back into the equation. \\[ -(\\arcsin(-x)) = \\arcsin(x) \\] Multiplying by -1 gives the desired identity. \\[ \\arcsin(-x) = -\\arcsin(x) \\]\n\nAnswer: The identity is proven.",
    "crumbs": [
      "Mathematical Analysis I",
      "2. Functions and Their Graphs, Elementary Functions and Properties"
    ]
  }
]