[
  {
    "objectID": "Mathematical Analysis I/lec_1.html",
    "href": "Mathematical Analysis I/lec_1.html",
    "title": "1. Set Theory, Complex Numbers, Mathematical Induction",
    "section": "",
    "text": "1. Summary\n\n1.1 Basics of Set Theory\nA set is a collection of distinct objects, known as elements or members. The language of sets is fundamental to modern mathematics.\n\nNotation: Sets are typically denoted by capital letters (e.g., \\(A\\), \\(B\\), \\(X\\)), and their elements are listed within curly braces {}. For example, the set \\(A = \\{1, 2, 3\\}\\) contains the elements 1, 2, and 3.\nSet-Builder Notation: A set can also be defined by a property that its elements must satisfy. The notation \\(A = \\{x \\in X \\mid p(x)\\}\\) defines a set \\(A\\) that contains all elements \\(x\\) from a larger set \\(X\\) for which the property \\(p(x)\\) is true.\nSubsets: If every element of a set \\(A\\) is also an element of a set \\(X\\), then \\(A\\) is a subset of \\(X\\), denoted as \\(A \\subseteq X\\). If \\(A\\) is a subset of \\(X\\) but is not equal to \\(X\\), it is a proper subset, denoted \\(A \\subset X\\).\nPower Set: The power set of a set \\(X\\), denoted \\(\\mathcal{P}(X)\\), is the set of all possible subsets of \\(X\\). If \\(X\\) has \\(n\\) elements, its power set \\(\\mathcal{P}(X)\\) has \\(2^n\\) elements.\nSet Operations:\n\nUnion (\\(A \\cup B\\)): The set of all elements that are in set \\(A\\), or in set \\(B\\), or in both.\nIntersection (\\(A \\cap B\\)): The set of all elements that are in both set \\(A\\) and set \\(B\\).\nComplement (\\(A^c\\) or \\(A'\\)): The set of all elements in the universal set \\(X\\) that are not in set \\(A\\).\n\n\n\n\n1.2 Complex Numbers\nComplex numbers extend the concept of one-dimensional real numbers to a two-dimensional plane. They are essential in many fields of science and engineering.\n\nDefinition: A complex number, \\(z\\), is a number of the form \\(z = a + bi\\), where \\(a\\) and \\(b\\) are real numbers, and \\(i\\) is the imaginary unit, defined by the property \\(i^2 = -1\\).\n\n\\(a\\) is called the real part, denoted \\(\\text{Re}(z)\\).\n\\(b\\) is called the imaginary part, denoted \\(\\text{Im}(z)\\).\n\nGeometric Representation: Every complex number \\(z = a + bi\\) can be visualized as a point \\((a, b)\\) in a two-dimensional Cartesian plane called the complex plane or Argand plane. The horizontal axis is the real axis, and the vertical axis is the imaginary axis.\n\n\nTrigonometric and Exponential Forms: A complex number can also be represented using polar coordinates \\((r, \\theta)\\).\n\nThe distance \\(r\\) from the origin is the modulus or absolute value, given by \\(r = |z| = \\sqrt{a^2 + b^2}\\).\nThe angle \\(\\theta\\) from the positive real axis is the argument, given by \\(\\theta = \\arctan\\left(\\frac{b}{a}\\right)\\), adjusted for the correct quadrant.\nThis leads to the trigonometric form: \\(z = r(\\cos\\theta + i\\sin\\theta)\\).\nUsing Euler’s Formula, \\(e^{i\\theta} = \\cos\\theta + i\\sin\\theta\\), we get the exponential (or polar) form: \\(z = re^{i\\theta}\\).\n\nDe Moivre’s Theorem: For any integer \\(n\\), this theorem provides a formula for calculating powers of complex numbers: \\[ z^n = [r(\\cos\\theta + i\\sin\\theta)]^n = r^n(\\cos(n\\theta) + i\\sin(n\\theta)) \\]\n\n\n\n1.3 Principles of Mathematical Induction\nMathematical induction is a powerful proof technique used to prove that a statement, formula, or property \\(P(n)\\) is true for all natural numbers \\(n\\) (or all integers from a certain starting point). It is analogous to a chain of dominoes falling.\nThe proof consists of three logical steps:\n\nBase Case: Prove that the statement \\(P(n)\\) is true for the first possible value of \\(n\\) (usually \\(n=1\\)). This is like tipping the first domino.\nInductive Hypothesis: Assume that the statement \\(P(k)\\) is true for some arbitrary natural number \\(k\\). This is the assumption that if any given domino falls…\nInductive Step: Using the inductive hypothesis, prove that the statement \\(P(k+1)\\) must also be true. …then the next domino in the line will also fall.\n\nOnce these three steps are successfully completed, we can conclude that the statement \\(P(n)\\) is true for all natural numbers \\(n \\ge 1\\).\n\n\n\n2. Definitions\n\nSet: A well-defined collection of distinct objects.\nSubset: A set \\(A\\) is a subset of \\(B\\) if all elements of \\(A\\) are also elements of \\(B\\).\nPower Set: The set of all subsets of a given set.\nUnion: The set of elements present in either of two sets.\nIntersection: The set of elements common to two sets.\nComplement: The set of elements not in a given set, relative to a universal set.\nComplex Number: A number of the form \\(a+bi\\), where \\(a, b\\) are real numbers and \\(i = \\sqrt{-1}\\).\nImaginary Unit (\\(i\\)): The number defined by the property \\(i^2 = -1\\).\nComplex Plane (Argand Plane): The two-dimensional plane where complex numbers are represented geometrically.\nMathematical Induction: A method of mathematical proof used to establish that a given statement is true for all natural numbers.\n\n\n\n3. Formulas\n\nCardinality of Power Set: For a set \\(X\\) with \\(n\\) elements, \\(|\\mathcal{P}(X)| = 2^n\\).\nUnion: \\(A \\cup B = \\{x \\mid x \\in A \\text{ or } x \\in B\\}\\).\nIntersection: \\(A \\cap B = \\{x \\mid x \\in A \\text{ and } x \\in B\\}\\).\nComplex Number Standard Form: \\(z = a + bi\\).\nImaginary Unit: \\(i = \\sqrt{-1}\\).\nModulus of a Complex Number: \\(r = |z| = \\sqrt{a^2 + b^2}\\).\nArgument of a Complex Number: \\(\\theta = \\arctan\\left(\\frac{b}{a}\\right)\\).\nTrigonometric Form: \\(z = r(\\cos\\theta + i\\sin\\theta)\\).\nEuler’s Formula: \\(e^{i\\theta} = \\cos\\theta + i\\sin\\theta\\).\nExponential (Polar) Form: \\(z = re^{i\\theta}\\).\nDe Moivre’s Theorem: \\(z^n = r^n(\\cos(n\\theta) + i\\sin(n\\theta))\\).\n\n\n\n4. Mistakes\n\nConfusing the Imaginary Part with the Imaginary Term: The imaginary part of \\(a+bi\\) is the real number \\(b\\), not \\(bi\\). Why it’s wrong: The imaginary part is a real-valued coefficient of the imaginary unit \\(i\\).\nForgetting the Base Case in Induction: Starting an induction proof with the inductive hypothesis without first proving the statement for the initial value (e.g., \\(n=1\\)). Why it’s wrong: The inductive step only proves that if one domino falls, the next one does. The base case proves that the first domino actually falls, starting the chain reaction. Without it, the entire proof is invalid.\nIncorrectly Applying De Moivre’s Theorem: When calculating \\((r(\\cos\\theta + i\\sin\\theta))^n\\), a common mistake is to forget to raise the modulus \\(r\\) to the power of \\(n\\), resulting in \\(r(\\cos(n\\theta) + i\\sin(n\\theta))\\). Why it’s wrong: The theorem requires both the modulus to be raised to the power and the argument to be multiplied by it.\nCircular Reasoning in the Inductive Step: Assuming \\(P(k+1)\\) is true to prove that \\(P(k+1)\\) is true. You must only use the assumption that \\(P(k)\\) is true. Why it’s wrong: This is a logical fallacy. The goal is to show that \\(P(k)\\) implies \\(P(k+1)\\), not that \\(P(k+1)\\) implies itself.\nMistaking Subset for Element: Confusing the relationships “is an element of” (\\(\\in\\)) and “is a subset of” (\\(\\subseteq\\)). For example, for the set \\(A = \\{1, 2\\}\\), the number \\(1\\) is an element (\\(1 \\in A\\)), but the set \\(\\{1\\}\\) is a subset (\\(\\{1\\} \\subseteq A\\)). Why it’s wrong: Sets contain elements, but they can also contain other sets as elements. The distinction is crucial for operations like the power set.\n\n\n\n5. Examples\n\nExample 1: Simplifying Complex Numbers\nQuestion: Express \\((2+3i)^2\\) in the form \\(X+Yi\\).\n\n\nClick to see the solution\n\n\nExpand the expression using the formula \\((a+b)^2 = a^2 + 2ab + b^2\\). \\[ (2+3i)^2 = (2)^2 + 2(2)(3i) + (3i)^2 \\]\nSimplify each term. \\[ = 4 + 12i + 9i^2 \\]\nSubstitute \\(i^2 = -1\\). \\[ = 4 + 12i + 9(-1) \\] \\[ = 4 + 12i - 9 \\]\nCombine the real parts. \\[ = (4-9) + 12i = -5 + 12i \\]\n\nAnswer: \\(-5 + 12i\\)\n\n\n\nExample 2: Complex Number Division\nQuestion: Express \\(\\frac{3-4i}{5+2i}\\) in the form \\(X+Yi\\).\n\n\nClick to see the solution\n\n\nFind the conjugate of the denominator. The conjugate of \\(5+2i\\) is \\(5-2i\\).\nMultiply the numerator and denominator by the conjugate. \\[ \\frac{3-4i}{5+2i} \\times \\frac{5-2i}{5-2i} = \\frac{(3-4i)(5-2i)}{(5+2i)(5-2i)} \\]\nExpand the numerator: \\((3)(5) + (3)(-2i) + (-4i)(5) + (-4i)(-2i) = 15 - 6i - 20i + 8i^2\\).\nExpand the denominator: \\((5)^2 - (2i)^2 = 25 - 4i^2\\).\nSubstitute \\(i^2 = -1\\) in both numerator and denominator and simplify.\n\nNumerator: \\(15 - 26i + 8(-1) = 15 - 26i - 8 = 7 - 26i\\).\nDenominator: \\(25 - 4(-1) = 25 + 4 = 29\\).\n\nWrite the final fraction. \\[ \\frac{7 - 26i}{29} = \\frac{7}{29} - \\frac{26}{29}i \\]\n\nAnswer: \\(\\frac{7}{29} - \\frac{26}{29}i\\)\n\n\n\nExample 3: Finding Trigonometric and Exponential Forms\nQuestion: Write the complex number \\(Z = 1+i\\) in trigonometric and exponential forms.\n\n\nClick to see the solution\n\n\nIdentify the real and imaginary parts: \\(a=1\\) and \\(b=1\\).\nCalculate the modulus (\\(r\\)): \\[ r = \\sqrt{a^2 + b^2} = \\sqrt{1^2 + 1^2} = \\sqrt{2} \\]\nCalculate the argument (\\(\\theta\\)): \\[ \\theta = \\arctan\\left(\\frac{b}{a}\\right) = \\arctan\\left(\\frac{1}{1}\\right) = \\frac{\\pi}{4} \\text{ radians (or 45°)} \\] (Since a and b are both positive, the point is in the first quadrant, so the angle is correct.)\nWrite the trigonometric form \\(z = r(\\cos\\theta + i\\sin\\theta)\\). \\[ Z = \\sqrt{2}\\left(\\cos\\left(\\frac{\\pi}{4}\\right) + i\\sin\\left(\\frac{\\pi}{4}\\right)\\right) \\]\nWrite the exponential form \\(z = re^{i\\theta}\\). \\[ Z = \\sqrt{2}e^{i\\frac{\\pi}{4}} \\]\n\nAnswer: * Trigonometric: \\(\\sqrt{2}\\left(\\cos\\left(\\frac{\\pi}{4}\\right) + i\\sin\\left(\\frac{\\pi}{4}\\right)\\right)\\) * Exponential: \\(\\sqrt{2}e^{i\\frac{\\pi}{4}}\\)\n\n\n\nExample 4: Using De Moivre’s Theorem\nQuestion: Simplify \\(Z = (2+2i)^3\\) using De Moivre’s Theorem.\n\n\nClick to see the solution\n\n\nConvert the base (\\(2+2i\\)) to trigonometric form.\n\n\\(a=2\\), \\(b=2\\).\nModulus \\(r = \\sqrt{2^2 + 2^2} = \\sqrt{4+4} = \\sqrt{8} = 2\\sqrt{2}\\).\nArgument \\(\\theta = \\arctan\\left(\\frac{2}{2}\\right) = \\arctan(1) = \\frac{\\pi}{4}\\).\nSo, \\(2+2i = 2\\sqrt{2}\\left(\\cos\\left(\\frac{\\pi}{4}\\right) + i\\sin\\left(\\frac{\\pi}{4}\\right)\\right)\\).\n\nApply De Moivre’s Theorem, with \\(n=3\\). \\[ Z = \\left(2\\sqrt{2}\\right)^3\\left(\\cos\\left(3 \\cdot \\frac{\\pi}{4}\\right) + i\\sin\\left(3 \\cdot \\frac{\\pi}{4}\\right)\\right) \\]\nSimplify the modulus and the argument.\n\n\\((2\\sqrt{2})^3 = 2^3 \\cdot (\\sqrt{2})^3 = 8 \\cdot 2\\sqrt{2} = 16\\sqrt{2}\\).\n\\(3 \\cdot \\frac{\\pi}{4} = \\frac{3\\pi}{4}\\).\n\\(Z = 16\\sqrt{2}\\left(\\cos\\left(\\frac{3\\pi}{4}\\right) + i\\sin\\left(\\frac{3\\pi}{4}\\right)\\right)\\).\n\nConvert back to standard form \\(X+Yi\\).\n\n\\(\\cos\\left(\\frac{3\\pi}{4}\\right) = -\\frac{\\sqrt{2}}{2}\\).\n\\(\\sin\\left(\\frac{3\\pi}{4}\\right) = \\frac{\\sqrt{2}}{2}\\).\n\\(Z = 16\\sqrt{2}\\left(-\\frac{\\sqrt{2}}{2} + i\\frac{\\sqrt{2}}{2}\\right) = 16\\left(-\\frac{2}{2} + i\\frac{2}{2}\\right) = 16(-1+i)\\).\n\n\nAnswer: \\(-16 + 16i\\)\n\n\n\nExample 5: Proof by Mathematical Induction\nQuestion: Using the principles of mathematical induction, show that for all positive integer values of \\(n\\), \\(P(n) = 5^{2n} + 3n - 1\\) is an integer multiple of 9.\n\n\nClick to see the solution\n\n\nBase Case: Test for \\(n=1\\). \\[ P(1) = 5^{2(1)} + 3(1) - 1 = 25 + 3 - 1 = 27 \\] Since \\(27 = 9 \\times 3\\), the statement is true for \\(n=1\\).\nInductive Hypothesis: Assume the statement is true for some arbitrary positive integer \\(k\\). That is, assume \\(5^{2k} + 3k - 1\\) is a multiple of 9. This means we can write \\(5^{2k} + 3k - 1 = 9m\\) for some integer \\(m\\). From this, we can state: \\(5^{2k} = 9m - 3k + 1\\).\nInductive Step: Prove the statement is true for \\(n=k+1\\). We need to show that \\(P(k+1) = 5^{2(k+1)} + 3(k+1) - 1\\) is a multiple of 9. \\[ 5^{2(k+1)} + 3(k+1) - 1 = 5^{2k+2} + 3k + 3 - 1 \\] \\[ = 5^2 \\cdot 5^{2k} + 3k + 2 \\] \\[ = 25 \\cdot 5^{2k} + 3k + 2 \\] Now, substitute the expression for \\(5^{2k}\\) from our hypothesis: \\[ = 25(9m - 3k + 1) + 3k + 2 \\] \\[ = 225m - 75k + 25 + 3k + 2 \\] \\[ = 225m - 72k + 27 \\] Factor out 9 from the expression: \\[ = 9(25m - 8k + 3) \\] Since \\(m\\) and \\(k\\) are integers, \\((25m - 8k + 3)\\) is also an integer. Therefore, \\(P(k+1)\\) is a multiple of 9.\n\nAnswer: Since the base case is true and the inductive step holds, by the principle of mathematical induction, \\(5^{2n} + 3n - 1\\) is a multiple of 9 for all positive integers \\(n\\).",
    "crumbs": [
      "Mathematical Analysis I",
      "1. Set Theory, Complex Numbers, Mathematical Induction"
    ]
  },
  {
    "objectID": "Computer Architecture/lec_1.html",
    "href": "Computer Architecture/lec_1.html",
    "title": "1. Computer Architecture Fundamentals, CPU Components, Memory Hierarchy, FPGAs",
    "section": "",
    "text": "1. Summary\n\n1.1 What is a Computer?\nA computer is fundamentally a machine designed to perform sequences of arithmetic or logical operations automatically. Modern computers achieve this through a stored-program model, where an electronic device operates under the control of a program stored in its memory. At the most basic level, a computer takes binary input (data), manipulates it according to a binary program (a sequence of instructions), and produces binary output (a result). The two most essential components of any computer are the Processor (CPU), which executes instructions, and the Memory, which stores both instructions and data.\n\n\n1.2 What is Computer Architecture?\nComputer Architecture is the discipline that defines the conceptual design and fundamental operational structure of a computer system. It acts as the critical interface between the system’s hardware and its software. Studying computer architecture involves understanding three key areas:\n\nHardware Organization: The physical arrangement and interconnection of components like the CPU, memory, and storage.\nHardware/Software Interaction Principles: The rules and methods by which software commands and controls the hardware, primarily through the Instruction Set Architecture (ISA).\nPerformance-Related Aspects: The analysis and design of systems to achieve high performance, considering factors like speed, power consumption, and efficiency.\n\n\n\n1.3 The Problem-Solution Stack\nSolving a problem with a computer involves multiple layers of abstraction, from the physical world to the user’s program. This stack illustrates how each layer builds upon the one below it, hiding complexity.\n\nProblem to Solve: The high-level goal (e.g., “render a 3D image”).\nAlgorithm + Data Structures: The logical method and data organization to solve the problem.\nUser Program: The implementation of the algorithm in a high-level language (e.g., C++, Python).\nSystem Programs: The operating system and compilers that manage resources and translate the user program into machine-readable instructions.\nProcessor Instruction Set Architecture (ISA): The specific set of low-level commands the hardware can execute. This is the primary boundary between software and hardware.\nMicroarchitecture: The specific implementation of the ISA in hardware, including how components like the ALU and registers are arranged.\nLogic Circuits: The fundamental building blocks (like AND/OR gates) that compose the microarchitecture.\nElectrons/Photons: The physical principles that make the logic circuits work.\n\n\n\n1.4 Core Hardware Components\nA computer system is composed of several key hardware components that work together.\n\nCPU (Central Processing Unit): The “brain” of the computer, responsible for fetching, decoding, and executing program instructions. A CPU contains several key parts:\n\nControl Unit (CU): Directs the flow of operations, fetching the next instruction from memory.\nArithmetic Logic Unit (ALU): Performs all arithmetic (e.g., addition, subtraction) and logic (e.g., AND, OR) operations.\nRegisters: A small number of extremely fast memory locations located directly on the CPU chip. They hold data that is actively being used by the current instruction.\n\nThe Memory Hierarchy: Not all memory is created equal. To balance speed, cost, and capacity, computers use a tiered memory system. Accessing data is fastest at the top and becomes progressively slower—but larger and cheaper—at lower levels. The existence of this hierarchy is a solution to the memory wall problem, where CPUs can process data much faster than they can retrieve it from main memory.\n\nRegisters (Fastest, smallest, most expensive)\nCPU Cache (L1, L2, L3)\nSystem Memory (RAM)\nStorage Devices (SSD, HDD) (Slowest, largest, cheapest)\n\nCPU Cache: A small amount of very fast memory placed between the CPU and the main system memory. It stores frequently accessed data and instructions, allowing the CPU to avoid the slow trip to main memory. L1 cache is the smallest and fastest, typically embedded directly into each CPU core.\nCommunication Buses: These are the data highways that connect the various components (CPU to memory, CPU to I/O devices). The speed of these buses can be a major performance bottleneck.\nI/O (Input/Output) Devices: Peripherals that allow the computer to interact with the outside world, such as keyboards, monitors, printers, and network cards.\n\n\n\n1.5 Processors vs. FPGAs\nWhile both are silicon chips, CPUs and FPGAs have fundamentally different purposes.\n\nProcessor (CPU): A CPU is a fixed device. Its internal logic circuits are permanently designed to execute a specific, unchangeable set of commands known as its Instruction Set Architecture (ISA) (e.g., x86, ARM). You cannot change what a CPU does; you can only provide it with different software instructions from its predefined set.\nFPGA (Field Programmable Gate Array): An FPGA is not a processor. It is a blank slate of reconfigurable logic circuits. A developer can program an FPGA to create a custom hardware design, which could be a custom processor, a graphics pipeline, or any other digital circuit. Its key features are:\n\nIt can be reprogrammed multiple times.\nYou design the hardware itself, supporting only the instructions you need, which can make it much more efficient for specific tasks.\nFPGAs are often used to test and prototype new processor designs before committing to the expensive manufacturing of a fixed CPU.\n\n\n\n\n\n2. Definitions\n\nComputer Architecture: The design and organization of a computer system, focusing on the parts of the system visible to a programmer, primarily the Instruction Set Architecture (ISA).\nCPU (Central Processing Unit): The hardware component within a computer that carries out the instructions of a computer program by performing the basic arithmetic, logical, control, and input/output (I/O) operations specified by the instructions.\nALU (Arithmetic Logic Unit): A digital circuit inside the CPU that performs arithmetic (add, subtract, etc.) and logic (AND, OR, NOT) operations on integer binary numbers.\nCU (Control Unit): The component of the CPU that directs the operation of the processor. It tells the computer’s memory, arithmetic logic unit, and input and output devices how to respond to the instructions that have been sent to the processor.\nRegister: One of a small set of data holding places that are part of the CPU. A register can hold an instruction, a storage address, or any kind of data.\nMemory Hierarchy: A structure that uses a hierarchy of memory and storage devices to optimize performance. The levels are tiered based on speed, cost, and capacity, from fast, small, expensive registers to slow, large, cheap storage.\nCPU Cache: A smaller, faster memory, closer to a processor core, which stores copies of the data from frequently used main memory locations.\nInstruction Set Architecture (ISA): The part of the computer architecture related to programming, including the native data types, instructions, registers, addressing modes, and memory architecture. It is the abstract model of a computer.\nFPGA (Field Programmable Gate Array): An integrated circuit designed to be configured by a customer or a designer after manufacturing—hence the term “field-programmable.”\n\n\n\n3. Mistakes\n\nConfusing FPGAs with CPUs: Treating an FPGA as just another type of processor. Why it’s wrong: A CPU has a fixed, unchangeable hardware design built to execute a predefined instruction set. An FPGA is a “blank canvas” of programmable logic gates that has no inherent function until a hardware design is loaded onto it. An FPGA can be programmed to be a CPU, but it isn’t one by default.\nIgnoring the Memory Hierarchy: Writing software with the assumption that all memory accesses (e.g., to RAM or an SSD) are equally fast. Why it’s wrong: Accessing data in the L1 cache can be over 100 times faster than accessing it from main RAM. Efficient programs are designed to maximize cache hits (finding data in the cache) and minimize cache misses (having to fetch data from slower memory levels).\nBelieving More Gigahertz (GHz) is Always Better: Judging a processor’s performance solely by its clock speed. Why it’s wrong: Clock speed is only one piece of the puzzle. A processor with a lower clock speed but a more efficient ISA (e.g., executing more work per cycle), more cores, or a larger, faster cache can easily outperform a processor with a higher clock speed.\nTreating All CPU Architectures as the Same: Assuming that a program compiled for one type of processor (like an Intel x86 chip) will run on another (like an Apple M-series ARM chip). Why it’s wrong: Different architectures have different ISAs, meaning they understand completely different sets of machine-language instructions. Software must be compiled specifically for the target architecture.\n\n\n\n4. Examples\n\nExample 1: Memory Hierarchy Access Time\nQuestion: A program needs to process a large array of numbers. The programmer writes a loop that reads the first element, then the last element, then the second element, then the second-to-last, and so on, working from the outside in. Another programmer writes a simple loop that processes the elements in sequential order (1st, 2nd, 3rd, …). Which program is likely to be faster, and why?\n\n\nClick to see the solution\n\n\nAnalyze the access pattern: The first program jumps back and forth across a large memory region. The second program accesses contiguous memory locations one after another.\nConsider how caching works: When the CPU requests data from a memory address, it doesn’t just load that single piece of data into the cache. It loads a whole block of adjacent data (called a cache line), anticipating that the program will need nearby data soon.\nEvaluate the first program: The “outside-in” access pattern defeats the purpose of the cache. After accessing the first element, the CPU caches the next few elements. However, the program immediately jumps to the end of the array, causing a cache miss. This process repeats, leading to many cache misses and slow performance.\nEvaluate the second program: The sequential access pattern works perfectly with the cache. After accessing the first element, the next several elements are already loaded into the cache. The subsequent reads are therefore cache hits, which are extremely fast.\n\nAnswer: The second program (sequential access) will be significantly faster because its memory access pattern maximizes the use of the CPU cache and results in a high number of cache hits.\n\n\n\nExample 2: CPU vs. FPGA Application\nQuestion: You are tasked with designing a network router that must inspect every single data packet for a specific malicious pattern at extremely high speeds (billions of packets per second). Would a high-end, general-purpose CPU or an FPGA be a better choice for the core of this device? Explain your reasoning.\n\n\nClick to see the solution\n\n\nDefine the problem: The task is very specific, highly repetitive, and demands extreme performance and parallelism (inspecting many packets simultaneously).\nEvaluate the CPU solution: A CPU would have to run a program that loops through each packet’s data. While a multi-core CPU can process several packets at once, its architecture is generalized and carries overhead for things not needed by this specific task (like running an OS). The sequential nature of executing instructions limits its ultimate throughput.\nEvaluate the FPGA solution: An FPGA can be programmed to create a massively parallel hardware pipeline. You can design a dedicated circuit where each stage performs one part of the inspection. As a packet flows through the circuit, it is being inspected. You can instantiate dozens or hundreds of these pipelines on a single FPGA, all running simultaneously at hardware speed.\nCompare: The FPGA can be tailored exactly to the task. It doesn’t waste resources on general-purpose features. Its inherent parallelism is a perfect match for the problem of inspecting countless independent data packets.\n\nAnswer: The FPGA would be the better choice. It allows for the creation of a custom, massively parallel hardware architecture specifically designed for the packet inspection task, which will deliver far greater throughput than a general-purpose CPU running software.\n\n\n\nExample 3: The Role of the Instruction Set\nQuestion: A very simple CPU’s instruction set only has three commands: - LOAD R1, mem_address: Loads a value from a memory address into Register 1. - LOAD R2, mem_address: Loads a value from a memory address into Register 2. - ADD R1, R2: Adds the value in R2 to R1, storing the result in R1. Assuming the number 5 is stored at memory address 100 and the number 10 is stored at memory address 104, write the sequence of instructions to calculate 5 + 10.\n\n\nClick to see the solution\n\n\nGoal: Get the numbers 5 and 10 into the CPU’s registers so the ALU can operate on them.\nStep 1: Load the first number. The LOAD R1 instruction is needed to bring the value from memory address 100 into the first register. LOAD R1, 100\nStep 2: Load the second number. The LOAD R2 instruction is needed to bring the value from memory address 104 into the second register. LOAD R2, 104\nStep 3: Perform the addition. Now that both operands are in registers, the ADD instruction can be executed. The result (15) will be stored in Register 1, overwriting the 5 that was there. ADD R1, R2\n\nAnswer: The sequence of instructions is: **\nLOAD R1, 100\nLOAD R2, 104\nADD R1, R2\n** After these three instructions execute, Register 1 will hold the value 15.",
    "crumbs": [
      "Computer Architecture",
      "1. Computer Architecture Fundamentals, CPU Components, Memory Hierarchy, FPGAs"
    ]
  },
  {
    "objectID": "Discrete Mathematics/lec_1.html",
    "href": "Discrete Mathematics/lec_1.html",
    "title": "1. Truth Tables, Disjunctive Normal Form (DNF), Conjunctive Normal Form (CNF)",
    "section": "",
    "text": "1. Summary\n\n1.1 Propositions and Truth Tables\nA proposition is a statement that can be definitively classified as either True or False. In a computational context, we represent True with 1 and False with 0. A truth table is a systematic way to list all possible outcomes of a logical formula by considering every combination of truth values for its variables.\n\n\n1.2 Logical Operators\nWe can combine propositions using logical operators to form more complex formulas.\n\nNegation (¬ or NOT): Inverts the truth value of a proposition.\n\n\n\n\\(P\\)\n\\(\\neg P\\)\n\n\n\n\n0\n1\n\n\n1\n0\n\n\n\nConjunction (& or ∧ or AND): True only if both propositions are true.\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\\(P_1 \\land P_2\\)\n\n\n\n\n0\n0\n0\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n\nDisjunction (∨ or OR): True if at least one of the propositions is true.\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\\(P_1 \\lor P_2\\)\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n0\n1\n\n\n1\n1\n1\n\n\n\nImplication (→ or “if…then”): False only when a true premise leads to a false conclusion. This is often the most counter-intuitive operator. The principle is “ex falso quodlibet”—from a false premise, anything can follow.\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\\(P_1 \\to P_2\\)\n\n\n\n\n0\n0\n1\n\n\n0\n1\n1\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n\nEquivalence (↔︎ or “if and only if”): True only if both propositions have the same truth value.\n\n\n\n\\(P_1\\)\n\\(P_2\\)\n\\(P_1 \\leftrightarrow P_2\\)\n\n\n\n\n0\n0\n1\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n\n\n\n\n1.3 Normal Forms\nA normal form provides a standardized structure for writing any logical formula. This is useful for simplifying expressions and proving equivalences.\n\n\n1.4 Disjunctive Normal Form (DNF)\nThe DNF of a formula is a disjunction of conjuncts (a series of AND-terms joined by ORs). Think of it as identifying every condition that makes the formula true.\n\nAlgorithm to find DNF from a truth table:\n\nSelect Rows: Identify all rows in the truth table where the final result is 1.\nConstruct Conjuncts (AND-terms): For each selected row, create a term by ANDing all the variables together.\n\nIf a variable’s value in that row is 1, use the variable directly (e.g., x).\nIf a variable’s value is 0, use its negation (e.g., ¬x).\n\nCombine with Disjunctions (ORs): Join all the conjuncts you created with the OR operator. The resulting expression is the DNF.\n\n\n\n\n1.5 Conjunctive Normal Form (CNF)\nThe CNF of a formula is a conjunction of disjuncts (a series of OR-terms joined by ANDs). Think of it as listing all the conditions that cannot happen for the formula to be true, effectively ruling out the false cases.\n\nAlgorithm to find CNF from a truth table:\n\nSelect Rows: Identify all rows where the final result is 0.\nConstruct Disjuncts (OR-terms): For each selected row, create a term by ORing all the variables together. This step uses an inverted logic compared to DNF:\n\nIf a variable’s value in that row is 0, use the variable directly (e.g., x).\nIf a variable’s value is 1, use its negation (e.g., ¬x).\n\nCombine with Conjunctions (ANDs): Join all the disjuncts you created with the AND operator. This expression is the CNF.\n\n\n\n\n\n2. Definitions\n\nProposition: A statement that is either true (1) or false (0).\nLiteral: A variable (e.g., \\(x\\)) or its negation (e.g., \\(\\neg x\\)).\nConjunct (Minterm): A conjunction (AND) of one or more literals, such as \\((x_1 \\land \\neg x_2)\\). This corresponds to a single row that evaluates to 1 in a truth table.\nDisjunct (Maxterm): A disjunction (OR) of one or more literals, such as \\((x_1 \\lor \\neg x_2)\\). This corresponds to a single row that evaluates to 0 in a truth table.\nDisjunctive Normal Form (DNF): A formula expressed as a disjunction of conjuncts (an OR of ANDs).\nConjunctive Normal Form (CNF): A formula expressed as a conjunction of disjuncts (an AND of ORs).\n\n\n\n3. Formulas\n\nGeneral Formula for DNF: For a function \\(f(x_1, \\dots, x_n)\\), the DNF is the disjunction of all minterms that make the function true. \\[ f(x_1, \\dots, x_n) = \\bigvee_{f(\\sigma_1, \\dots, \\sigma_n)=1} (x_1^{\\sigma_1} \\land \\dots \\land x_n^{\\sigma_n}) \\] Where \\(x^1 = x\\) and \\(x^0 = \\neg x\\).\nGeneral Formula for CNF: For a function \\(f(x_1, \\dots, x_n)\\), the CNF is the conjunction of all maxterms that make the function false. \\[ f(x_1, \\dots, x_n) = \\bigwedge_{f(\\sigma_1, \\dots, \\sigma_n)=0} (x_1^{\\bar{\\sigma_1}} \\lor \\dots \\lor x_n^{\\bar{\\sigma_n}}) \\] Where \\(x^{\\bar{1}} = \\neg x\\) and \\(x^{\\bar{0}} = x\\).\n\n\n\n4. Mistakes\n\nMixing up DNF and CNF rules: A common error is using the variable rules for DNF (e.g., 0 becomes ¬x) when constructing the terms for CNF. Why it’s wrong: The rules are inverted. For CNF, you focus on the ‘0’ outcomes, and a variable value of ‘0’ corresponds to the positive literal x in the disjunct.\nIncorrectly connecting terms: Using AND to connect terms in a DNF or OR to connect terms in a CNF. Why it’s wrong: DNF is a disjunction (OR) of conjuncts. CNF is a conjunction (AND) of disjuncts. The outermost operator must match the form’s name.\nMisinterpreting Implication (\\(P \\to Q\\)): Believing that if the premise \\(P\\) is false, the entire statement must be false. Why it’s wrong: In classical logic, a false premise can imply anything. The only way for an implication to be false is for a true premise to lead to a false conclusion (1 → 0).\nIgnoring Operator Precedence: Evaluating a formula like \\(p \\land q \\lor r\\) from left to right without respecting precedence. Why it’s wrong: Logical operators have a defined order of operations, typically ¬ first, then ∧, then ∨, and finally → and ↔︎. The expression should be evaluated as \\((p \\land q) \\lor r\\).\n\n\n\n5. Examples\n\nExample 1\nQuestion: Obtain both DNF and CNF for the truth table \\(T(x, y) = (1001)\\).\n\n\nClick to see the solution\n\n\nConstruct the full truth table: The sequence (1001) corresponds to the output column for inputs (00, 01, 10, 11).\n\n\n\nx\ny\nT(x,y)\n\n\n\n\n0\n0\n1\n\n\n0\n1\n0\n\n\n1\n0\n0\n\n\n1\n1\n1\n\n\n\nDerive the DNF (from rows that are 1):\n\nRow 1 (x=0, y=0): Variables are 0, so we use their negations. The conjunct is \\((\\neg x \\land \\neg y)\\).\nRow 4 (x=1, y=1): Variables are 1, so we use them directly. The conjunct is \\((x \\land y)\\).\nCombine the conjuncts with OR.\n\nAnswer (DNF): \\((\\neg x \\land \\neg y) \\lor (x \\land y)\\)\nDerive the CNF (from rows that are 0):\n\nRow 2 (x=0, y=1): x is 0 (use \\(x\\)), y is 1 (use \\(\\neg y\\)). The disjunct is \\((x \\lor \\neg y)\\).\nRow 3 (x=1, y=0): x is 1 (use \\(\\neg x\\)), y is 0 (use \\(y\\)). The disjunct is \\((\\neg x \\lor y)\\).\nCombine the disjuncts with AND.\n\nAnswer (CNF): \\((x \\lor \\neg y) \\land (\\neg x \\lor y)\\)\n\n\n\n\nExample 2\nQuestion: Obtain both DNF and CNF for the truth table \\(T(x_1, x_2) = (0100)\\).\n\n\nClick to see the solution\n\n\nConstruct the full truth table:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nT(\\(x_1, x_2\\))\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n0\n0\n\n\n1\n1\n0\n\n\n\nDerive the DNF (from the single row that is 1):\n\nRow 2 (\\(x_1=0, x_2=1\\)): x1 is 0 (\\(\\neg x_1\\)), x2 is 1 (\\(x_2\\)). The conjunct is \\((\\neg x_1 \\land x_2)\\).\nSince there is only one term, no OR is needed.\n\nAnswer (DNF): \\((\\neg x_1 \\land x_2)\\)\nDerive the CNF (from rows that are 0):\n\nRow 1 (\\(x_1=0, x_2=0\\)): x1 is 0 (\\(x_1\\)), x2 is 0 (\\(x_2\\)). The disjunct is \\((x_1 \\lor x_2)\\).\nRow 3 (\\(x_1=1, x_2=0\\)): x1 is 1 (\\(\\neg x_1\\)), x2 is 0 (\\(x_2\\)). The disjunct is \\((\\neg x_1 \\lor x_2)\\).\nRow 4 (\\(x_1=1, x_2=1\\)): x1 is 1 (\\(\\neg x_1\\)), x2 is 1 (\\(\\neg x_2\\)). The disjunct is \\((\\neg x_1 \\lor \\neg x_2)\\).\nCombine the disjuncts with AND.\n\nAnswer (CNF): \\((x_1 \\lor x_2) \\land (\\neg x_1 \\lor x_2) \\land (\\neg x_1 \\lor \\neg x_2)\\)\n\n\n\n\nExample 3\nQuestion: Obtain both DNF and CNF for the truth table \\(T(a, b, c) = (01010110)\\).\n\n\nClick to see the solution\n\n\nConstruct the full truth table:\n\n\n\na\nb\nc\nT(a,b,c)\n\n\n\n\n0\n0\n0\n0\n\n\n0\n0\n1\n1\n\n\n0\n1\n0\n0\n\n\n0\n1\n1\n1\n\n\n1\n0\n0\n0\n\n\n1\n0\n1\n1\n\n\n1\n1\n0\n1\n\n\n1\n1\n1\n0\n\n\n\nDerive the DNF (from rows that are 1):\n\nRow 2 (0,0,1): \\((\\neg a \\land \\neg b \\land c)\\)\nRow 4 (0,1,1): \\((\\neg a \\land b \\land c)\\)\nRow 6 (1,0,1): \\((a \\land \\neg b \\land c)\\)\nRow 7 (1,1,0): \\((a \\land b \\land \\neg c)\\)\nCombine with OR.\n\nAnswer (DNF): \\((\\neg a \\land \\neg b \\land c) \\lor (\\neg a \\land b \\land c) \\lor (a \\land \\neg b \\land c) \\lor (a \\land b \\land \\neg c)\\)\nDerive the CNF (from rows that are 0):\n\nRow 1 (0,0,0): \\((a \\lor b \\lor c)\\)\nRow 3 (0,1,0): \\((a \\lor \\neg b \\lor c)\\)\nRow 5 (1,0,0): \\((\\neg a \\lor b \\lor c)\\)\nRow 8 (1,1,1): \\((\\neg a \\lor \\neg b \\lor \\neg c)\\)\nCombine with AND.\n\nAnswer (CNF): \\((a \\lor b \\lor c) \\land (a \\lor \\neg b \\lor c) \\land (\\neg a \\lor b \\lor c) \\land (\\neg a \\lor \\neg b \\lor \\neg c)\\)",
    "crumbs": [
      "Discrete Mathematics",
      "1. Truth Tables, Disjunctive Normal Form (DNF), Conjunctive Normal Form (CNF)"
    ]
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_1.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_1.html",
    "title": "1. Vectors, Vector Spaces, and Linear Independence",
    "section": "",
    "text": "1. Summary\n\n1.1 What is a Vector?\nA vector is a fundamental mathematical object that possesses both magnitude (or length) and direction. Vectors can be understood in two primary ways:\n\nGeometrically: A vector is represented as a directed line segment or an arrow in space. The length of the arrow corresponds to its magnitude, and the direction it points to is its direction. A key property is that a vector is independent of its starting position; it is defined only by its length and orientation.\nAlgebraically: A vector is an ordered list of numbers, called components or coordinates. This list can be written as a column or a row. For instance, a vector in a 2D plane can be written as \\(\\vec{v} = \\begin{pmatrix} x \\\\ y \\end{pmatrix}\\) or \\(\\vec{v} = (x, y)\\).\n\nThere is a one-to-one correspondence between a point \\(P(x, y, z)\\) in space and its position vector \\(\\vec{OP}\\), which starts at the origin \\(O(0, 0, 0)\\) and ends at point \\(P\\).\n\n\n1.2 Vector Operations\nStandard operations can be performed on vectors:\n\nVector Addition: To add two vectors, \\(\\vec{u}\\) and \\(\\vec{v}\\), you add their corresponding components. Geometrically, this is visualized using the tip-to-tail method: place the tail of \\(\\vec{v}\\) at the tip of \\(\\vec{u}\\). The resulting vector, \\(\\vec{u} + \\vec{v}\\), starts at the tail of \\(\\vec{u}\\) and ends at the tip of \\(\\vec{v}\\).\nScalar Multiplication: To multiply a vector \\(\\vec{v}\\) by a scalar (a single number) \\(c\\), you multiply each component of \\(\\vec{v}\\) by \\(c\\). This operation scales the vector’s magnitude. If \\(c &gt; 0\\), the direction remains the same. If \\(c &lt; 0\\), the direction is reversed.\nVector Subtraction: Subtracting \\(\\vec{v}\\) from \\(\\vec{u}\\) is equivalent to adding the negative of \\(\\vec{v}\\): \\(\\vec{u} - \\vec{v} = \\vec{u} + (-1)\\vec{v}\\).\n\n\n\n1.3 Vector Norm and Distance\nThe norm, or magnitude, of a vector \\(\\vec{v}\\), denoted as \\(||\\vec{v}||\\), represents its length. It is calculated by taking the square root of the sum of the squares of its components. This is a generalization of the Pythagorean theorem.\nThe distance between two points, \\(P\\) and \\(Q\\), in space is simply the norm of the vector connecting them, \\(\\vec{PQ}\\). \\[ d(P, Q) = ||\\vec{PQ}|| = ||Q - P|| \\]\nA unit vector is a vector with a norm of 1. Any non-zero vector can be converted into a unit vector pointing in the same direction through a process called normalization: dividing the vector by its own norm.\n\n\n1.4 Vector Spaces and Subspaces\nA vector space is a collection of objects (vectors) that can be added together and multiplied by scalars, adhering to a set of ten rules, or axioms. These axioms ensure that vector operations behave consistently and predictably. The set of all 2D vectors, denoted \\(\\mathbb{R}^2\\), is a classic example of a vector space.\nA subspace is a subset of a larger vector space that is, by itself, also a vector space. To verify if a subset \\(H\\) is a subspace, we use the Subspace Test, which simplifies the process to checking just three conditions: 1. The zero vector of the parent space must be in \\(H\\). 2. \\(H\\) must be closed under addition (if \\(\\vec{u}, \\vec{v} \\in H\\), then \\(\\vec{u}+\\vec{v} \\in H\\)). 3. \\(H\\) must be closed under scalar multiplication (if \\(\\vec{u} \\in H\\) and \\(c\\) is a scalar, then \\(c\\vec{u} \\in H\\)).\n\n\n1.5 Linear Combinations, Span, Basis, and Dimension\n\nA linear combination of a set of vectors is a new vector formed by summing scalar multiples of those vectors.\nThe span of a set of vectors is the set of all possible linear combinations that can be formed from them. The span of a set of vectors always forms a subspace. For example, the span of two non-collinear vectors in \\(\\mathbb{R}^3\\) is a plane passing through the origin.\nA set of vectors is linearly independent if no vector in the set can be expressed as a linear combination of the others. This is the ideal case, containing no redundant vectors. The only way to sum their scalar multiples to get the zero vector is if all scalars are zero.\nA set of vectors is linearly dependent if at least one vector is redundant (i.e., it lies within the span of the others).\nA basis for a vector space is a set of linearly independent vectors that spans the entire space. It is the smallest set of vectors needed to “build” the whole space.\nThe dimension of a vector space is the number of vectors in its basis.\n\n\n\n1.6 Vector Projections\nA vector can be broken down into components relative to another vector. The vector projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\) (denoted \\(\\vec{a'}\\)) is the “shadow” that \\(\\vec{a}\\) casts on the line defined by \\(\\vec{b}\\). It represents the component of \\(\\vec{a}\\) that is parallel to \\(\\vec{b}\\). The other component, the vector rejection (\\(\\vec{a''}\\)), is perpendicular to \\(\\vec{b}\\) and is found by \\(\\vec{a''} = \\vec{a} - \\vec{a'}\\).\n\n\n\n2. Definitions\n\nVector: A mathematical object possessing both magnitude (length) and direction, typically represented by an ordered list of numbers.\nScalar: A single numerical quantity used to scale vectors.\nNorm (Magnitude): The length of a vector, calculated as the square root of the sum of the squares of its components.\nUnit Vector: A vector with a norm of 1.\nVector Space: A set of vectors and a set of scalars that satisfy ten axioms governing addition and scalar multiplication.\nSubspace: A subset of a vector space that is itself a vector space under the same operations.\nLinear Combination: A sum of vectors, each multiplied by a scalar coefficient.\nSpan: The set of all possible linear combinations of a set of vectors.\nLinearly Independent: A set of vectors where no vector can be written as a linear combination of the others.\nLinearly Dependent: A set of vectors where at least one vector can be written as a linear combination of the others.\nBasis: A set of linearly independent vectors that spans an entire vector space.\nDimension: The number of vectors in a basis for a vector space.\nVector Projection: The component of one vector that lies in the direction of another vector.\n\n\n\n3. Formulas\n\nVector Addition: \\(\\vec{u} + \\vec{v} = \\begin{pmatrix} u_1 + v_1 \\\\ u_2 + v_2 \\\\ \\vdots \\end{pmatrix}\\)\nScalar Multiplication: \\(c\\vec{v} = \\begin{pmatrix} cv_1 \\\\ cv_2 \\\\ \\vdots \\end{pmatrix}\\)\nVector Norm: \\(||\\vec{v}|| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\\)\nDistance Formula: \\(d(P, Q) = ||\\vec{Q} - \\vec{P}|| = \\sqrt{(q_1-p_1)^2 + (q_2-p_2)^2 + \\dots}\\)\nNormalization (Unit Vector): \\(\\hat{v} = \\frac{\\vec{v}}{||\\vec{v}||}\\)\nVector Projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\): \\(\\vec{a'} = \\text{proj}_{\\vec{b}}\\vec{a} = \\left( \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||^2} \\right) \\vec{b}\\)\nVector Rejection of \\(\\vec{a}\\) from \\(\\vec{b}\\): \\(\\vec{a''} = \\vec{a} - \\vec{a'}\\)\n\n\n\n4. Mistakes\n\nAssuming a Set is a Subspace without Verification: Forgetting to check one of the three conditions (zero vector, closure under addition, closure under scalar multiplication). For instance, a line in \\(\\mathbb{R}^2\\) not passing through the origin is not a subspace because it fails the zero vector test.\nAdding a Scalar to a Vector: Operations like \\(5 + \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\\) are undefined. Why it’s wrong: Scalars and vectors are fundamentally different mathematical objects and their operations are defined separately.\nAssuming n Vectors Form a Basis for \\(\\mathbb{R}^n\\): A set of n vectors in an n-dimensional space only forms a basis if it both spans the space and is linearly independent. For example, \\(\\left\\{ \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} \\right\\}\\) are two vectors in \\(\\mathbb{R}^2\\), but they do not form a basis because they are linearly dependent and only span a line.\nFailing to Check for Closure with Negative Scalars: The first quadrant \\(S = \\{(x, y) \\in \\mathbb{R}^2 | x \\ge 0, y \\ge 0\\}\\) is not a vector space because it is not closed under multiplication by negative scalars. A vector \\(\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\) is in \\(S\\), but \\((-1) \\cdot \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}\\) is not.\n\n\n\n5. Examples\n\nExample 1: Finding Unknown Coordinates\nQuestion: Determine the unknown coordinates for the points \\(A(3, 5)\\), \\(B(4, 6)\\), \\(C(-2, 5)\\), and \\(D(x, y)\\), given that the vector \\(\\vec{AB}\\) is equivalent to the vector \\(\\vec{CD}\\).\n\n\nClick to see the solution\n\n\nDefine the vectors: A vector from point P to Q is found by subtracting the coordinates of P from Q. \\[ \\vec{AB} = B - A = (4 - 3, 6 - 5) = (1, 1) \\] \\[ \\vec{CD} = D - C = (x - (-2), y - 5) = (x + 2, y - 5) \\]\nSet the vectors equal: For the vectors to be equivalent, their corresponding components must be equal. \\[ 1 = x + 2 \\] \\[ 1 = y - 5 \\]\nSolve for x and y: \\[ x = 1 - 2 = -1 \\] \\[ y = 1 + 5 = 6 \\]\n\nAnswer: The coordinates of point D are \\((-1, 6)\\).\n\n\n\nExample 2: Linear Dependence\nQuestion: Show that the vectors \\(\\vec{u} = (1, 2)\\), \\(\\vec{v} = (3, 6)\\) are linearly dependent.\n\n\nClick to see the solution\n\n\nDefinition of Linear Dependence: Two vectors are linearly dependent if one is a scalar multiple of the other. We need to find a scalar \\(c\\) such that \\(\\vec{v} = c\\vec{u}\\). \\[ (3, 6) = c(1, 2) \\]\nSet up component equations: \\[ 3 = c \\cdot 1 \\] \\[ 6 = c \\cdot 2 \\]\nSolve for c: Both equations yield \\(c=3\\). Since a single scalar \\(c\\) exists that satisfies the condition, the vectors are scalar multiples of each other.\n\nAnswer: The vectors are linearly dependent because \\(\\vec{v} = 3\\vec{u}\\).\n\n\n\nExample 3: Checking for a Subspace\nQuestion: The set \\(S = \\{ \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\in \\mathbb{R}^2 | x \\ge 0, y \\ge 0 \\}\\) represents the first quadrant. Show that \\(S\\) is not a vector space.\n\n\nClick to see the solution\n\n\nRecall the Subspace Test: A set is a vector space (or subspace) if it contains the zero vector and is closed under both vector addition and scalar multiplication. We only need to show it fails one of these tests.\nTest closure under scalar multiplication: Pick a vector that is clearly in \\(S\\), for example, \\(\\vec{v} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\). Both components are \\(\\ge 0\\).\nMultiply by a negative scalar: Choose a negative scalar, like \\(c = -1\\). \\[ c\\vec{v} = (-1) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix} \\]\nCheck if the result is in S: The resulting vector \\(\\begin{pmatrix} -1 \\\\ -1 \\end{pmatrix}\\) has components that are not \\(\\ge 0\\). Therefore, it is not in \\(S\\).\n\nAnswer: The set \\(S\\) is not a vector space because it is not closed under scalar multiplication.\n\n\n\nExample 4: Vector Projection\nQuestion: Consider the vectors \\(\\vec{a} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}\\) and \\(\\vec{b} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\). Compute the vector projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\) (the vector \\(\\vec{a'}\\)).\n\n\nClick to see the solution\n\n\nRecall the projection formula: \\[ \\vec{a'} = \\left( \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{b}||^2} \\right) \\vec{b} \\]\nCalculate the dot product \\(\\vec{a} \\cdot \\vec{b}\\): \\[ \\vec{a} \\cdot \\vec{b} = (3)(1) + (4)(0) = 3 \\]\nCalculate the squared norm of \\(\\vec{b}\\): \\[ ||\\vec{b}||^2 = 1^2 + 0^2 = 1 \\]\nSubstitute the values into the formula: \\[ \\vec{a'} = \\left( \\frac{3}{1} \\right) \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = 3 \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix} \\]\n\nThis result makes intuitive sense: the “shadow” of the vector \\((3, 4)\\) on the x-axis is a vector of length 3 along that axis.\nAnswer: The projection of \\(\\vec{a}\\) onto \\(\\vec{b}\\) is \\(\\vec{a'} = \\begin{pmatrix} 3 \\\\ 0 \\end{pmatrix}\\).",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "1. Vectors, Vector Spaces, and Linear Independence"
    ]
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_2.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_2.html",
    "title": "2. Inner Product, Dot Product, Vector Norms, Orthogonality, Vector Projection",
    "section": "",
    "text": "1. Summary\n\n1.1 The Inner Product\nAn inner product is a function that takes two vectors and produces a single scalar number. Think of it as a generalized way to multiply two vectors. For an operation to be considered a valid inner product on a vector space, it must satisfy four key properties, often called axioms:\n\nSymmetry: The order of the vectors doesn’t matter. \\[ \\langle u, v \\rangle = \\langle v, u \\rangle \\]\nLinearity: Scaling one of the vectors by a constant c scales the entire inner product by c. \\[ \\langle cu, v \\rangle = c \\langle u, v \\rangle \\]\nAdditivity: The inner product distributes over vector addition. \\[ \\langle u + w, v \\rangle = \\langle u, v \\rangle + \\langle w, v \\rangle \\]\nPositive Definiteness: The inner product of a vector with itself is always non-negative. It is zero if and only if the vector itself is the zero vector. \\[ \\langle v, v \\rangle \\ge 0 \\quad \\text{and} \\quad \\langle v, v \\rangle = 0 \\iff v = 0 \\]\n\nA vector space equipped with a specific inner product is called an inner product space.\n\n\n1.2 The Dot Product: The Standard Inner Product on \\(\\mathbb{R}^n\\)\nThe most common example of an inner product is the dot product (also known as the Euclidean inner product). For two vectors \\(u = (u_1, u_2, \\dots, u_n)\\) and \\(v = (v_1, v_2, \\dots, v_n)\\) in \\(\\mathbb{R}^n\\), the dot product is defined as the sum of the products of their corresponding components:\n\\[ u \\cdot v = u_1v_1 + u_2v_2 + \\dots + u_nv_n = \\sum_{i=1}^{n} u_i v_i \\]\nThe dot product satisfies all four axioms of an inner product and is the foundation for Euclidean geometry in two and three dimensions.\n\n\n1.3 Vector Norm (Length)\nThe inner product provides a natural way to define the length or norm of a vector. The norm of a vector \\(v\\), denoted \\(\\|v\\|\\), is the square root of the inner product of the vector with itself:\n\\[ \\|v\\| = \\sqrt{\\langle v, v \\rangle} \\]\nFor the standard dot product in \\(\\mathbb{R}^n\\), this becomes the familiar distance formula: \\(\\|v\\| = \\sqrt{v_1^2 + v_2^2 + \\dots + v_n^2}\\).\n\n\n1.4 Geometric Interpretation: Angles and the Dot Product\nThe dot product elegantly connects algebra with geometry. For two non-zero vectors \\(v\\) and \\(w\\), their dot product is related to the angle \\(\\theta\\) between them by the formula:\n\\[ v \\cdot w = \\|v\\| \\|w\\| \\cos \\theta \\]\nThis relationship is fundamental. It allows us to calculate the angle between two vectors:\n\\[ \\theta = \\arccos\\left(\\frac{v \\cdot w}{\\|v\\| \\|w\\|}\\right) \\]\nThe sign of the dot product tells us about the angle: * Positive (\\(v \\cdot w &gt; 0\\)): The angle \\(\\theta\\) is acute (\\(&lt; 90^\\circ\\)). * Zero (\\(v \\cdot w = 0\\)): The angle \\(\\theta\\) is a right angle (\\(= 90^\\circ\\)). The vectors are orthogonal. * Negative (\\(v \\cdot w &lt; 0\\)): The angle \\(\\theta\\) is obtuse (\\(&gt; 90^\\circ\\)).\n\n\n1.5 Orthogonality\nTwo vectors are orthogonal (perpendicular) if their inner product is zero. This is a direct consequence of the geometric formula, since \\(\\cos(90^\\circ) = 0\\). This provides a simple algebraic test for perpendicularity.\n\\[ v \\text{ is orthogonal to } w \\iff v \\cdot w = 0 \\]\n\n\n1.6 Vector Projection\nProjection allows us to find the component of one vector that lies in the direction of another.\n\nThe vector projection of \\(v\\) onto \\(w\\), denoted \\(\\text{proj}_w(v)\\), is the “shadow” that vector \\(v\\) casts on vector \\(w\\). It is a vector that is parallel to \\(w\\).\nThe scalar projection of \\(v\\) onto \\(w\\), denoted \\(\\text{comp}_w(v)\\), is the signed length of this shadow. It is a scalar.\n\nThe formulas are: \\[ \\text{proj}_w(v) = \\left(\\frac{v \\cdot w}{w \\cdot w}\\right) w \\quad \\text{and} \\quad \\text{comp}_w(v) = \\frac{v \\cdot w}{\\|w\\|} \\]\n\n\n1.7 Decomposing a Vector\nAny vector \\(v\\) can be broken down (decomposed) into two orthogonal components relative to another vector \\(w\\): 1. A component parallel to \\(w\\): \\(v_{\\parallel} = \\text{proj}_w(v)\\). 2. A component orthogonal to \\(w\\): \\(v_{\\perp} = v - v_{\\parallel}\\).\nThis gives us \\(v = v_{\\parallel} + v_{\\perp}\\), where \\(v_{\\parallel} \\cdot v_{\\perp} = 0\\).\n\n\n1.8 Key Inequalities\nTwo important inequalities arise from the properties of the inner product:\n\nCauchy-Schwarz Inequality: This states that the absolute value of the inner product of two vectors is always less than or equal to the product of their norms. \\[ |\\langle v, w \\rangle| \\le \\|v\\| \\|w\\| \\]\nTriangle Inequality: This states that the length of the sum of two vectors is less than or equal to the sum of their individual lengths. Geometrically, this means the length of one side of a triangle is never greater than the sum of the other two sides. \\[ \\|v + w\\| \\le \\|v\\| + \\|w\\| \\]\n\n\n\n\n2. Definitions\n\nInner Product: A function that takes two vectors from a vector space and returns a scalar, satisfying the axioms of symmetry, linearity, additivity, and positive definiteness.\nDot Product: The standard inner product on \\(\\mathbb{R}^n\\), calculated by summing the products of corresponding vector components.\nInner Product Space: A vector space that has a defined inner product.\nNorm (Vector Length): The length of a vector, defined as \\(\\|v\\| = \\sqrt{\\langle v, v \\rangle}\\).\nOrthogonal Vectors: Two vectors whose inner product is zero.\nVector Projection: The vector component of one vector that lies along the direction of a second vector.\nScalar Projection: The signed length of the vector projection.\n\n\n\n3. Formulas\n\nDot Product (Algebraic): \\(u \\cdot v = \\sum_{i=1}^{n} u_i v_i\\)\nNorm from Dot Product: \\(\\|v\\| = \\sqrt{v \\cdot v}\\)\nDot Product (Geometric): \\(v \\cdot w = \\|v\\| \\|w\\| \\cos \\theta\\)\nAngle Between Vectors: \\(\\theta = \\arccos\\left(\\frac{v \\cdot w}{\\|v\\| \\|w\\|}\\right)\\)\nVector Projection of \\(v\\) onto \\(w\\): \\(\\text{proj}_w(v) = \\left(\\frac{v \\cdot w}{w \\cdot w}\\right) w\\)\nScalar Projection of \\(v\\) onto \\(w\\): \\(\\text{comp}_w(v) = \\frac{v \\cdot w}{\\|w\\|}\\)\nCauchy-Schwarz Inequality: \\(|v \\cdot w| \\le \\|v\\| \\|w\\|\\)\nTriangle Inequality: \\(\\|u + v\\| \\le \\|u\\| + \\|v\\|\\)\n\n\n\n4. Mistakes\n\nAssuming \\(a \\cdot b = a \\cdot c\\) implies \\(b=c\\): This is incorrect. The dot product does not have a general cancellation property. For example, if \\(a = (1, 1)\\), \\(b = (2, 2)\\), and \\(c = (4, 0)\\), then \\(a \\cdot b = 4\\) and \\(a \\cdot c = 4\\), but clearly \\(b \\neq c\\). Why it’s wrong: Geometrically, this condition means that \\(b\\) and \\(c\\) have the same projection onto \\(a\\), but their orthogonal components can be different.\nConfusing Scalar and Vector Projection: The scalar projection is a number (a signed length), while the vector projection is a vector. You cannot use one in place of the other. Why it’s wrong: They represent different concepts; one is a magnitude, and the other is a physical vector with both magnitude and direction.\nIncorrectly Defining Vectors for Angles in a Triangle: When finding an angle like \\(\\angle ABC\\), the vectors used must both originate from the vertex \\(B\\). You must use vectors \\(\\vec{BA}\\) and \\(\\vec{BC}\\), not \\(\\vec{AB}\\) and \\(\\vec{BC}\\). Why it’s wrong: Using vectors that don’t share a common origin will result in calculating the exterior angle or a completely unrelated angle.\nForgetting the Square Root for the Norm: The norm \\(\\|v\\|\\) is \\(\\sqrt{v \\cdot v}\\). A common mistake is to forget the square root and use \\(\\|v\\|^2\\) instead of \\(\\|v\\|\\). Why it’s wrong: This is a simple calculation error that affects all subsequent geometric calculations, such as finding angles or scalar projections.\nNormalizing the Wrong Vector in Projection: The projection formula \\(\\left(\\frac{v \\cdot w}{w \\cdot w}\\right) w\\) scales the vector \\(w\\). A mistake is to divide by \\(v \\cdot v\\) or multiply by \\(v\\). Why it’s wrong: You are projecting onto \\(w\\), so the resulting vector must be a multiple of \\(w\\). The scalar factor is determined by the dot products involving both vectors, but the direction is determined solely by \\(w\\).\n\n\n\n5. Examples\n\nExample 1: Dot Product Calculation\nQuestion: Calculate the dot product of \\(u = (1, -2, 4)\\) and \\(v = (3, 0, -5)\\).\n\n\nClick to see the solution\n\n\nMultiply corresponding components:\n\nx-components: \\((1)(3) = 3\\)\ny-components: \\((-2)(0) = 0\\)\nz-components: \\((4)(-5) = -20\\)\n\nSum the results: \\[ 3 + 0 + (-20) = -17 \\]\n\nAnswer: The dot product \\(u \\cdot v\\) is -17.\n\n\n\nExample 2: Finding the Angle Between Vectors\nQuestion: Find the angle between \\(u = (3, -1)\\) and \\(v = (2, 4)\\).\n\n\nClick to see the solution\n\n\nCalculate the dot product \\(u \\cdot v\\): \\[ u \\cdot v = (3)(2) + (-1)(4) = 6 - 4 = 2 \\]\nCalculate the norm of each vector: \\[ \\|u\\| = \\sqrt{3^2 + (-1)^2} = \\sqrt{9 + 1} = \\sqrt{10} \\] \\[ \\|v\\| = \\sqrt{2^2 + 4^2} = \\sqrt{4 + 16} = \\sqrt{20} \\]\nApply the angle formula: \\[ \\cos \\theta = \\frac{u \\cdot v}{\\|u\\| \\|v\\|} = \\frac{2}{\\sqrt{10} \\sqrt{20}} = \\frac{2}{\\sqrt{200}} = \\frac{2}{10\\sqrt{2}} = \\frac{1}{5\\sqrt{2}} \\]\nFind the angle \\(\\theta\\): \\[ \\theta = \\arccos\\left(\\frac{1}{5\\sqrt{2}}\\right) \\approx 81.87^\\circ \\]\n\nAnswer: The angle between the vectors is approximately \\(81.87^\\circ\\).\n\n\n\nExample 3: Finding an Unknown Component for Orthogonality\nQuestion: Find the value(s) of \\(x\\) such that the vectors \\(u = (x, -1, 3)\\) and \\(v = (x, 5, 1)\\) are orthogonal.\n\n\nClick to see the solution\n\n\nSet the dot product to zero: For the vectors to be orthogonal, their dot product must be 0. \\[ u \\cdot v = (x)(x) + (-1)(5) + (3)(1) = 0 \\]\nSimplify the expression: \\[ x^2 - 5 + 3 = 0 \\] \\[ x^2 - 2 = 0 \\]\nSolve for \\(x\\): \\[ x^2 = 2 \\] \\[ x = \\pm\\sqrt{2} \\]\n\nAnswer: The vectors are orthogonal if \\(x\\) is \\(\\sqrt{2}\\) or \\(-\\sqrt{2}\\).\n\n\n\nExample 4: Vector and Scalar Projection\nQuestion: Find the vector and scalar projection of \\(v = (5, 3)\\) onto \\(w = (4, 0)\\).\n\n\nClick to see the solution\n\n\nCalculate the necessary dot products: \\[ v \\cdot w = (5)(4) + (3)(0) = 20 \\] \\[ w \\cdot w = (4)(4) + (0)(0) = 16 \\]\nCalculate the norm of \\(w\\) for the scalar projection: \\[ \\|w\\| = \\sqrt{w \\cdot w} = \\sqrt{16} = 4 \\]\nCalculate the vector projection: \\[ \\text{proj}_w(v) = \\left(\\frac{v \\cdot w}{w \\cdot w}\\right) w = \\left(\\frac{20}{16}\\right) (4, 0) = \\frac{5}{4} (4, 0) = (5, 0) \\]\nCalculate the scalar projection: \\[ \\text{comp}_w(v) = \\frac{v \\cdot w}{\\|w\\|} = \\frac{20}{4} = 5 \\]\n\nAnswer: The vector projection is \\((5, 0)\\) and the scalar projection is 5.\n\n\n\nExample 5: Angle in a Triangle\nQuestion: Given points \\(A(1, 2)\\), \\(B(3, -1)\\), and \\(C(-2, 1)\\), find the measure of angle \\(\\angle ABC\\).\n\n\nClick to see the solution\n\n\nDefine vectors from the vertex B: The angle \\(\\angle ABC\\) is formed by vectors \\(\\vec{BA}\\) and \\(\\vec{BC}\\). \\[ \\vec{BA} = A - B = (1-3, 2-(-1)) = (-2, 3) \\] \\[ \\vec{BC} = C - B = (-2-3, 1-(-1)) = (-5, 2) \\]\nCalculate the dot product \\(\\vec{BA} \\cdot \\vec{BC}\\): \\[ \\vec{BA} \\cdot \\vec{BC} = (-2)(-5) + (3)(2) = 10 + 6 = 16 \\]\nCalculate the norms \\(\\|\\vec{BA}\\|\\) and \\(\\|\\vec{BC}\\|\\): \\[ \\|\\vec{BA}\\| = \\sqrt{(-2)^2 + 3^2} = \\sqrt{4 + 9} = \\sqrt{13} \\] \\[ \\|\\vec{BC}\\| = \\sqrt{(-5)^2 + 2^2} = \\sqrt{25 + 4} = \\sqrt{29} \\]\nApply the angle formula: \\[ \\cos(\\angle ABC) = \\frac{16}{\\sqrt{13}\\sqrt{29}} = \\frac{16}{\\sqrt{377}} \\]\nFind the angle: \\[ \\angle ABC = \\arccos\\left(\\frac{16}{\\sqrt{377}}\\right) \\approx 35.84^\\circ \\]\n\nAnswer: The measure of angle \\(\\angle ABC\\) is approximately \\(35.84^\\circ\\).\n\n\n\nExample 6: Decomposing a Vector\nQuestion: Decompose the vector \\(a = (5, 1, -3)\\) into two vectors, one parallel to \\(b = (1, 2, 2)\\) (\\(a_\\parallel\\)) and one orthogonal to it (\\(a_\\perp\\)).\n\n\nClick to see the solution\n\n\nFind the parallel component (\\(a_\\parallel\\)) using vector projection: \\[ a_\\parallel = \\text{proj}_b(a) = \\left(\\frac{a \\cdot b}{b \\cdot b}\\right) b \\]\nCalculate the dot products: \\[ a \\cdot b = (5)(1) + (1)(2) + (-3)(2) = 5 + 2 - 6 = 1 \\] \\[ b \\cdot b = (1)^2 + (2)^2 + (2)^2 = 1 + 4 + 4 = 9 \\]\nCalculate the parallel vector: \\[ a_\\parallel = \\left(\\frac{1}{9}\\right) (1, 2, 2) = \\left(\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9}\\right) \\]\nFind the orthogonal component (\\(a_\\perp\\)) by subtraction: \\[ a_\\perp = a - a_\\parallel = (5, 1, -3) - \\left(\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9}\\right) \\] \\[ a_\\perp = \\left(5-\\frac{1}{9}, 1-\\frac{2}{9}, -3-\\frac{2}{9}\\right) = \\left(\\frac{44}{9}, \\frac{7}{9}, -\\frac{29}{9}\\right) \\]\n(Optional) Verify orthogonality: \\[ a_\\parallel \\cdot a_\\perp = \\left(\\frac{1}{9}\\right)\\left(\\frac{44}{9}\\right) + \\left(\\frac{2}{9}\\right)\\left(\\frac{7}{9}\\right) + \\left(\\frac{2}{9}\\right)\\left(-\\frac{29}{9}\\right) = \\frac{44 + 14 - 58}{81} = \\frac{0}{81} = 0 \\] The dot product is 0, so the components are orthogonal.\n\nAnswer: The parallel component is \\(a_\\parallel = (\\frac{1}{9}, \\frac{2}{9}, \\frac{2}{9})\\) and the orthogonal component is \\(a_\\perp = (\\frac{44}{9}, \\frac{7}{9}, -\\frac{29}{9})\\).",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "2. Inner Product, Dot Product, Vector Norms, Orthogonality, Vector Projection"
    ]
  },
  {
    "objectID": "Introduction to Programming/lec_1.html",
    "href": "Introduction to Programming/lec_1.html",
    "title": "1. Introduction to Programming and C, Compilation, Memory",
    "section": "",
    "text": "1. Summary\n\n1.1 What is Programming?\nProgramming is the fundamental skill in computer science. It involves writing instructions for a computer to execute. A professional programmer should not only know several languages but also be able to quickly learn new ones. This is possible by understanding the basic concepts that are common to nearly all programming languages, such as:\n\nData types\nAlgorithms and control flow\nExpressions and statements\nSyntax and semantics\n\n\n\n1.2 Fundamental Concepts\n\nVariable, Constant, Value: A variable is a named storage location that holds a value, which can change during program execution. A constant is a named storage location whose value cannot be changed after it is initialized.\nOperators and Assignment: Operators are symbols that perform operations on values (e.g., +, -, *, /). The assignment operator (=) is used to store a value in a variable.\nData Structures: These are ways of organizing and storing data. Simple examples include arrays, lists, stacks, and queues.\nProgramming Paradigms: This refers to the style or “way” of programming. Common paradigms include:\n\nImperative: Describes computation as a series of statements that change a program’s state (e.g., C).\nObject-Oriented (OOP): Organizes code around “objects,” which bundle data and the methods that operate on that data (e.g., Java, C++).\nFunctional: Treats computation as the evaluation of mathematical functions and avoids changing state and mutable data (e.g., Lisp, Haskell, and features in modern C++).\n\n\n\n\n1.3 Introduction to the C Language\nCreated by Dennis Ritchie and Brian Kernighan, C is a powerful and influential language.\n\nMiddle-Level Language: It provides a level of abstraction above assembly language but is still close enough to the hardware to allow for fine-grained control over memory and system resources.\nUnsafe by Design: C prioritizes performance and control over safety. It leaves memory management (allocating and freeing memory) and bounds-checking entirely up to the programmer, which is a common source of bugs.\nAssumes Compilation: C source code must be translated into machine instructions by a compiler before it can be run by the computer’s processor.\n\n\n\n1.4 Building a C Program: Compilation and Linking\nA C program is built in two main stages:\n\nCompilation: A compiler (such as GCC, the GNU Compiler Collection) takes a human-readable source file (e.g., program.c) and translates it into a machine-readable object file (e.g., program.o). Each source file is compiled independently of others.\nLinking: A linker takes one or more object files and combines them with any necessary code from libraries (like the standard I/O library) to produce a single, final executable file.\n\nThe diagram below illustrates this process for a program split into multiple files:\n\n\n1.5 The C Program Structure\n\nPreprocessor Directives: These are commands that are processed before the actual compilation begins. The most common is #include &lt;stdio.h&gt;, which tells the preprocessor to include the contents of the standard input/output header file.\nThe main Function: Every C program must have a main function. It is the entry point of the program—execution always begins here.\nFunctions: All program logic and functionality are organized into functions.\nVariables:\n\nGlobal Variables: Declared outside of any function. They are accessible from any function in the program.\nLocal Variables: Declared inside a function or a block. They are only accessible within that function or block.\nFunction Parameters: Variables used to pass information into a function. They behave like local variables.\n\n\n\n\n1.6 The Common Memory Model\nWhen a C program runs, the operating system allocates a virtual address space for it, which is typically divided into four main regions:\n\nCode (or Text) Segment: This is where the compiled machine instructions of the program are stored. This region is read-only to prevent the program from accidentally modifying its own instructions.\nStatic/Global Data Segment: This segment stores global variables, static variables, and string literals. These variables exist for the entire duration of the program’s execution.\nHeap: This region is used for dynamic memory allocation. The programmer can request blocks of memory from the heap during runtime (e.g., using malloc) and must explicitly free them when they are no longer needed. The heap typically grows upwards in memory address.\nStack: This region is used to manage function calls. It stores local variables, function parameters, and return addresses. The stack operates in a Last-In, First-Out (LIFO) manner and grows downwards in memory address.\n\n\n\n1.7 How the Stack Works\nThe stack is fundamental to controlling the flow of program execution.\n\nWhen a function is called, a new Stack Frame (also called an Activation Record) is pushed onto the top of the stack.\nThis stack frame contains all the necessary information for that function call, including its parameters, local variables, and the return address (where execution should resume after the function finishes).\nIf that function calls another function, a new stack frame for the new function is pushed on top of the previous one.\nWhen a function finishes and returns, its stack frame is popped off the stack, and its local variables are destroyed. Execution jumps back to the return address stored in the now-exposed stack frame below.\n\n\n\n1.8 Scope and Blocks\n\nScope refers to the portion of the source code where a variable is “visible” and can be accessed.\nA Block is a section of code enclosed in curly braces ({...}). In C, blocks are the primary mechanism for defining scope.\nA variable declared inside a block is local to that block and is only visible from the point of its declaration to the end of the block.\nVariable Hiding: If you declare a variable in an inner block with the same name as a variable in an outer block, the inner variable “hides” the outer one. Within the inner block, any reference to that name will refer to the inner variable.\n\n\n\n1.9 Storage Class Specifiers\nStorage class specifiers in C determine a variable’s lifetime (how long it exists) and visibility (scope).\n\nauto: This is the default specifier for local variables. An auto variable is created on the stack when its block is entered and is destroyed when the block is exited. Its value is not retained between function calls.\nstatic:\n\nWhen used with a local variable, it changes the variable’s lifetime. A static local variable is stored in the static data segment, not the stack. It is created only once (when the program starts) and exists for the entire program duration. Its value is preserved between function calls.\nWhen used with a global variable, it restricts the variable’s visibility to only the file in which it is declared.\n\nextern: This is a declaration, not a definition. It tells the compiler that a variable is defined in another source file. It acts as a placeholder that the linker will resolve later by finding the actual variable definition.\n\n\n\n\n2. Definitions\n\nCompiler: A program that translates source code from a high-level programming language (like C) to a lower-level language (like machine code) that the computer can execute.\nLinker: A program that takes one or more object files generated by a compiler and combines them into a single executable program.\nScope: The region of a program’s source code in which a declared variable is visible and can be accessed.\nStack: A region of memory that stores temporary variables and control data for function calls. It operates in a Last-In, First-Out (LIFO) manner.\nHeap: A region of memory used for dynamic memory allocation, where the programmer has direct control over creating and destroying data during runtime.\nStatic Memory: A region of memory where global and static variables are stored. These variables exist for the entire lifetime of the program.\nProgramming Paradigm: A fundamental style of programming, such as imperative, functional, or object-oriented, which dictates how programs are structured and executed.\nSyntax: The set of rules that defines the combinations of symbols that are considered to be correctly structured programs in a language. For example, int x = 10; is syntactically correct C.\nSemantics: The meaning of the language’s constructs. Static semantics are checked at compile-time (e.g., trying to assign a string to an integer variable), while dynamic semantics define the program’s behavior at runtime.\n\n\n\n3. Mistakes\n\nConfusing Syntax with Semantics: Assuming that because code compiles without errors (correct syntax), it is logically correct (correct semantics). Why it’s wrong: A program can be syntactically perfect but contain logical flaws or undefined behavior that the compiler cannot detect, leading to runtime errors or incorrect results.\nIgnoring Compiler Warnings: Compiling code and running it despite the compiler issuing warnings. Why it’s wrong: Warnings often indicate potential bugs or non-standard behavior that could cause the program to fail under certain conditions. For instance, using a variable before it has been initialized is a common warning that leads to unpredictable behavior.\nForgetting & in scanf: Writing scanf(\"%d\", n); instead of scanf(\"%d\", &n);. Why it’s wrong: The scanf function needs the memory address where it should store the input value. The expression n evaluates to the value of the variable, whereas &n evaluates to its address. Providing the value instead of the address causes scanf to write to an unpredictable memory location, often leading to a program crash.\nUsing a Variable Outside Its Scope: Declaring a variable inside a loop (e.g., for (int i=0;...)) and then trying to access i after the loop has finished. Why it’s wrong: A variable’s lifetime is tied to its scope. Once program execution leaves the block ({...}) where the variable was declared, the variable is destroyed and its memory is reclaimed. Attempting to access it results in a compile-time error.\nReturning a Pointer to a Local Variable: Writing a function that creates a local variable and returns its memory address. Why it’s wrong: Local variables are stored on the stack in the function’s stack frame. When the function returns, its stack frame is destroyed. The returned pointer becomes a “dangling pointer” because it points to memory that is no longer valid. Accessing this memory leads to undefined and often catastrophic behavior.\n\n\n\n4. Examples\n\nExample 1: Scope and Variable Hiding\nQuestion: What will the following C program print to the console?\n#include &lt;stdio.h&gt;\n\nint main() {\n    int x = 10;\n    printf(\"Outer x before block: %d\\n\", x);\n\n    {\n        int x = 20; // This x \"hides\" the outer x\n        printf(\"Inner x: %d\\n\", x);\n    }\n\n    printf(\"Outer x after block: %d\\n\", x);\n    return 0;\n}\n\n\nClick to see the solution\n\n\nFirst printf: The variable x with the value 10 is in scope. The program prints 10.\nEntering the Inner Block: A new local variable, also named x, is declared and initialized to 20. This inner x is now in scope and hides the outer x.\nSecond printf: Inside the block, any reference to x refers to the inner variable. The program prints 20.\nExiting the Inner Block: The inner x goes out of scope and is destroyed. The outer x (with value 10) becomes visible again.\nThird printf: The program prints the value of the outer x, which is 10.\n\nAnswer:\nOuter x before block: 10\nInner x: 20\nOuter x after block: 10\n\n\n\nExample 2: auto vs. static Local Variables\nQuestion: Analyze the two C functions below. What will be printed when counter_auto() and counter_static() are each called three times in a row?\n#include &lt;stdio.h&gt;\n\nvoid counter_auto() {\n    auto int count = 0;\n    count++;\n    printf(\"Auto count: %d\\n\", count);\n}\n\nvoid counter_static() {\n    static int count = 0; // Initialized only once\n    count++;\n    printf(\"Static count: %d\\n\", count);\n}\n\nint main() {\n    printf(\"Calling counter_auto three times:\\n\");\n    counter_auto();\n    counter_auto();\n    counter_auto();\n\n    printf(\"\\nCalling counter_static three times:\\n\");\n    counter_static();\n    counter_static();\n    counter_static();\n    \n    return 0;\n}\n\n\nClick to see the solution\n\n\nAnalyze counter_auto(): The variable count is an auto local variable. It is created on the stack each time the function is called and initialized to 0. It is then incremented to 1 and printed. When the function returns, count is destroyed. Therefore, it will print 1 every time.\nAnalyze counter_static(): The variable count is a static local variable. It is stored in the static data segment and is initialized to 0 only once, when the program starts. Because it persists between function calls, its value is retained.\n\nThe first call increments it to 1 and prints 1.\nThe second call increments it from 1 to 2 and prints 2.\nThe third call increments it from 2 to 3 and prints 3.\n\n\nAnswer:\nCalling counter_auto three times:\nAuto count: 1\nAuto count: 1\nAuto count: 1\n\nCalling counter_static three times:\nStatic count: 1\nStatic count: 2\nStatic count: 3\n\n\n\nExample 3: Compiling and Linking Multiple Files\nQuestion: You are given three files: main.c, math_utils.c, and math_utils.h. What GCC commands are needed to compile and link them into a single executable named calculator?\nFile: math_utils.h\n#ifndef MATH_UTILS_H\n#define MATH_UTILS_H\n\n// Function prototype\nint add(int a, int b);\n\n#endif\nFile: math_utils.c\n#include \"math_utils.h\"\n\n// Function definition\nint add(int a, int b) {\n    return a + b;\n}\nFile: main.c\n#include &lt;stdio.h&gt;\n#include \"math_utils.h\"\n\nint main() {\n    int result = add(5, 3);\n    printf(\"The result is: %d\\n\", result);\n    return 0;\n}\n\n\nClick to see the solution\n\nThe process involves two steps: first, compiling each .c source file into an object file, and second, linking the object files together.\n\nCompile main.c: This command tells GCC to compile main.c but stop before linking (-c), creating an object file named main.o. bash     gcc -c main.c -o main.o\nCompile math_utils.c: This command does the same for math_utils.c, creating math_utils.o. bash     gcc -c math_utils.c -o math_utils.o\nLink the object files: This command takes the two object files and links them together to create the final executable file named calculator (-o calculator). bash     gcc main.o math_utils.o -o calculator Alternatively, you can perform all steps in a single command, and GCC will handle the intermediate compilation and linking automatically.\n\nAnswer: The commands are:\n# Step-by-step approach\ngcc -c main.c -o main.o\ngcc -c math_utils.c -o math_utils.o\ngcc main.o math_utils.o -o calculator\n\n# All-in-one command\ngcc main.c math_utils.c -o calculator\nTo run the final program: ./calculator",
    "crumbs": [
      "Introduction to Programming",
      "1. Introduction to Programming and C, Compilation, Memory"
    ]
  },
  {
    "objectID": "Introduction to Programming/lec_2.html",
    "href": "Introduction to Programming/lec_2.html",
    "title": "2. Memory, Pointers, and Types",
    "section": "",
    "text": "1. Summary\n\n1.1 From Source Code to Executable Program\nA C program’s journey from a human-readable text file to a machine-executable file involves several distinct stages. This process ensures that high-level logic is correctly translated into low-level instructions the computer’s processor can understand.\n\nHigh-Level Language (Source Code): You begin by writing code in a language like C (e.g., in a program.c file). This code is abstract and platform-independent.\nCompilation: A compiler translates the source code into assembly language. Assembly is a low-level language that is much closer to machine instructions but still uses human-readable mnemonics.\nAssembly: An assembler converts the assembly code into machine code (also known as object code). This code consists of binary digits (1s and 0s) that the CPU can directly execute. The output is typically an object file (e.g., program.o).\nLinking: A C program is often built from multiple source files (called translation units). Each is compiled into its own object file. The linker’s job is to combine these object files, along with any necessary code from libraries (like the standard input/output library), into a single executable program.\n\n\n\n1.2 Memory Organization and Access\nComputer memory can be visualized as a vast, single array of cells. Every cell has a unique address (its location) and stores a value. C programs typically interact with two main areas of memory: the stack and the heap.\n\nThe Stack: This is a highly organized, efficient region of memory that operates on a Last-In, First-Out (LIFO) basis. It is used for static memory allocation. When a function is called, a new block of memory, called a stack frame or activation record, is pushed onto the stack. This frame holds the function’s local variables, arguments, and the return address. When the function finishes, its frame is popped off the stack, and all its local variables are destroyed. This process is automatic and managed by the compiler.\nThe Heap: This is a large, less organized pool of memory used for dynamic memory allocation. Unlike the stack, the programmer is responsible for managing memory on the heap. You must explicitly request a block of memory (using functions like malloc) and explicitly release it when you are done (using free). The lifetime of heap-allocated memory is not tied to function scopes; it persists until it is explicitly deallocated.\n\n\n\n1.3 The C Type System: Static Typing\nC is a statically-typed language. This means that the type of every variable must be declared before it is used, and this type is checked by the compiler before the program is run. This is in contrast to dynamically-typed languages (like Python or JavaScript), where type checks happen at runtime.\n\nPros of Static Typing:\n\nSafety: Many type-related errors are caught during compilation, preventing bugs in the final program.\nPerformance: The compiler knows the exact size and layout of data, allowing it to generate highly optimized machine code.\nReadability: Explicit type declarations make code easier for others to understand.\n\nFundamental Types: These are the basic building blocks, such as int, char, float, and double. They can be modified with keywords like signed, unsigned, and long. The exact size of these types (except char, which is always one byte) can depend on the underlying hardware.\nDerived Types: These are more complex types built from fundamental types, including arrays, structs, unions, and pointers.\n\n\n\n1.4 Pointers: The Core of C\nA pointer is arguably the most powerful and defining feature of C. It is a special type of variable whose value is not a number or character, but rather the memory address of another variable.\n\nAddress-Of Operator (&): When placed before a variable name, this unary operator returns the memory address of that variable.\nDereference Operator (*): Also known as the indirection operator. When placed before a pointer variable, it accesses the value stored at the memory address the pointer is holding.\n\nPointers allow for indirect manipulation of data, efficient array processing, and are essential for dynamic memory management.\n\n\n1.5 Dynamic Memory Allocation with malloc\nWhen you don’t know the amount of memory you need at compile-time, you must allocate it dynamically on the heap. The standard library function malloc() (memory allocation) is used for this.\n\nmalloc(size) takes one argument: the number of bytes to allocate.\nIt finds a contiguous block of free memory of that size on the heap.\nIt returns a void* pointer to the first byte of that block. A void* is a generic pointer that must be cast to the appropriate type (e.g., int*, char*) before it can be dereferenced.\nIf malloc cannot find enough free memory, it returns NULL.\n\n\n\n1.6 Arrays and Strings\n\nAn array is a collection of elements of the same type stored in a contiguous block of memory. The name of an array often behaves like a pointer to its first element.\nA C-style string is not a built-in type but a convention: it is simply an array of characters that is terminated by a special null character (\\0). This null terminator acts as a sentinel, signaling the end of the string to library functions like printf() and strlen().\n\n\n\n\n2. Definitions\n\nPointer: A variable whose value is the memory address of another variable.\nAddress: A unique numerical identifier that specifies a location in the computer’s memory.\nDereferencing: The process of accessing the value stored at the memory address held by a pointer, using the * operator.\nStack: A region of memory where local variables and function call information are stored. Memory is managed automatically in a Last-In, First-Out (LIFO) manner.\nHeap: A region of memory used for dynamic memory allocation. The programmer is responsible for explicitly allocating and deallocating memory blocks from this area.\nStatic Typing: A type system where the type of a variable is known at compile-time. C enforces this, requiring explicit type declarations.\nDynamic Typing: A type system where the type of a variable is determined at run-time.\nTranslation Unit: A single source code file (.c file) and all the header files it includes. It is the basic unit of compilation.\nActivation Record (Stack Frame): A block of memory on the stack created for a single function call, containing its local variables, parameters, and return address.\n\n\n\n3. Mistakes\n\nDereferencing an Uninitialized or NULL Pointer: Attempting to access the value at an invalid address. An uninitialized pointer contains a garbage address, and a NULL pointer points to nothing. Why it’s wrong: This leads to undefined behavior, which almost always results in a program crash (segmentation fault). You must always ensure a pointer points to a valid memory location before dereferencing it.\nReturning a Pointer to a Local Variable: A function’s local variables exist on its stack frame, which is destroyed when the function returns. Returning a pointer to such a variable creates a “dangling pointer.” Why it’s wrong: The pointer now points to a memory location that is no longer valid. That memory can be overwritten at any time by subsequent function calls, leading to unpredictable and hard-to-debug errors.\nForgetting to Null-Terminate a String: If you build a string character by character, you must manually add the \\0 at the end. Why it’s wrong: Standard string functions (printf, strcpy, strlen, etc.) rely on the null terminator to know where the string ends. Without it, they will continue reading from adjacent memory, leading to buffer overflows, corrupted data, or crashes.\nMemory Leaks: Forgetting to call free() on memory that was allocated with malloc(). Why it’s wrong: The program loses its reference to the allocated heap memory but the memory remains reserved. Over time, repeated leaks will consume all available memory, causing the program or the entire system to fail. For every malloc(), there must be a corresponding free().\nBuffer Overflow: Writing more data into an array (a buffer) than it has been allocated to hold. Why it’s wrong: This overwrites adjacent memory, which could be holding other important variables or program instructions. It is a major source of software vulnerabilities and crashes.\n\n\n\n4. Examples\n\nExample 1: Basic Pointer Manipulation\nQuestion: Declare an integer val with a value of 42. Create a pointer p_val that points to val. Use the pointer to change the value of val to 100, and then print the new value.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\nint main() {\n    // 1. Declare the original integer variable.\n    int val = 42;\n    printf(\"Original value of val: %d\\n\", val);\n\n    // 2. Declare a pointer to an integer.\n    int *p_val;\n\n    // 3. Assign the address of 'val' to the pointer 'p_val'.\n    // The '&' operator gets the memory address.\n    p_val = &val;\n\n    // 4. Dereference the pointer 'p_val' to change the value it points to.\n    // The '*' operator accesses the value at the stored address.\n    *p_val = 100;\n\n    // 5. Print the value of 'val' to confirm it has changed.\n    printf(\"New value of val: %d\\n\", val);\n\n    return 0;\n}\nAnswer: The program will output:\nOriginal value of val: 42\nNew value of val: 100\n\n\n\nExample 2: Swapping Values with a Function\nQuestion: Write a function swap that takes two integer pointers as arguments and swaps the values they point to. Demonstrate its use in main.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n\n// 1. Define the swap function that accepts two integer pointers.\nvoid swap(int *a, int *b) {\n    // 2. Create a temporary variable to hold the value of the first integer.\n    // We must dereference 'a' to get the value it points to.\n    int temp = *a;\n\n    // 3. Assign the value pointed to by 'b' to the location pointed to by 'a'.\n    *a = *b;\n\n    // 4. Assign the stored temporary value to the location pointed to by 'b'.\n    *b = temp;\n}\n\nint main() {\n    int x = 10;\n    int y = 20;\n\n    printf(\"Before swap: x = %d, y = %d\\n\", x, y);\n\n    // 5. Call the swap function, passing the addresses of x and y.\n    swap(&x, &y);\n\n    printf(\"After swap: x = %d, y = %d\\n\", x, y);\n\n    return 0;\n}\nAnswer: The program will output:\nBefore swap: x = 10, y = 20\nAfter swap: x = 20, y = 10\n\n\n\nExample 3: Dynamic Array Allocation\nQuestion: Ask the user how many integers they want to store. Dynamically allocate an array of that size on the heap, fill it with the numbers 0, 1, 2, …, and then print the array. Finally, free the allocated memory.\n\n\nClick to see the solution\n\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt; // Required for malloc() and free()\n\nint main() {\n    int n;\n    printf(\"How many integers do you want to store? \");\n    scanf(\"%d\", &n);\n\n    // 1. Declare a pointer that will hold the address of our dynamic array.\n    int *arr;\n\n    // 2. Allocate memory on the heap.\n    // We need space for 'n' integers, so the total size is n * sizeof(int).\n    // The result of malloc (a void*) is cast to an integer pointer (int*).\n    arr = (int*) malloc(n * sizeof(int));\n\n    // 3. Always check if malloc succeeded. If not, it returns NULL.\n    if (arr == NULL) {\n        printf(\"Error: Memory allocation failed.\\n\");\n        return 1; // Exit with an error code\n    }\n\n    // 4. Fill the dynamically allocated array with values.\n    for (int i = 0; i &lt; n; i++) {\n        arr[i] = i; // Array syntax arr[i] is equivalent to *(arr + i)\n    }\n\n    // 5. Print the contents of the array to verify.\n    printf(\"Array elements: \");\n    for (int i = 0; i &lt; n; i++) {\n        printf(\"%d \", arr[i]);\n    }\n    printf(\"\\n\");\n\n    // 6. Free the memory once we are done with it to prevent a memory leak.\n    free(arr);\n\n    return 0;\n}\nAnswer: If the user enters 5, the output will be:\nHow many integers do you want to store? 5\nArray elements: 0 1 2 3 4",
    "crumbs": [
      "Introduction to Programming",
      "2. Memory, Pointers, and Types"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_3.html",
    "href": "Academic Writing and Argumentation/lec_3.html",
    "title": "3. Sentence Problems, Punctuation",
    "section": "",
    "text": "1. Summary\n\n1.1 Common Sentence Problems\nA well-formed sentence requires a clear subject and verb and must express a complete thought. The following are common errors that disrupt this structure.\n\nSentence Fragments: A sentence fragment is an incomplete sentence that is punctuated as if it were complete. It often lacks a subject, a verb, or both, or it may be a dependent clause that isn’t connected to a main clause.\n\nFragment: Because I could not find my shoes.\nCorrection: I felt sad because I could not find my shoes. (The fragment is now joined to a complete sentence).\n\nChoppy Sentences: These are short, simplistic sentences that follow one another. While grammatically correct, they make the text sound abrupt and fail to show the logical connections between ideas.\n\nChoppy: Our results were inconsistent. The program has an error. We need to talk to Paul Davis.\nCorrection: We will ask Paul Davis to review the program for errors because it produced inconsistent results. (The sentences are combined to show cause and effect).\n\nRun-on Sentences: A run-on sentence occurs when two or more independent clauses (complete sentences) are joined without proper punctuation or conjunctions.\n\nFused Sentence: No punctuation is used between the clauses.\n\nFused: The experiment failed it had been left unobserved too long.\n\nComma Splice: Only a comma is used to join the clauses. A comma alone is not strong enough.\n\nComma Splice: The experiment failed, it had been left unobserved too long.\n\nCorrection: The experiment had been left unobserved for too long, so it failed. (A comma and a coordinating conjunction are added).\n\nLoose Sentences: These sentences are overly long and convoluted, often placing the main idea at the very beginning and then adding a series of modifying phrases and clauses. This can make the core message difficult to follow.\n\nLoose: We got the contract, according to which we must be ready by June 1 with the necessary personnel and equipment to get the job done, so a staff meeting is scheduled for February 12.\nCorrection: We must close the contract by June 1, so a mandatory staff meeting is scheduled for February 12. (The sentence is made more direct and concise).\n\nCoordination and Subordination Issues:\n\nExcessive Coordination: This involves linking too many clauses with coordinating conjunctions like and. It creates rambling sentences where all ideas seem equally important.\nExcessive Subordination: This involves creating a complex sentence with too many dependent clauses, making it hard to understand the main point.\nCorrection: Break the complex sentence into several simpler, clearer sentences that logically connect.\n\nNon-Parallel Structures: In a list or series, all items must have the same grammatical form. This is called parallelism. When they don’t, the structure is non-parallel.\n\nNon-Parallel: I like to swim, to sail, and rowing. (Two infinitives, one gerund).\nCorrection (Infinitives): I like to swim, to sail, and to row.\nCorrection (Gerunds): I like swimming, sailing, and rowing.\n\nThat vs. Which: These words introduce clauses, but are not interchangeable.\n\nUse that for a restrictive clause—information that is essential to the meaning of the sentence. Do not use a comma before that. If you remove the that clause, the meaning of the sentence changes fundamentally.\n\nExample: The thieves stole the pink elephant that I love. (This specifies which pink elephant was stolen).\n\nUse which for a non-restrictive clause—information that is non-essential or extra. Always use a comma before which. If you remove the which clause, the core meaning of the sentence remains intact.\n\nExample: The thieves stole the pink elephant, which I love. (This states the elephant was stolen and, as an aside, mentions that I love it).\n\n\n\n\n\n1.2 Using Commas Correctly\nCommas signal a brief pause, separate items, and clarify sentence structure. While over-punctuating is generally better than under-punctuating, never use a single comma to separate a subject from its verb.\n\nJoining Independent Clauses: Use a comma before a coordinating conjunction (For, And, Nor, But, Or, Yet, So—often remembered by the acronym FANBOYS) when it connects two independent clauses.\n\nExample: The program is finished, but it still has several bugs.\n\nDependent Clauses:\n\nWhen a dependent clause comes before the main clause, separate it with a comma.\n\nExample: Since clowns taste funny, a cannibal does not eat them.\n\nWhen a dependent clause comes after the main clause, do not use a comma.\n\nExample: A cannibal does not eat clowns because they taste funny.\n\n\nSeparating Elements:\n\nTransitions: Use a comma after a transitional word or phrase.\n\nExample: Clowns taste funny. Therefore, a cannibal does not eat them.\n\nLists: Use commas to separate three or more items in a series.\n\nExample: My bath toys were a hairdryer, a toaster, and a radio.\n\nParenthetical Expressions & Appositives: Use commas to set off extra information that could be removed without changing the sentence’s basic meaning. An appositive is a specific type of parenthetical that renames a noun.\n\nParenthetical: Clowns, as most researchers know, taste funny.\nAppositive: My dog, Rex, doesn’t like cats.\nNote: While grammatically correct, inserting these expressions between a subject and verb can reduce readability. It is often more effective to place the expression at the beginning of the sentence or to restructure it.\n\nContrast: Use a comma to separate contrasting phrases.\n\nExample: Cats have servants, not masters.\n\n\nQuotations:\n\nReporting clause first: He said, “Polish the dull side.”\nQuotation first: “If you can’t see the bright side of life,” he said.\nInterrupted quotation: “If you can’t see the bright side,” he said, “polish the dull side.”\n\n\n\n\n1.3 Formatting Lists\nThe punctuation for bulleted or numbered lists depends on whether the list items are complete sentences.\n\nIncomplete Sentence Items: Use this format when the introductory stem and the list items form a complete sentence together.\n\nIntroduce the list with a colon.\nBegin each item with a lowercase letter.\nEnd each item except the last with a semicolon.\nEnd the final item with a period.\nExample: My parents gave me the following toys:\n\na hairdryer;\na toaster;\na radio.\n\n\nComplete Sentence Items: Use this format when each list item is a standalone sentence.\n\nIntroduce the list with a colon.\nBegin each item with a capital letter.\nEnd each item with a period.\nExample: Cannibals avoid clowns for the following reasons:\n\nClowns run fast.\nClowns taste funny.\nClowns are scary.\n\n\n\n\n\n\n2. Mistakes\n\nComma Splice: Joining two complete sentences (independent clauses) with only a comma. Why it’s wrong: A comma indicates a pause, but it is not strong enough to connect two separate, complete thoughts. You must use a period, a semicolon, or a comma followed by a coordinating conjunction (FANBOYS).\nPunctuating a Sentence Fragment: Placing a period after an incomplete thought. Why it’s wrong: A sentence must have a subject and a verb to express a complete idea. A fragment leaves the reader waiting for the rest of the thought and should be integrated into an adjacent sentence.\nSeparating a Subject from its Verb: Placing a single comma between the subject of a clause and its main verb. Why it’s wrong: The Subject-Verb pair is the core of a sentence. A single comma creates an unnatural and confusing separation. While a pair of commas can set off non-essential information, a single comma here is always an error.\nUsing that and which incorrectly: Confusing essential (restrictive) and non-essential (non-restrictive) clauses. Why it’s wrong: This error misleads the reader. Using which for essential information (or that for non-essential information) changes the fundamental meaning of the sentence by signaling the wrong level of importance for the clause.\nLack of Parallelism in Lists: Writing items in a series with inconsistent grammatical structures. Why it’s wrong: The brain processes patterns efficiently. When a pattern is broken, it creates a jarring effect that disrupts the flow of reading and makes the sentence harder to understand.\nMissing Comma Before FANBOYS in a Compound Sentence: Forgetting the comma when joining two independent clauses with a conjunction like and, but, or so. Why it’s wrong: Without the comma, the reader may not immediately see that a new, complete thought is beginning. The comma acts as a clear signal to pause and process the first clause before moving to the second.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "3. Sentence Problems, Punctuation"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_6.html",
    "href": "Academic Writing and Argumentation/lec_6.html",
    "title": "6. Descriptive Paragraph",
    "section": "",
    "text": "1. Summary\n\n1.1 What is a Descriptive Paragraph?\nA descriptive paragraph is a focused piece of writing that aims to create a clear and vivid picture of a person, place, object, or concept in the reader’s mind. Its primary function is not to tell a story or argue a point, but to show the subject through carefully chosen details. A well-crafted descriptive paragraph describes a subject’s main features with precision, often appealing to the reader’s senses to make the experience more immersive.\n\n\n1.2 Purpose of a Descriptive Paragraph\nDescriptive paragraphs are versatile and serve several key purposes in writing, particularly in technical and academic contexts. They are used to:\n\nDescribe an object or mechanism: This involves detailing the physical attributes, components, and appearance of a tangible item, such as a tool, a piece of hardware, or a scientific specimen.\nDescribe a process: This explains the sequence of events or steps in a particular operation, such as a software installation, a chemical reaction, or a system workflow.\nProvide a classification or typology: This involves organizing a subject into categories and describing the distinct features of each. The malware example from the source material is a perfect illustration of this, classifying malware into viruses, worms, and trojans and describing each type.\n\n\n\n1.3 The Structure of a Descriptive Paragraph\nAn effective descriptive paragraph follows a clear and logical three-part structure, analogous to a well-defined function in programming.\n\nParagraph Head (Topic Sentence): This is the opening sentence that introduces the subject of the paragraph. It should be clear and focused, setting the stage for the details that will follow. It’s crucial to avoid explicitly announcing your topic with phrases like, “I will now describe…” or “This paragraph is about…”. The introduction should be seamless.\nBody (Features and Details): This is the core of the paragraph where the description happens. It should be organized around two or three main features of the subject. Each feature is then elaborated upon with specific, relevant supporting details. These details are the facts, examples, and explanations that bring the description to life.\nConcluding Sentence: The final sentence provides closure. It can either summarize the main features described or rephrase the topic sentence to reinforce the paragraph’s main point.\n\n\n\n1.4 Providing Relevant Information\nThe strength of a descriptive paragraph lies in its details. These details must be relevant and factual, directly supporting the feature being discussed. Effective details often include:\n\nFacts: Objective information that helps the reader understand the subject.\nExplanations: Clarifications that explain how a component works or why a feature is important.\nExamples: Concrete instances that illustrate a concept, such as showing a virus becomes dormant until the file is opened.\n\n\n\n1.5 Key Writing Tips\nTo write an effective descriptive paragraph, adhere to the following principles:\n\nUse Neutral Language: Rely on objective, neutral words that do not evoke strong emotions. The goal is to describe, not to persuade.\nPrioritize Clarity: Make your description as clear and precise as possible. Avoid ambiguity.\nAdd a Title: A title helps frame the topic for the reader.\nEnsure Grammatical Correctness: Check that all sentences have a clear subject and verb.\nMaintain an Academic Style: The tone should be formal and consistent.\nProofread Diligently: Ask a peer to review your draft to catch errors you might have missed. Note any recurring mistakes and make a conscious effort to avoid them in future writing.\n\n\n\n\n2. Mistakes\n\nAnnouncing the Topic: Using phrases like “This paragraph will describe…” or “I am going to tell you about…”. Why it’s wrong: This is considered poor style in academic and technical writing. The topic sentence should introduce the subject naturally without meta-commentary.\nBeing Vague or Abstract: Using general words instead of specific, concrete details. For example, saying a machine is “good” instead of describing it as “efficient, processing 500 units per minute with a 99.8% accuracy rate.” Why it’s wrong: The primary goal of a descriptive paragraph is to create a clear picture; vague language fails to achieve this and leaves the reader with an incomplete understanding.\nUsing Biased or Emotional Language: Including words that carry strong positive or negative connotations (e.g., “a disgusting piece of code,” “a beautiful algorithm”). Why it’s wrong: Technical and academic descriptions should be objective. Emotional language introduces personal bias and undermines the credibility of the description.\nDisorganized Structure: Presenting details in a random order rather than grouping them logically under main features. Why it’s wrong: A lack of structure makes the paragraph confusing and difficult to follow. A logical flow—such as spatial, chronological, or from general to specific—is essential for clarity.\nOverloading with Adjectives: Stuffing sentences with too many adjectives, which can make the writing clunky and forced. Why it’s wrong: It’s more effective to use strong, precise nouns and verbs than to rely on a long string of weak adjectives. For instance, instead of “the big, tall, shiny, metallic server rack,” one could write “the towering server rack gleamed under the overhead lights.”",
    "crumbs": [
      "Academic Writing and Argumentation",
      "6. Descriptive Paragraph"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_4.html",
    "href": "Academic Writing and Argumentation/lec_4.html",
    "title": "4. Writing an Effective Paragraph, Paragraph Structure, Transitions",
    "section": "",
    "text": "1. Summary\nThis guide outlines the principles of crafting effective paragraphs. A paragraph is not merely a collection of sentences; it is a structured, cohesive unit of thought, much like a well-defined function in programming. Each paragraph should focus on a single, distinct idea and develop it thoroughly before moving on to the next.\n\n1.1 What is a Paragraph?\nA paragraph is a fundamental unit of a larger text, composed of a group of related sentences that collectively develop one central idea. Think of paragraphs as the building blocks of an essay, report, or any other document. Just as a wall is built from individual bricks, a text is constructed from individual paragraphs. The core principle is simple: one paragraph, one idea.\nAn effective paragraph is characterized by the following qualities:\n\nUnified: All sentences directly support the single main idea.\nLogical: Sentences are arranged in a coherent order that is easy for the reader to follow. A key technique for this is the “known-new contract.”\nWell-structured: It follows a predictable pattern of introduction, development, and conclusion.\nClear and Concise: It communicates its point without unnecessary words or ambiguity.\n\n\n\n1.2 The Anatomy of an Effective Paragraph (The Burger Analogy)\nA powerful way to visualize paragraph structure is the burger analogy. Each component of the paragraph has a specific role, just like the ingredients in a burger.\n\nThe Paragraph Head (Top Bun): This is the first sentence or two of the paragraph, also known as the topic sentence. Its purpose is to introduce the main idea. It has two parts: the Topic (what the paragraph is about) and the Controlling Idea (the specific point or argument you want to make about the topic). This sentence sets the reader’s expectations for everything that follows.\nSupporting Sentences (The Fillings): These sentences form the body of the paragraph and make up the majority of its content (typically at least three sentences). Their function is to develop the controlling idea introduced in the paragraph head. This is done through a two-step process:\n\nExplain: Clarify the controlling idea by providing reasons, examples, or outlining the steps in a process.\nGive Details: Substantiate your explanation with specific evidence. This can include:\n\nFacts: Verifiable pieces of information.\nStatistics: Numerical data from surveys or studies.\nAnecdotes: Brief stories or personal accounts.\nExpert Opinions: Quotes or paraphrased ideas from a knowledgeable source.\n\n\nThe Concluding Sentence (Bottom Bun): This is the final sentence of the paragraph. Its job is to provide a sense of closure. It should never introduce new ideas or details. There are two primary strategies for writing a concluding sentence:\n\nRestate: Rephrase the controlling idea from the paragraph head using different words.\nSummarize: Briefly recap the main points made in the supporting sentences.\n\n\n\n\n1.3 Creating Cohesion and Flow\nA paragraph is more than its structural parts; the sentences must connect smoothly to guide the reader. This logical flow is called cohesion.\n\nThe Known-New Contract: This is a powerful principle for creating a logical chain between sentences. It dictates that you should begin a sentence with known information (something the reader already knows, often from the previous sentence) and end it with new information (the next piece of the argument you are building). This creates an overlap that pulls the reader forward.\nTransitions: These are words or phrases that act as signposts, explicitly showing the relationship between ideas.\n\nDirect Transitions: These are specific words like First, However, In addition, Consequently, or For example. They signal shifts in logic, time, or emphasis.\nIndirect Transitions: This technique creates flow more subtly.\n\nWord-links: Repeating a key word or phrase from the previous sentence.\nIdea-links: Using synonyms or different phrasing to refer to a concept mentioned in the previous sentence (e.g., following “a horrible student” with “this young man”).\n\n\n\nUsing a mix of direct and indirect transitions results in prose that is both clear and sophisticated.\n\n\n\n2. Mistakes\n\nLosing Focus (Lack of Unity): Including a sentence that, while interesting, does not directly develop the paragraph’s controlling idea. Why it’s wrong: This breaks the “one paragraph, one idea” rule. It distracts and confuses the reader, weakening the overall argument, similar to how an unrelated line of code can introduce a bug in a function.\nAnnouncing Your Topic: Using phrases like “In this paragraph, I will discuss…” or “I am going to write about…”. Why it’s wrong: This is stylistically weak and redundant. A well-written paragraph head should state the main idea directly and efficiently, without needing a formal announcement.\nIncomplete Paragraph Head: The topic sentence is a fragment (e.g., “The difference between authorization and authentication.”). Why it’s wrong: A fragment lacks a controlling idea. It states a topic but makes no point about it, leaving the reader unsure of the paragraph’s purpose.\nIntroducing New Information in the Conclusion: Adding a new fact, detail, or sub-topic in the final sentence. Why it’s wrong: The conclusion’s sole purpose is to provide closure by summarizing or restating what has already been discussed. Introducing a new point leaves the idea undeveloped and the reader hanging.\nAbrupt or Missing Transitions: Jumping between supporting points without using transitional words or the known-new contract to bridge the gap. Why it’s wrong: This makes the text feel choppy and disconnected. The reader is forced to guess the logical relationship between sentences, which can lead to misinterpretation.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "4. Writing an Effective Paragraph, Paragraph Structure, Transitions"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_5.html",
    "href": "Academic Writing and Argumentation/lec_5.html",
    "title": "5. Avoiding Plagiarism, Referencing, Summarizing, Paraphrasing",
    "section": "",
    "text": "1. Summary\nThis guide provides a comprehensive overview of academic integrity, focusing on how to properly use and credit sources to avoid plagiarism. We will cover the definition of plagiarism, the mechanics of referencing in IEEE style, and the essential techniques of summarizing and paraphrasing.\n\n1.1 What is Plagiarism?\nPlagiarism is the act of presenting someone else’s work, ideas, or words as your own without giving proper credit to the original source. It is a serious academic offense with severe consequences, which can include failing an assignment, being reported to the department, or even expulsion from the university.\nA common guideline you might hear is to avoid using “more than 3 words verbatim (word-for-word) in a row” without referencing.\nA correction is warranted here: While this “three-word rule” is a helpful starting point, it is an oversimplification. True plagiarism is about the theft of ideas and structure, not just strings of words. Changing a few words in a sentence, a practice known as “patchwriting,” is still considered plagiarism if the original sentence structure and idea are kept without proper attribution.\n\n\n1.2 Plagiarism vs. Similarity\nIt’s crucial to understand the difference between plagiarism and similarity.\n\nPlagiarism is the act of academic misconduct. It is an ethical violation.\nSimilarity is a metric used by software (like Turnitin) to measure the percentage of text in your document that matches text in its database.\n\nA high similarity score does not automatically mean you have plagiarized. Similarity tools can flag many things that are perfectly acceptable, including:\n\nProperly cited direct quotations.\nNames, titles, and established terminology.\nNumerical data.\nCommonly used phrases or nouns that are difficult to reword.\nYour list of references.\n\nThe key is whether the matched text is properly attributed. If it is, it’s not plagiarism.\n\n\n1.3 How to Avoid Plagiarism: Citing Sources\nThe primary way to avoid plagiarism is to cite your sources. A citation is a formal reference to the source of information. This is done through two connected components: in-text citations and a reference list.\nThis guide focuses on the IEEE (Institute of Electrical and Electronics Engineers) style.\nIn-Text Citations (IEEE Style)\nAn in-text citation is a marker in your text that points the reader to the full source details in the reference list.\n\nFormat: Citations are numbers enclosed in square brackets, e.g., [1].\nNumbering: Citations are numbered sequentially, starting with [1], in the order they appear in your writing.\nPlacement: The citation number should appear on the text line, have a space before it, and come inside the sentence’s punctuation.\n\nExample: Researchers have confirmed that this method is effective [1].\n\nMultiple Authors: For a source with three or more authors, use the first author’s last name followed by et al. (Latin for “and others,” always italicized).\n\nExample: Wood et al. [7] claim that…\n\nMultiple Sources: You can reference multiple sources for a single point by listing each citation number.\n\nExample: Several recent studies [3], [4], [15] have suggested that…\n\n\nThe Reference List\nThe reference list appears at the end of your paper and provides the full publication details for every source cited in your text. Each numbered entry in the list corresponds to the in-text citation number.\n\n\n1.4 How to Avoid Plagiarism: Using Source Material\nBeyond simply adding a citation, you must handle the source material correctly. There are three main ways to incorporate information from a source: quoting, summarizing, and paraphrasing.\n\n1.4.1 Direct Quotations\nA direct quotation is an exact, word-for-word copy of text from a source.\n\nWhen to use: Use quotations when the author’s original wording is precise, powerful, or essential to your point, or when you are providing a specific definition.\nFormat: Enclose the copied text in quotation marks (” “) and include an in-text citation with the page number if available.\n\nExample: Baez et al. have noted that “full 3D stacking can potentially offer additional advantages” [7, p. 14].\n\nEllipsis: If you need to omit unnecessary words from the middle of a quote, use an ellipsis (a set of three dots: ...). Be careful not to change the original meaning of the sentence.\n\nExample: As seen in [5, p. 14], “the proposed circuit has improved signal attenuation … and has been experiencing less performance degradation”.\n\n\n\n\n1.4.2 Summarizing\nSummarizing involves restating the main ideas or arguments of a source in your own words, but in a condensed form. You give the main points but leave out the details.\n\nWhen to use: Use a summary when the specific details of a source are irrelevant to your argument, but the main point is important.\n\n\n\n1.4.3 Paraphrasing\nParaphrasing is rewriting a passage from a source in your own words and sentence structure while preserving the original meaning. A paraphrase is typically about the same length as the original passage.\n\nWhen to use: Use paraphrasing to integrate an author’s specific idea smoothly into your text, demonstrating that you fully understand it.\nShared Language: When paraphrasing, there are some words and phrases you cannot or should not change. This is called shared language and includes:\n\nTitles, proper nouns (names), and established terminology.\nNumerical data (dates, figures).\nCommon nouns that are difficult to reword without sounding unnatural.\n\n\n\n\n\n1.5 How to Paraphrase in 6 Steps\nFollow this process to create an effective and legitimate paraphrase.\nLet’s use this original text as an example: “Only 9% of the students who work part-time earn sufficient income to support themselves.”\n\nRead the original several times until you are confident you understand its meaning.\nNote key concepts and shared language.\n\nKey concepts: small portion of working students are self-sufficient.\nShared language: 9%, students, part-time, income.\n\nWrite your version without looking at the original. This forces you to use your own sentence structure.\n\nFirst draft: Of all the students who work part-time jobs, 9% make enough money to earn a living.\n\nCompare your version with the original. Check for phrases that are still too similar in structure or wording.\n\nComparison: The phrase “the students who work part-time” is very close.\n\nChange phrases that are still too similar.\n\nSecond draft: Of all the students with part-time jobs, just 9% make enough money to earn a living.\n\nCite your source as per IEEE.\n\nFinal paraphrase: According to [1], of all the students with part-time jobs, just 9% make enough money to earn a living.\n\n\n\n\n1.6 Reporting Verbs\nWhen you introduce a quote or a paraphrase, use reporting verbs instead of always defaulting to “says” or “states”. Stronger reporting verbs can accurately express the author’s position or your evaluation of it.\n\nNeutral Verbs (use sparingly): describes, explains, notes, writes.\nStronger Verbs (to show the author’s stance): argues, claims, asserts, contends, suggests, insists.\nStronger Verbs (to show your evaluation): criticizes, dismisses, praises, evaluates.\nExample with a neutral verb: The Asian Police Alliance [34] says the rise in drug trafficking is because of Western pop culture.\nExample with a stronger verb: The Asian Police Alliance [34] blames the rise in drug trafficking on Western pop culture.\n\n\n\n\n2. Mistakes\n\nIncorrectly Formatting Citations. A common error is to write sentences like “In reference [1], Jones discusses…” or “In Jones [2], a new approach is proposed.” Why it’s wrong: This phrasing is clunky and grammatically awkward. In IEEE style, the citation should be treated like a footnote number that points to the source, not as the subject of the sentence. The best practice is to name the author and place the citation immediately after, as in “Jones [1] discusses…”\nBelieving the “Three-Word Rule” is Absolute. Some students think that as long as they don’t copy more than three consecutive words, they are safe from plagiarism. Why it’s wrong: Plagiarism is about the uncredited use of ideas and structure, not just words. Changing a few words in a sentence (“patchwriting”) while keeping the author’s sentence structure and flow is still plagiarism. A proper paraphrase requires you to digest the idea and restate it using your own sentence structure and vocabulary.\nForgetting to Cite a Paraphrase or Summary. Students sometimes believe that if they put an idea into their own words, they don’t need to cite it. Why it’s wrong: Even when you use your own words, the idea still belongs to the original author. Failing to provide a citation for a paraphrased or summarized idea is a serious form of plagiarism.\nUsing an Ellipsis to Misrepresent a Source. An ellipsis (...) can be used to remove irrelevant words from a quotation, but it should never be used to alter the original meaning. Why it’s wrong: Intentionally changing the author’s argument by selectively omitting words is a form of academic dishonesty and misleads your reader.\nMismatching In-Text Citations and the Reference List. This occurs when the number in the text (e.g., [7]) does not correspond to the correct source in the numbered reference list at the end of the paper. Why it’s wrong: This breaks the connection between your claim and its evidence, making it impossible for a reader to find the source. It defeats the entire purpose of citation. Always double-check your numbering.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "5. Avoiding Plagiarism, Referencing, Summarizing, Paraphrasing"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_2.html",
    "href": "Academic Writing and Argumentation/lec_2.html",
    "title": "2. Principles of Effective Academic Writing",
    "section": "",
    "text": "1. Summary\n\n1.1 Be Formal\nA formal tone establishes objectivity and professionalism. It is a cornerstone of academic discourse, distinguishing it from casual communication.\n\nAvoid Contracted Forms: Always write out the full forms of words.\n\nInstead of: “isn’t,” “wasn’t,” “mustn’t”\nUse: “is not,” “was not,” “must not”\n\nAvoid Spoken Language: Replace informal, conversational words with more formal and precise alternatives.\n\nInstead of: “The results have been pretty good.”\nUse: “The results have been encouraging.”\nInstead of: “…a huge number of unneeded connections…”\nUse: “…numerous unneeded connections…”\n\nAvoid Punctuation Showing Attitude: Use words to convey emphasis, not punctuation like exclamation marks.\n\nInstead of: “Turnout in the election was less than 20 percent!”\nUse: “Surprisingly, turnout in the election was less than 20 percent.”\nNote: The source material contained a typo, “lection,” which has been corrected to “election.”\n\n\n\n\n1.2 Be Concise\nConciseness means using the fewest words necessary to convey an idea clearly. Wordiness can obscure your argument and frustrate the reader.\n\nAvoid Phrasal Verbs: Opt for single-word verbs.\n\nInstead of: “The committee brought up this issue…”\nUse: “The committee raised this issue…”\n\nAvoid Negatives: Use affirmative words where possible.\n\nInstead of: “not many,” “did not accept,” “did not stay”\nUse: “few,” “rejected,” “left”\n\nAvoid Redundant Pairs and Modifiers: These are words that repeat the same meaning.\n\nExamples: “any and all” (use “any”), “first and foremost” (use “first”), “completely finish” (use “finish”), “basic fundamentals” (use “fundamentals”).\n\nAvoid Metaconcepts: These are “concepts about concepts” that add unnecessary words.\n\nInstead of: “The re-factoring strategy seemed to be ineffective.”\nUse: “Re-factoring seemed to be ineffective.”\n\n\n\n\n1.3 Be Precise\nPrecision in language strengthens your arguments and prevents misinterpretation.\n\nAvoid Vague Words: Replace subjective or non-specific words with precise terminology.\n\nInstead of: “The device performance is bad.” or “This design is good.”\nUse: “The device performance is substandard.” or “This design is effective.”\n\nUse Complete Lists: Avoid using “etc.” in formal lists. Specify all elements.\n\nInstead of: “…divides elements into metals, non-metals, etc.”\nUse: “…divides elements into metals, non-metals, and semi-metals or metalloids.”\n\n\n\n\n1.4 Be Cautious\nAcademic claims must be supported by evidence and presented with appropriate nuance.\n\nAvoid Generalizations: Broad, sweeping statements are rarely accurate.\n\nInstead of: “Everyone has access to the Internet nowadays.”\nUse: “Internet access is widespread nowadays.”\n\nAvoid Emotions: Maintain an objective tone.\n\nInstead of: “It is stupid to think that…”\nUse: “It is debatable to think that…”\n\nUse Hedging: Use cautious language (hedging) to qualify claims and reflect the nuances of research.\n\nInstead of: “The virus is widespread in central Asia.”\nUse: “The virus appears to be widespread in central Asia.”\n\n\n\n\n1.5 Be Clear\nClarity ensures your reader can follow your line of reasoning without difficulty. This is achieved through direct sentence structures.\n\nAvoid Nominalization: Use verbs instead of nouns derived from verbs, especially as the sentence’s subject.\n\nNominalizations are nouns created from verbs or adjectives (e.g., “optimization” from “optimize,” “development” from “develop”).\nInstead of: “Optimization of our work force is a key goal…”\nUse: “Our company primarily aims at optimizing the work force.”\n\nAvoid Passive Voice (Generally): The active voice is usually more direct and vigorous. In active voice, the subject performs the action.\n\nPassive: “The papers were graded by the teacher.”\nActive: “The teacher graded the papers.”\nWhen to Use Passive Voice: It is appropriate when the actor is unknown or unimportant, or to emphasize the object of the action. It is often used in the “Methods” section of scientific papers (e.g., “Samples were collected…”).\n\nUse Action Verbs: Replace weak “be” verbs (is, are, was, were) with dynamic, active verbs.\nUse Concrete Subjects: Avoid starting sentences with expletives like “There is/are” and “It is.”\n\nInstead of: “There are three ways to solve this problem.”\nUse: “This problem has three solutions.”\n\nKeep Subjects and Verbs Close: Place the main subject and verb near the beginning of the sentence to improve readability.\n\n\n\n1.6 Be Careful with Pronouns (I, We, You)\nThe use of personal pronouns depends on the context and discipline.\n\nHow to use “I”: Use “I” to describe research steps (“I collected the data”) or to state your intention in a section (“In this chapter, I will…”). Do not use “I” to state personal opinions (“I think it is likely…”).\nHow to use “WE”: Use “we” to refer to a group of co-authors. Do not use “we” to group yourself with the reader (“We can stop obesity…”).\nHow to use “YOU”: Avoid using “you.” Replace it with a concrete noun.\n\nInstead of: “You can see the results in Table 3.”\nUse: “Table 3 shows the results.”\n\n\n\n\n\n2. Mistakes\n\nUsing Informal Language: This includes contractions (“don’t”), slang (“a lot of stuff”), and emotional punctuation (“!”). Why it’s wrong: Academic writing demands a formal and objective tone to maintain credibility. Informality makes the work seem unprofessional.\nOverusing the Passive Voice: While sometimes necessary, overuse of the passive voice makes writing wordy, indirect, and can hide who is performing an action. Why it’s wrong: The active voice is generally clearer, more concise, and more direct.\nBeing Vague or Imprecise: Using words like “good,” “bad,” or “things” weakens your argument. Why it’s wrong: Academic discourse requires precision. Claims must be specific and quantifiable whenever possible to be convincing.\nWordiness and Redundancy: This involves using redundant pairs (“each and every”), unnecessary modifiers (“completely finish”), or overly complex sentences. Why it’s wrong: Conciseness is a key principle of academic writing. Unnecessary words obscure your main points and make the text difficult to follow.\nMaking Broad Generalizations: Statements like “Everyone knows…” are usually inaccurate and unsupported. Why it’s wrong: Academic claims must be cautious and supported by evidence. Generalizations undermine the credibility of the argument.\nIncorrect Use of Personal Pronouns: Using “I” to state an opinion, “we” to include the reader, or “you” directly is often inappropriate. Why it’s wrong: These practices can violate the objective, impersonal tone required in many academic disciplines.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "2. Principles of Effective Academic Writing"
    ]
  },
  {
    "objectID": "Academic Writing and Argumentation/lec_1.html",
    "href": "Academic Writing and Argumentation/lec_1.html",
    "title": "1. Effective Sentence Structure, Clauses, and Sentence Types",
    "section": "",
    "text": "1. Summary\n\n1.1 The Building Blocks: Sentences and Clauses\nA sentence is the fundamental unit of written communication. To be complete, it must satisfy four conditions: 1. It expresses a complete thought. 2. It follows a specific grammatical structure. 3. It begins with a capital letter. 4. It ends with punctuation (a period, question mark, or exclamation point).\nThe core of every sentence is a clause. A clause is a group of words that contains two essential components: * A subject: The person, place, or thing performing the action. * A verb: The action or state of being.\nThe basic formula for a clause is: Subject + Verb.\nIf a group of words is missing a subject, a verb, or fails to express a complete thought, it is called a fragment. Fragments are incomplete and grammatically incorrect when used as standalone sentences.\n\nExample Fragment (missing subject and verb): “At the restaurant.”\nExample Fragment (missing subject): “Have learned a lot today.”\nExample Fragment (missing verb): “Food at the restaurant.”\n\n\n\n1.2 Clause Types: Independent vs. Dependent\nClauses can be categorized into two types, which function like components in a program.\n\nIndependent Clause (or Main Clause): This clause expresses a complete thought and can stand alone as a sentence. It’s like a “main function” that can execute on its own.\n\nExample: “I like pizza.”\nExample: “He has read a lot of books.”\n\nDependent Clause (or Subordinate Clause): This clause does not express a complete thought and cannot stand alone. It must be attached to an independent clause to make sense. It functions like a “subroutine” or helper function that provides additional information. Dependent clauses often begin with a subordinating conjunction (e.g., because, although, if, when, while).\n\nExample: “Although I like pizza…”\nExample: “…because he has read a lot of books.”\n\n\n\n\n1.3 Basic and Extended Sentence Structure\nThe most common sentence structure in English is SVO (Subject-Verb-Object). * Subject: The doer of the action. * Verb: The action. * Object: The receiver of the action.\n\nExample (SVO): Nkuma (S) eats (V) apples (O).\n\nCorrection Note: Some sentences do not have an object and follow a simpler SV (Subject-Verb) structure. For instance, in “Karim sleeps,” Karim is the subject and sleeps is the verb. There is no object receiving an action.\nThis basic structure can be extended with more details, such as place and time.\n\nExample (Extended): Karim (S) sleeps (V) at home (Place) on Mondays (Time).\n\n\n\n1.4 The Four Sentence Types\nBy combining independent and dependent clauses in different ways, we can create four types of sentences.\n1. Simple Sentence A simple sentence consists of exactly one independent clause. * Structure: Independent Clause. * Example: “A woman went to the gym.”\n2. Compound Sentence A compound sentence consists of two or more independent clauses joined together. These clauses are typically linked by a comma and a coordinating conjunction. * Structure: Independent Clause, [Coordinating Conjunction] Independent Clause. * The coordinating conjunctions can be remembered with the acronym FANBOYS: For, And, Nor, But, Or, Yet, So. * Example: “Dogs have masters, but cats have servants.”\n3. Complex Sentence A complex sentence contains one independent clause and at least one dependent clause. The clauses are joined by a subordinating conjunction (like because, since, whenever, although). The punctuation depends on the order of the clauses. * Structure 1 (No Comma): Independent Clause [Subordinating Conjunction] Dependent Clause. * Example: “A cannibal does not eat clowns because they taste funny.” * Structure 2 (Comma Required): [Subordinating Conjunction] Dependent Clause, Independent Clause. * Example: “Since clowns taste funny, a cannibal does not eat them.”\n4. Compound-Complex Sentence This is a combination of the two previous types. It contains at least two independent clauses and at least one dependent clause. * Structure Example: Dependent Clause, Independent Clause, [Coordinating Conjunction] Independent Clause. * Example: “Although he organized his sources by theme, Mongo decided to arrange them chronologically, and he carefully followed the MEAL plan for organization.” * Warning: Use these sentences carefully. While grammatically correct, they can become long and difficult to read, potentially making your writing less clear.\n\n\n\n2. Mistakes\n\nUsing Sentence Fragments: A common mistake is writing a dependent clause or a phrase as if it were a complete sentence.\n\nIncorrect: “Because he has read a lot of books.”\nWhy it’s wrong: This is a dependent clause. It provides a reason but doesn’t state what the result of that reason is. It needs an independent clause to complete the thought (e.g., “He is very knowledgeable because he has read a lot of books.”).\n\nCreating a Comma Splice (Run-On Sentence): This error occurs when two independent clauses are joined with only a comma, which is not strong enough.\n\nIncorrect: “The woman went to the gym, everybody liked her immediately.”\nWhy it’s wrong: Both “The woman went to the gym” and “everybody liked her immediately” are complete thoughts. They must be separated by a period, a semicolon, or a comma followed by a FANBOYS conjunction.\nCorrect: “The woman went to the gym, and everybody liked her immediately.”\n\nForgetting the Comma in Complex Sentences: When a complex sentence begins with a dependent clause, a comma must be placed after it.\n\nIncorrect: “Whenever we stop feeding them black rabbits die.”\nWhy it’s wrong: The comma acts as a logical separator, telling the reader that the introductory condition (“Whenever we stop feeding them”) has ended and the main point is about to begin.\nCorrect: “Whenever we stop feeding them, black rabbits die.”\n\nOverusing Compound-Complex Sentences: While powerful, these sentences can easily become convoluted and confusing.\n\nWhy it’s wrong: The primary goal of writing is clarity. Overly long sentences force the reader to hold too many ideas in their head at once, reducing readability. It is often more effective to break a complex idea into several shorter sentences.",
    "crumbs": [
      "Academic Writing and Argumentation",
      "1. Effective Sentence Structure, Clauses, and Sentence Types"
    ]
  },
  {
    "objectID": "Introduction to Programming/lec_3.html",
    "href": "Introduction to Programming/lec_3.html",
    "title": "3. Pointers, Declarations, Preprocessing, and File I/O",
    "section": "",
    "text": "1. Summary\nThis document provides a foundational overview of several advanced topics in the C programming language: pointers, complex declarations, the preprocessor, and file input/output. These concepts are essential for moving beyond basic programming and are fundamental to understanding how C interacts with system memory and the file system.\n\n1.1 Pointers\nA pointer is a special type of variable that does not hold a data value (like an integer or character) but instead holds a memory address. It “points” to the location where another variable is stored. This allows for indirect manipulation of data, dynamic memory management, and efficient handling of complex data structures.\n\nDeclaration: Pointers are declared using an asterisk (*) between the data type and the variable name. For example, int *ptr; declares a pointer named ptr that can hold the address of an integer.\nAddress-of Operator (&): This unary operator returns the memory address of a variable. To make ptr point to an integer variable var, you would write ptr = &var;.\nDereference Operator (*): This unary operator accesses the value stored at the memory address held by a pointer. For example, *ptr would retrieve the value of var. You can also use it to modify the value: *ptr = 20; would change the value of var to 20.\nPointers and Arrays: In C, an array’s name can be treated as a constant pointer to its first element. This means array is equivalent to &array[0]. This relationship allows for pointer arithmetic, where you can increment or decrement a pointer to move through the elements of an array (e.g., *(array + 1) is the same as array[1]).\nDynamic Memory Allocation: Pointers are crucial for managing the heap, a region of memory for data whose size is not known at compile time.\n\nmalloc(size): The “memory allocation” function reserves a block of memory of a specified size (in bytes) on the heap. It returns a generic void* pointer to the start of that block.\nfree(ptr): This function releases a block of memory previously allocated with malloc, returning it to the system. It is the programmer’s responsibility to free any memory they allocate.\n\n\n\n\n1.2 Declarations\nC’s declaration syntax allows for creating complex types by combining pointers (*), arrays ([]), and functions (()). Understanding the rules of precedence and associativity is key to reading them correctly.\n\nBasic Components: A declaration consists of a storage class (static, extern), a type specifier (int, struct S), an entity name, and an optional initializer.\nReading Complex Declarations: A helpful heuristic is the “Clockwise/Spiral Rule”. Start with the variable name, then move in a spiral/clockwise direction. When you encounter a *, say “pointer to”. When you see [], say “array of”. When you find (), say “function returning”. Parentheses can be used to override the default precedence.\n\nExample: int *(*f)(int);\n\nStart at f: “f is…”\nMove right, hit ): move left to *: “…a pointer to…”\nMove out of parentheses, hit (int): “…a function taking an int…”\nMove left, hit *: “…returning a pointer to…”\nEnd at int: “…an int.”\n\n\nFull reading: f is a pointer to a function taking an int and returning a pointer to an int.\n\n\ntypedef Declarations: The typedef keyword allows you to create an alias for a data type. This is extremely useful for simplifying complex declarations and improving code readability. For example, typedef int (*MathFunc)(int); creates a new type name MathFunc that can be used to declare pointers to functions that take an int and return an int.\n\n\n\n1.3 Preprocessing\nThe C preprocessor is a text-processing tool that runs before the actual compilation of the source code. It scans the code for specific instructions, known as preprocessor directives, which all begin with a hash symbol (#).\n\n#include: This directive includes the content of another file into the current source file. It is most commonly used to include header files (.h) which contain function declarations and macro definitions.\n\n#include &lt;stdio.h&gt;: Looks for the file in standard system directories.\n#include \"myheader.h\": Looks for the file in the current project directory first.\n\n#define: This directive is used to create macros.\n\nObject-like macros: Replace a name with a value (e.g., #define PI 3.14159).\nFunction-like macros: Behave like simple functions but are expanded inline via text substitution. This can be faster but is prone to errors if not written carefully (see Mistakes section).\n\nConditional Compilation: These directives allow you to include or exclude parts of the code based on certain conditions. This is useful for writing code that can be compiled for different platforms or for debugging purposes.\n\n#ifdef MACRO_NAME: Includes the following code only if MACRO_NAME has been defined.\n#ifndef MACRO_NAME: The opposite of #ifdef. Often used in header files to prevent them from being included multiple times.\n#if expression: Includes code if a constant expression evaluates to true (non-zero).\n#else, #elif, #endif: Used to build more complex conditional logic.\n\n\n\n\n1.4 File I/O\nFile Input/Output (I/O) in C is handled through a set of standard library functions defined in &lt;stdio.h&gt;. All file operations use a special pointer type called FILE *, which acts as a stream handle.\n\nOpening a File: The fopen() function is used to open a file and prepare it for reading or writing. It returns a FILE * pointer on success or NULL on failure.\n\nSyntax: FILE *fp = fopen(\"filename.txt\", \"mode\");\n\nFile Modes: The mode is a string that specifies the intended operation:\n\n\"r\": Read-only. The file must exist.\n\"w\": Write-only. Creates the file if it doesn’t exist; otherwise, erases its contents.\n\"a\": Append. Creates the file if it doesn’t exist. All writes occur at the end of the file.\nAdding a + (e.g., \"r+\", \"w+\") opens the file for both reading and writing (update).\nAdding a b (e.g., \"rb\", \"wb+\") opens the file in binary mode.\n\nReading and Writing: Once a file is open, various functions can be used to interact with it, such as:\n\nfprintf(fp, \"...\", ...) and fscanf(fp, \"...\", ...): Work like printf and scanf but operate on a file stream.\nfputs(str, fp) and fgets(buffer, size, fp): Write and read strings (lines) from a file.\n\nClosing a File: The fclose(fp) function must be called when you are finished with a file. This flushes any buffered data to the disk and releases the file handle.\n\n\n\n\n2. Definitions\n\nPointer: A variable that stores the memory address of another variable.\nDereferencing: The act of accessing the value stored at the memory address a pointer is pointing to, using the * operator.\nDangling Pointer: A pointer that points to a memory location that has already been deallocated (freed). Using it leads to undefined behavior.\nMemory Leak: A situation in which memory allocated on the heap is no longer needed but is not released (freed). This consumes available memory and can eventually cause a program to fail.\nHeap: A region of a program’s memory used for dynamic memory allocation, managed by malloc() and free().\nStack: A region of memory used for static memory allocation, managing local variables and function call information. Memory is automatically allocated and deallocated as functions are called and return.\nPreprocessor: A program that processes the source code before it is passed to the compiler, handling directives like #include and #define.\nMacro: A fragment of code that has been given a name. When the name is used, it is replaced by the contents of the macro through simple text substitution by the preprocessor.\ntypedef: A keyword in C used to create an alias or synonym for an existing data type, often to simplify complex type declarations.\nFILE stream: A data structure defined in &lt;stdio.h&gt; that represents an input or output file. It is accessed via a pointer (FILE *).\n\n\n\n3. Mistakes\n\nForgetting to Free Allocated Memory: Every call to malloc() must have a corresponding call to free(). Why it’s wrong: Failing to free memory causes a memory leak. The program will consume more and more memory over its lifetime, which can lead to it slowing down or crashing.\nDereferencing a NULL or Uninitialized Pointer: Attempting to use a pointer that has not been assigned a valid memory address. Why it’s wrong: This results in undefined behavior. On most modern operating systems, it will cause a segmentation fault and crash the program, as it’s an attempt to access a protected or invalid memory location.\nUnsafe Macro Definitions: Writing function-like macros without proper parenthesizing. Consider #define MULTIPLY(a, b) a * b. If used as MULTIPLY(2 + 3, 4), it expands to 2 + 3 * 4, which evaluates to 14, not the expected 20. Why it’s wrong: Macros are simple text substitution, not true function calls. The C order of operations applies to the expanded text. The correct definition is #define MULTIPLY(a, b) ((a) * (b)).\nReturning a Pointer to a Local Variable: A function’s local variables exist on the stack and are destroyed when the function returns. Why it’s wrong: Returning a pointer to such a variable creates a dangling pointer. The memory location it points to is no longer valid and may be overwritten by subsequent function calls, leading to corrupted data and unpredictable behavior.\nForgetting to Check if fopen() Returned NULL: fopen() returns NULL if it fails to open a file (e.g., file not found in read mode, no permissions). Why it’s wrong: If you proceed to use the NULL FILE pointer with functions like fprintf() or fclose(), your program will crash. Always check the return value of fopen() before using the file pointer.\n\n\n\n4. Examples\n\nExample 1: Pointer Manipulation\nQuestion: What will be the final output of the following C code?\n#include &lt;stdio.h&gt;\n\nint main() {\n    int x = 10;\n    int y = 20;\n    int *p1 = &x;\n    int *p2 = &y;\n\n    *p1 = *p2 + 5;\n    p2 = p1;\n    *p2 = *p2 - 3;\n\n    printf(\"x = %d, y = %d\\n\", x, y);\n    return 0;\n}\n\n\nClick to see the solution\n\n\nInitialization: x is 10, y is 20. p1 points to x, p2 points to y.\n*p1 = *p2 + 5;: The value at p1 (which is x) becomes the value at p2 (which is y, i.e., 20) plus 5. So, x is now 25. y is still 20.\np2 = p1;: Pointer p2 is changed to hold the same address as p1. Now, both p1 and p2 point to x. p2 no longer points to y.\n*p2 = *p2 - 3;: The value at p2 (which is x) is updated. x becomes its current value (25) minus 3. So, x is now 22. The variable y is unaffected by this step because no pointer is pointing to it anymore.\nprintf: The final values of x and y are printed.\n\nAnswer:\nx = 22, y = 20\n\n\n\nExample 2: Interpreting a Complex Declaration\nQuestion: Describe in plain English the type of the variable a4 in the following C declaration: int (*(a4[10]))(int);\n\n\nClick to see the solution\n\nWe use the Clockwise/Spiral Rule, starting from the variable name a4.\n\nStart at a4: “a4 is…”\nMove right, find [10]: “…an array of 10…”\nMove left, find * inside parentheses: “…pointers to…”\nMove out of parentheses, find (int): “…a function that takes an int parameter…”\nMove left to the beginning, find int: “…and returns an int.”\n\nAnswer: a4 is an array of 10 pointers to functions, where each function takes an integer as an argument and returns an integer.\n\n\n\nExample 3: Safe Macro Usage\nQuestion: A programmer writes a macro to find the maximum of two numbers: #define MAX(a, b) a &gt; b ? a : b. Explain what is wrong with this macro and provide a corrected version. Test both with the expression MAX(5, 10-8).\n\n\nClick to see the solution\n\n\nIdentify the Flaw: The original macro uses simple text replacement without parentheses around its arguments.\nTest the Flawed Macro: The expression MAX(5, 10-8) would be expanded by the preprocessor to 5 &gt; 10-8 ? 5 : 10-8.\nEvaluate based on C precedence: Due to operator precedence, the &gt; comparison is evaluated before the - subtraction. The expression becomes (5 &gt; 10) - 8.\nCalculate the incorrect result: 5 &gt; 10 is false (evaluates to 0). So the expression becomes 0 - 8, which is -8. This is incorrect; the maximum of 5 and 2 is 5.\nCorrect the Macro: To fix this, we must wrap each argument and the entire expression in parentheses. This ensures that the arguments are fully evaluated before being used in the macro’s logic, and the macro’s result is treated as a single unit.\n\nAnswer: The macro is unsafe because operator precedence can cause expressions passed as arguments to be evaluated incorrectly. The corrected, safe version is: #define MAX(a, b) ((a) &gt; (b) ? (a) : (b))",
    "crumbs": [
      "Introduction to Programming",
      "3. Pointers, Declarations, Preprocessing, and File I/O"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "InnoNotes",
    "section": "",
    "text": "Created by Zakhar Podyakov with ❤️ If you find any mistakes or have suggestions for improvement, please write to me. Telegram | Github"
  },
  {
    "objectID": "Analytical Geometry and Linear Algebra I /lec_3.html",
    "href": "Analytical Geometry and Linear Algebra I /lec_3.html",
    "title": "3. Matrices and Determinants, Vector Cross Product, Scalar Triple Product",
    "section": "",
    "text": "1. Summary\n\n1.1 Introduction to Matrices\nA matrix is a rectangular grid of numbers arranged in rows and columns. The size, or dimension, of a matrix is given by m x n, where m is the number of rows and n is the number of columns.\n\nSquare Matrix: A matrix with an equal number of rows and columns (n x n).\nIdentity Matrix (\\(I\\)): A square matrix with ones on the main diagonal (from top-left to bottom-right) and zeros everywhere else. It is the matrix equivalent of the number 1.\nZero Matrix: A matrix where all entries are zero.\nDiagonal Matrix: A square matrix where all non-diagonal elements are zero.\nSymmetric Matrix: A square matrix that is equal to its transpose (\\(A = A^T\\)).\nTriangular Matrix: A square matrix where all entries above or below the main diagonal are zero. It can be upper triangular or lower triangular.\n\n\n\n1.2 Basic Matrix Operations\n\nAddition and Subtraction: These are performed element-wise on matrices of the same dimensions. You simply add or subtract the corresponding entries.\nScalar Multiplication: Multiplying a matrix by a scalar (a single number) involves multiplying every element in the matrix by that scalar.\nTranspose (\\(A^T\\)): The transpose of a matrix is formed by swapping its rows and columns. The first row becomes the first column, the second row becomes the second column, and so on. If \\(A\\) is an m x n matrix, \\(A^T\\) will be an n x m matrix.\nTrace (tr(A)): The trace of a square matrix is the sum of the elements on its main diagonal.\n\n\n\n1.3 Matrix Multiplication\nMultiplying two matrices, \\(A\\) and \\(B\\), is more complex. To get the element in the \\(i\\)-th row and \\(j\\)-th column of the product matrix \\(AB\\), you take the dot product of the \\(i\\)-th row of \\(A\\) with the \\(j\\)-th column of \\(B\\).\n\nCompatibility: For the product \\(AB\\) to be defined, the number of columns in matrix \\(A\\) must equal the number of rows in matrix \\(B\\).\nNon-Commutativity: A critical property of matrix multiplication is that it is not commutative. In general, \\(AB \\neq BA\\). The order of multiplication matters.\n\n\n\n1.4 The Determinant\nThe determinant is a special scalar value that can only be calculated from a square matrix. It provides important information about the matrix.\n\nSignificance: A non-zero determinant means the matrix is invertible. Geometrically, the determinant represents the scaling factor of the linear transformation described by the matrix.\nCalculation (2x2): For \\(A = \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix}\\), the determinant is \\(\\det(A) = ad - bc\\).\nCalculation (3x3): This can be done using Sarrus’s rule or, more generally, through cofactor expansion.\n\n\n\n1.5 The Matrix Inverse (\\(A^{-1}\\))\nThe inverse of a square matrix \\(A\\) is another matrix, denoted \\(A^{-1}\\), such that their product is the identity matrix (\\(AA^{-1} = I\\)).\n\nExistence: An inverse exists only if the matrix is non-singular, meaning its determinant is non-zero (\\(\\det(A) \\neq 0\\)).\nAdjugate Method: A common way to find the inverse is:\n\nMatrix of Minors (\\(M_{ij}\\)): For each element, find the determinant of the sub-matrix that remains after deleting its row and column.\nMatrix of Cofactors (\\(C_{ij}\\)): Apply a “checkerboard” pattern of signs to the matrix of minors using the formula \\(C_{ij} = (-1)^{i+j} M_{ij}\\).\nAdjugate Matrix (adj(A)): Transpose the matrix of cofactors.\nInverse: The inverse is found by multiplying the adjugate matrix by the reciprocal of the determinant: \\(A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)\\).\n\n\n\n\n1.6 Vector Cross Product\nThe cross product is an operation between two vectors in 3D space (\\(\\mathbb{R}^3\\)) that results in a new vector.\n\nPerpendicularity: The resulting vector, \\(\\vec{a} \\times \\vec{b}\\), is perpendicular to both \\(\\vec{a}\\) and \\(\\vec{b}\\).\nMagnitude: The magnitude of the cross product, \\(||\\vec{a} \\times \\vec{b}||\\), is equal to the area of the parallelogram formed by the two vectors. The area of the triangle formed by them is half of this value.\nDirection: The direction of the resulting vector is determined by the right-hand rule.\nAnti-Commutativity: The cross product is anti-commutative: \\(\\vec{a} \\times \\vec{b} = -(\\vec{b} \\times \\vec{a})\\).\n\n\n\n1.7 Scalar Triple Product\nThe scalar triple product involves three vectors from \\(\\mathbb{R}^3\\) and results in a scalar value. It is calculated as \\(\\vec{a} \\cdot (\\vec{b} \\times \\vec{c})\\).\n\nGeometric Interpretation: The absolute value of the scalar triple product represents the volume of the parallelepiped formed by the three vectors.\nCoplanarity: If the scalar triple product is zero, it means the volume is zero, and therefore the three vectors lie on the same plane (they are coplanar).\n\n\n\n\n2. Definitions\n\nMatrix: A rectangular array of numbers, symbols, or expressions, arranged in rows and columns.\nSquare Matrix: A matrix with the same number of rows as columns.\nIdentity Matrix (\\(I\\)): A square matrix with ones on the main diagonal and zeros elsewhere, which acts as the multiplicative identity.\nTranspose (\\(A^T\\)): A matrix obtained by swapping the rows and columns of another matrix.\nDeterminant (\\(\\det(A)\\)): A scalar value associated with a square matrix that determines if the matrix is invertible.\nSingular Matrix: A square matrix whose determinant is zero, meaning it has no inverse.\nAdjugate Matrix (adj(A)): The transpose of the cofactor matrix.\nCross Product (\\(\\vec{a} \\times \\vec{b}\\)): A binary operation on two vectors in 3D space that produces a vector perpendicular to both original vectors.\nScalar Triple Product (\\(\\vec{a} \\cdot (\\vec{b} \\times \\vec{c})\\)): A product of three vectors that yields a scalar representing the volume of the parallelepiped they span.\nCoplanar Vectors: A set of vectors that all lie in the same plane.\n\n\n\n3. Formulas\n\n2x2 Determinant: \\(\\det \\begin{pmatrix} a & b \\\\ c & d \\end{pmatrix} = ad - bc\\)\nMatrix Inverse (Adjugate Method): \\(A^{-1} = \\frac{1}{\\det(A)} \\text{adj}(A)\\)\nCofactor: \\(C_{ij} = (-1)^{i+j} M_{ij}\\), where \\(M_{ij}\\) is the minor.\nCross Product (Determinant Form): \\(\\vec{a} \\times \\vec{b} = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ a_1 & a_2 & a_3 \\\\ b_1 & b_2 & b_3 \\end{pmatrix}\\)\nArea of Triangle (with vertices A, B, C): \\(\\text{Area} = \\frac{1}{2} ||\\vec{AB} \\times \\vec{AC}||\\)\nScalar Triple Product / Volume: \\(V = |\\vec{a} \\cdot (\\vec{b} \\times \\vec{c})| = \\left| \\det \\begin{pmatrix} a_1 & a_2 & a_3 \\\\ b_1 & b_2 & b_3 \\\\ c_1 & c_2 & c_3 \\end{pmatrix} \\right|\\)\n\n\n\n4. Mistakes\n\nAssuming Matrix Multiplication is Commutative: Multiplying matrices in a different order usually produces a different result (\\(AB \\neq BA\\)). Why it’s wrong: The row-by-column multiplication process is order-dependent.\nForgetting the Sign Pattern for Cofactors: When calculating the matrix of cofactors, it’s easy to forget the \\((-1)^{i+j}\\) term, which creates a “checkerboard” pattern of positive and negative signs. Why it’s wrong: The signs are essential for the definition of the determinant and the inverse.\nMistaking the Determinant of a Scaled Matrix: For an \\(n \\times n\\) matrix, \\(\\det(kA) = k^n \\det(A)\\), not \\(k \\det(A)\\). Why it’s wrong: The scalar \\(k\\) applies to each of the \\(n\\) rows, and the determinant is multiplicative across rows.\nApplying Cross Product to 2D Vectors: The cross product is exclusively defined for vectors in three-dimensional space. Why it’s wrong: The concept of a single vector being mutually perpendicular to two other vectors requires a third dimension.\nConfusing Adjugate and Inverse: The adjugate matrix is the transpose of the cofactor matrix. You must still divide it by the determinant to get the final inverse. Why it’s wrong: The adjugate is an intermediate step; without dividing by the determinant, \\(A \\cdot \\text{adj}(A) = \\det(A)I\\), not \\(I\\).\n\n\n\n5. Examples\n\nExample 1: Matrix Operation Sizing (Lab 3, 1a)\nQuestion: Given matrices P(4x5), R(5x2), and S(4x2), determine if the expression PR + S is defined. If so, what is the size of the resulting matrix?\n\n\nClick to see the solution\n\n\nAnalyze the multiplication PR:\n\nP has dimensions (4 x 5).\nR has dimensions (5 x 2).\nThe inner dimensions match (5 and 5), so the product is defined.\nThe resulting matrix PR will have the outer dimensions: (4 x 2).\n\nAnalyze the addition (PR) + S:\n\nThe matrix PR has dimensions (4 x 2).\nThe matrix S has dimensions (4 x 2).\nSince both matrices have the same dimensions, the addition is defined.\n\nDetermine the final size: The resulting matrix will have the same dimensions as the operands, which is (4 x 2).\n\nAnswer: The expression is defined, and the resulting matrix has a size of 4 x 2.\n\n\n\nExample 2: Matrix Multiplication (Lab 3, 2b)\nQuestion: Given \\(A = \\begin{pmatrix} 3 & 0 \\\\ -1 & 2 \\\\ 1 & 1 \\end{pmatrix}\\) and \\(B = \\begin{pmatrix} 4 & -1 \\\\ 0 & 2 \\end{pmatrix}\\), compute the product AB.\n\n\nClick to see the solution\n\n\nCheck dimensions: A is (3 x 2) and B is (2 x 2). The inner dimensions match, so the product is defined. The result will be a (3 x 2) matrix.\nCalculate the element at Row 1, Column 1: (Row 1 of A) \\(\\cdot\\) (Column 1 of B) = \\((3)(4) + (0)(0) = 12\\).\nCalculate the element at Row 1, Column 2: (Row 1 of A) \\(\\cdot\\) (Column 2 of B) = \\((3)(-1) + (0)(2) = -3\\).\nCalculate the element at Row 2, Column 1: (Row 2 of A) \\(\\cdot\\) (Column 1 of B) = \\((-1)(4) + (2)(0) = -4\\).\nCalculate the element at Row 2, Column 2: (Row 2 of A) \\(\\cdot\\) (Column 2 of B) = \\((-1)(-1) + (2)(2) = 1 + 4 = 5\\).\nCalculate the element at Row 3, Column 1: (Row 3 of A) \\(\\cdot\\) (Column 1 of B) = \\((1)(4) + (1)(0) = 4\\).\nCalculate the element at Row 3, Column 2: (Row 3 of A) \\(\\cdot\\) (Column 2 of B) = \\((1)(-1) + (1)(2) = -1 + 2 = 1\\).\nAssemble the final matrix: \\[ \\begin{pmatrix} 12 & -3 \\\\ -4 & 5 \\\\ 4 & 1 \\end{pmatrix} \\]\n\nAnswer: The resulting matrix is \\(\\begin{pmatrix} 12 & -3 \\\\ -4 & 5 \\\\ 4 & 1 \\end{pmatrix}\\).\n\n\n\nExample 3: Determinant with Scalar Multiplication (Lab 3, 2e)\nQuestion: Given \\(D = \\begin{pmatrix} 1 & 5 & 2 \\\\ -1 & 0 & 1 \\\\ 3 & 2 & 4 \\end{pmatrix}\\), compute \\(\\det(2D)\\).\n\n\nClick to see the solution\n\n\nRecall the property of determinants with scalar multiplication: For an \\(n \\times n\\) matrix, \\(\\det(kA) = k^n \\det(A)\\).\nIdentify n and k: Here, D is a 3x3 matrix, so \\(n=3\\). The scalar is \\(k=2\\). Therefore, \\(\\det(2D) = 2^3 \\det(D) = 8 \\det(D)\\).\nCalculate \\(\\det(D)\\) using Sarrus’s Rule:\n\nSum of main diagonals: \\((1)(0)(4) + (5)(1)(3) + (2)(-1)(2) = 0 + 15 - 4 = 11\\).\nSum of anti-diagonals: \\((2)(0)(3) + (1)(1)(2) + (5)(-1)(4) = 0 + 2 - 20 = -18\\).\n\\(\\det(D) = (11) - (-18) = 11 + 18 = 29\\).\n\nCalculate the final result: \\(\\det(2D) = 8 \\times \\det(D) = 8 \\times 29 = 232\\).\n\nAnswer: \\(\\det(2D) = 232\\).\n\n\n\nExample 4: Area of a Triangle (Tutorial, Problem 1)\nQuestion: Compute the area of a triangle with vertices at A(1, 2, 0), B(3, 0, -3), and C(5, 2, 6).\n\n\nClick to see the solution\n\n\nDefine two vectors spanning the triangle from vertex A:\n\n\\(\\vec{AB} = B - A = (3-1, 0-2, -3-0) = \\langle 2, -2, -3 \\rangle\\).\n\\(\\vec{AC} = C - A = (5-1, 2-2, 6-0) = \\langle 4, 0, 6 \\rangle\\).\n\nCompute the cross product \\(\\vec{AB} \\times \\vec{AC}\\): \\[ \\vec{AB} \\times \\vec{AC} = \\det \\begin{pmatrix} \\mathbf{i} & \\mathbf{j} & \\mathbf{k} \\\\ 2 & -2 & -3 \\\\ 4 & 0 & 6 \\end{pmatrix} \\]\n\n\\(\\mathbf{i}\\) component: \\(((-2)(6) - (-3)(0)) = -12\\).\n\\(\\mathbf{j}\\) component: \\(-((2)(6) - (-3)(4)) = -(12 + 12) = -24\\).\n\\(\\mathbf{k}\\) component: \\(((2)(0) - (-2)(4)) = 8\\).\nThe resulting vector is \\(\\langle -12, -24, 8 \\rangle\\).\n\nFind the magnitude of the cross product vector: \\[ ||\\langle -12, -24, 8 \\rangle|| = \\sqrt{(-12)^2 + (-24)^2 + 8^2} = \\sqrt{144 + 576 + 64} = \\sqrt{784} = 28 \\] This magnitude is the area of the parallelogram formed by \\(\\vec{AB}\\) and \\(\\vec{AC}\\).\nCalculate the area of the triangle: The area of the triangle is half the area of the parallelogram. \\[ \\text{Area} = \\frac{1}{2} \\times 28 = 14 \\]\n\nAnswer: The area of the triangle is 14 square units.\n\n\n\nExample 5: Finding a Matrix Inverse (Lab 3, 4a)\nQuestion: Find the inverse of the matrix \\(X = \\begin{pmatrix} 3 & 4 & -1 \\\\ 2 & 0 & 7 \\\\ 1 & -3 & -2 \\end{pmatrix}\\).\n\n\nClick to see the solution\n\n\nStep 1: Calculate the Determinant of X. \\[ \\det(X) = 3(0 - (-21)) - 4(-4 - 7) + (-1)(-6 - 0) \\] \\[ \\det(X) = 3(21) - 4(-11) - 1(-6) = 63 + 44 + 6 = 113 \\] Since \\(\\det(X) \\neq 0\\), the inverse exists.\nStep 2: Find the Matrix of Minors. \\[ M = \\begin{pmatrix}\n(0)(-2) - (7)(-3) & (2)(-2) - (7)(1) & (2)(-3) - (0)(1) \\\\\n(4)(-2) - (-1)(-3) & (3)(-2) - (-1)(1) & (3)(-3) - (4)(1) \\\\\n(4)(7) - (-1)(0) & (3)(7) - (-1)(2) & (3)(0) - (4)(2)\n\\end{pmatrix} = \\begin{pmatrix}\n21 & -11 & -6 \\\\\n-11 & -5 & -13 \\\\\n28 & 23 & -8\n\\end{pmatrix} \\]\nStep 3: Find the Matrix of Cofactors (apply the checkerboard sign pattern). \\[ C = \\begin{pmatrix}\n+21 & -(-11) & +(-6) \\\\\n-(-11) & +(-5) & -(-13) \\\\\n+28 & -(23) & +(-8)\n\\end{pmatrix} = \\begin{pmatrix}\n21 & 11 & -6 \\\\\n11 & -5 & 13 \\\\\n28 & -23 & -8\n\\end{pmatrix} \\]\nStep 4: Find the Adjugate Matrix (transpose the cofactor matrix). \\[ \\text{adj}(X) = C^T = \\begin{pmatrix}\n21 & 11 & 28 \\\\\n11 & -5 & -23 \\\\\n-6 & 13 & -8\n\\end{pmatrix} \\]\nStep 5: Calculate the Inverse using \\(X^{-1} = \\frac{1}{\\det(X)}\\text{adj}(X)\\). \\[ X^{-1} = \\frac{1}{113} \\begin{pmatrix}\n21 & 11 & 28 \\\\\n11 & -5 & -23 \\\\\n-6 & 13 & -8\n\\end{pmatrix} \\]\n\nAnswer: \\(X^{-1} = \\begin{pmatrix}\n    21/113 & 11/113 & 28/113 \\\\\n    11/113 & -5/113 & -23/113 \\\\\n    -6/113 & 13/113 & -8/113\n    \\end{pmatrix}\\)",
    "crumbs": [
      "Analytical Geometry and Linear Algebra I ",
      "3. Matrices and Determinants, Vector Cross Product, Scalar Triple Product"
    ]
  },
  {
    "objectID": "Discrete Mathematics/lec_2.html",
    "href": "Discrete Mathematics/lec_2.html",
    "title": "2. Logical Equivalence, Normal Forms (DNF, CNF, ANF)",
    "section": "",
    "text": "1. Summary\n\n1.1 Classification of Logical Formulas\nIn logic, any declarative statement, or proposition, can be classified based on its truth values across all possible scenarios.\n\nA Tautology is a formula that is always true, regardless of the truth values of its variables. For example, the formula \\(p \\lor \\neg p\\) is a tautology because it is true whether \\(p\\) is true or false.\nA Contradiction is a formula that is always false. The formula \\(p \\land \\neg p\\) is a contradiction.\nA Contingency is a formula that is neither a tautology nor a contradiction. Its truth value depends on the truth values of its variables. For example, \\(p \\land q\\) is a contingency.\n\nA formula is considered satisfiable if there exists at least one assignment of truth values to its variables that makes the entire formula true. Both tautologies and contingencies are satisfiable, while contradictions are not.\n\n\n1.2 Logical Equivalence\nTwo propositions, \\(P_1\\) and \\(P_2\\), are logically equivalent if they have the exact same truth table. This means that for every possible combination of truth values for their variables, \\(P_1\\) and \\(P_2\\) will have the same resulting truth value. We denote this equivalence using the symbol \\(\\equiv\\). For example, the implication \\(a \\rightarrow b\\) is logically equivalent to \\(\\neg a \\lor b\\), written as \\(a \\rightarrow b \\equiv \\neg a \\lor b\\).\nProving logical equivalence can be done by constructing a truth table for both expressions or by using a series of known equivalences (laws) to transform one expression into the other.\n\n\n1.3 Key Logical Equivalences (Laws)\n\nIdentity Laws: \\(p \\lor F \\equiv p\\), \\(p \\land T \\equiv p\\)\nDomination Laws: \\(p \\lor T \\equiv T\\), \\(p \\land F \\equiv F\\)\nIdempotent Laws: \\(p \\lor p \\equiv p\\), \\(p \\land p \\equiv p\\)\nDouble Negation Law: \\(\\neg(\\neg p) \\equiv p\\)\nCommutative Laws: \\(p \\lor q \\equiv q \\lor p\\), \\(p \\land q \\equiv q \\land p\\)\nAssociative Laws: \\((p \\lor q) \\lor r \\equiv p \\lor (q \\lor r)\\), \\((p \\land q) \\land r \\equiv p \\land (q \\land r)\\)\nDistributive Laws: \\(p \\lor (q \\land r) \\equiv (p \\lor q) \\land (p \\lor r)\\), \\(p \\land (q \\lor r) \\equiv (p \\land q) \\lor (p \\land r)\\)\nDe Morgan’s Laws: These are crucial for simplifying negated expressions: \\(\\neg(p \\land q) \\equiv \\neg p \\lor \\neg q\\) and \\(\\neg(p \\lor q) \\equiv \\neg p \\land \\neg q\\). Correction from source material: The slides correctly apply the laws, but it’s important to state explicitly that the operator between the terms is also inverted (AND to OR, OR to AND).\nAbsorption Laws: \\(p \\lor (p \\land q) \\equiv p\\), \\(p \\land (p \\lor q) \\equiv p\\)\nImplication Equivalence: \\(p \\rightarrow q \\equiv \\neg p \\lor q\\)\nBi-implication Equivalence: \\(p \\leftrightarrow q \\equiv (p \\rightarrow q) \\land (q \\rightarrow p) \\equiv (p \\land q) \\lor (\\neg p \\land \\neg q)\\)\n\n\n\n1.4 Normal Forms: DNF and CNF\nA logical formula can be standardized into a normal form.\n\nDisjunctive Normal Form (DNF): A formula is in DNF if it is a disjunction (ORs) of conjunctions (ANDs) of literals (a variable or its negation). A DNF expression can be derived from a truth table by taking every row where the formula is true and creating an AND clause that matches that row’s inputs. All these AND clauses are then ORed together. This is often called a “sum of products.”\nConjunctive Normal Form (CNF): A formula is in CNF if it is a conjunction (ANDs) of disjunctions (ORs) of literals. A CNF expression can be derived from a truth table by taking every row where the formula is false, creating an OR clause from the negation of that row’s inputs, and then ANDing all these OR clauses together. This is often called a “product of sums.”\n\n\n\n1.5 Algebraic Normal Form (ANF)\nAlgebraic Normal Form (ANF), also known as a Zhegalkin polynomial, re-expresses a logical formula as a polynomial modulo 2. In this system, multiplication corresponds to the logical AND (\\(\\land\\)), and addition corresponds to the logical XOR (\\(\\oplus\\)).\nThe key translations are:\n\n\\(p \\land q \\equiv p \\cdot q\\) (or simply \\(pq\\))\n\\(p \\oplus q\\) (XOR)\n\\(\\neg p \\equiv p \\oplus 1\\)\n\\(p \\lor q \\equiv p \\oplus q \\oplus pq\\)\n\\(p \\rightarrow q \\equiv 1 \\oplus p \\oplus pq\\)\n\\(p \\leftrightarrow q \\equiv 1 \\oplus p \\oplus q\\)\n\nAny boolean expression can be uniquely converted into this polynomial form, which is useful in cryptography and circuit design.\n\n\n\n\n2. Definitions\n\nProposition: A declarative statement that is either true or false.\nTautology: A logical formula that is true for all possible truth value assignments to its variables.\nContradiction: A logical formula that is false for all possible truth value assignments.\nContingency: A formula that can be either true or false, depending on the truth values of its variables.\nSatisfiable Formula: A formula for which there exists at least one assignment of truth values that makes the formula true.\nLogical Equivalence: The property of two formulas having identical truth tables.\nLiteral: A propositional variable (e.g., \\(p\\)) or its negation (e.g., \\(\\neg p\\)).\nDisjunctive Normal Form (DNF): A logical formula represented as a disjunction of conjunctive clauses (e.g., \\((p \\land q) \\lor (\\neg r \\land s)\\)).\nConjunctive Normal Form (CNF): A logical formula represented as a conjunction of disjunctive clauses (e.g., \\((p \\lor q) \\land (\\neg r \\lor s)\\)).\nAlgebraic Normal Form (ANF): The representation of a logical function as a polynomial using AND (multiplication) and XOR (addition) operations modulo 2.\n\n\n\n\n3. Formulas\n\nDouble Negation: \\(\\neg(\\neg p) \\equiv p\\)\nDe Morgan’s Laws:\n\n\\(\\neg(p \\lor q) \\equiv \\neg p \\land \\neg q\\)\n\\(\\neg(p \\land q) \\equiv \\neg p \\lor \\neg q\\)\n\nDistributive Laws:\n\n\\(p \\land (q \\lor r) \\equiv (p \\land q) \\lor (p \\land r)\\)\n\\(p \\lor (q \\land r) \\equiv (p \\lor q) \\land (p \\lor r)\\)\n\nImplication: \\(p \\rightarrow q \\equiv \\neg p \\lor q\\)\nBi-implication: \\(p \\leftrightarrow q \\equiv (p \\land q) \\lor (\\neg p \\land \\neg q)\\)\nAlgebraic Normal Form (ANF) Conversions:\n\n\\(\\neg p \\equiv p \\oplus 1\\)\n\\(p \\lor q \\equiv p \\oplus q \\oplus pq\\)\n\\(p \\land q \\equiv pq\\)\n\\(p \\rightarrow q \\equiv 1 \\oplus p \\oplus pq\\)\n\\(p \\leftrightarrow q \\equiv 1 \\oplus p \\oplus q\\)\n\nANF Properties (Modulo 2):\n\n\\(p \\oplus p \\equiv 0\\)\n\\(p \\cdot p \\equiv p\\)\n\n\n\n\n\n4. Mistakes\n\nIncorrectly applying De Morgan’s Law: A common mistake is to distribute the negation without flipping the operator. For example, writing \\(\\neg(a \\lor b)\\) as \\(\\neg a \\lor \\neg b\\). Why it’s wrong: De Morgan’s Law requires inverting the operator as well, so the correct form is \\(\\neg a \\land \\neg b\\).\nConfusing XOR with OR in ANF: Translating \\(a \\lor b\\) as just \\(a \\oplus b\\). Why it’s wrong: Logical OR is not equivalent to XOR. The correct ANF for OR is \\(a \\oplus b \\oplus ab\\). The term \\(ab\\) corrects for the case where both \\(a\\) and \\(b\\) are true, as \\(1 \\oplus 1 = 0\\) but \\(1 \\lor 1 = 1\\).\nAssuming Distributivity of XOR over AND: Believing that \\(x \\oplus (y \\cdot z) \\equiv (x \\oplus y) \\cdot (x \\oplus z)\\). Why it’s wrong: This property does not hold in Boolean algebra. As shown in the slides, a truth table for both sides yields different results. AND distributes over XOR, but not the other way around.\nErrors in CNF/DNF Simplification: Failing to apply the absorption law, \\(a \\lor (a \\land b) \\equiv a\\). A student might leave the expression as is, thinking it’s fully simplified. Why it’s wrong: The absorption law shows that the term \\((a \\land b)\\) is redundant if \\(a\\) is already present in a disjunction, leading to a simpler, equivalent formula.\nForgetting to Negate Inputs for CNF: When deriving CNF from a truth table, one must create OR clauses for the rows where the output is FALSE. A common error is to use the variables directly instead of their negations. Why it’s wrong: To make the clause true (and thus not affect the outcome of the AND expression), you must ensure that the specific combination of false inputs evaluates to true in the clause. For a false row like \\((a=0, b=1)\\), the clause must be \\((\\neg a \\lor b)\\) to be a valid part of the CNF. Correction: The slide says for CNF use \\((\\neg a \\lor b)\\) for the row where a=1,b=0. This is correct, as for that specific input combination (which makes the original function false), this clause also evaluates to false (0 v 0 = 0). The full CNF is a conjunction of such clauses that are 0 only on their specific false line.\n\n\n\n\n5. Examples\n\nExample 1: Applying De Morgan’s Laws\nQuestion: Apply negation and simplify the expression \\((\\neg a \\lor b) \\land (c \\lor \\neg d)\\) using De Morgan’s Laws.\n\n\nClick to see the solution\n\n\nApply negation to the entire expression: \\[ \\neg ((\\neg a \\lor b) \\land (c \\lor \\neg d)) \\]\nApply De Morgan’s Law to the central AND operator. This flips the AND to an OR and distributes the negation to the two parenthetical clauses. \\[ \\neg(\\neg a \\lor b) \\lor \\neg(c \\lor \\neg d) \\]\nApply De Morgan’s Law to each of the two clauses.\n\nFor the first clause: \\(\\neg(\\neg a \\lor b) \\equiv \\neg(\\neg a) \\land \\neg b\\)\nFor the second clause: \\(\\neg(c \\lor \\neg d) \\equiv \\neg c \\land \\neg(\\neg d)\\)\n\nSimplify using the Double Negation law (\\(\\neg(\\neg p) \\equiv p\\)).\n\nFirst clause becomes: \\(a \\land \\neg b\\)\nSecond clause becomes: \\(\\neg c \\land d\\)\n\nCombine the simplified clauses with the OR from step 2.\n\nAnswer: The simplified expression is \\((a \\land \\neg b) \\lor (\\neg c \\land d)\\).\n\n\n\nExample 2: Finding and Simplifying DNF\nQuestion: Find the Disjunctive Normal Form (DNF) for a function \\(\\Phi(x, y, z)\\) with the truth table vector \\((01111110)\\) and simplify it. (The vector represents the function’s output for inputs \\(xyz=000, 001, ..., 111\\)).\n\n\nClick to see the solution\n\n\nIdentify rows where the output is 1. These correspond to the minterms.\n\n\\(xyz=001\\): \\(\\neg x \\land \\neg y \\land z\\)\n\\(xyz=010\\): \\(\\neg x \\land y \\land \\neg z\\)\n\\(xyz=011\\): \\(\\neg x \\land y \\land z\\)\n\\(xyz=100\\): \\(x \\land \\neg y \\land \\neg z\\)\n\\(xyz=101\\): \\(x \\land \\neg y \\land z\\)\n\\(xyz=110\\): \\(x \\land y \\land \\neg z\\)\n\nWrite the full DNF by ORing all minterms: \\[ (\\neg x \\land \\neg y \\land z) \\lor (\\neg x \\land y \\land \\neg z) \\lor (\\neg x \\land y \\land z) \\lor (x \\land \\neg y \\land \\neg z) \\lor (x \\land \\neg y \\land z) \\lor (x \\land y \\land \\neg z) \\]\nSimplify by grouping terms.\n\nGroup \\((\\neg x \\land y \\land \\neg z) \\lor (\\neg x \\land y \\land z) \\rightarrow \\neg x \\land y\\)\nGroup \\((\\neg x \\land \\neg y \\land z) \\lor (\\neg x \\land y \\land z) \\rightarrow \\neg x \\land z\\)\nGroup \\((x \\land \\neg y \\land z) \\lor (\\neg x \\land \\neg y \\land z) \\rightarrow \\neg y \\land z\\)\nIt is often easier to derive the CNF for the ‘0’ cases and then negate. The function is 0 for \\(xyz=000\\) and \\(xyz=111\\).\n\nAlternative (easier) Method: Find CNF of the zeros and apply De Morgan’s law.\n\nThe function is 0 for \\(xyz=000\\) and \\(xyz=111\\).\nThe CNF of the function is \\((x \\lor y \\lor z) \\land (\\neg x \\lor \\neg y \\lor \\neg z)\\).\nThe DNF of the negation is \\((\\neg x \\land \\neg y \\land \\neg z) \\lor (x \\land y \\land z)\\).\nNegating this gives back the original function’s DNF: \\(\\neg((\\neg x \\land \\neg y \\land \\neg z) \\lor (x \\land y \\land z)) \\equiv (x \\lor y \\lor z) \\land (\\neg x \\lor \\neg y \\lor \\neg z)\\), which is the CNF. Let’s return to simplifying the DNF directly.\n\nSimplify the full DNF using consensus or algebraic manipulation.\n\n\\((\\neg x \\land \\neg y \\land z) \\lor (\\neg x \\land y \\land z) = \\neg x \\land z\\)\n\\((\\neg x \\land y \\land \\neg z) \\lor (x \\land y \\land \\neg z) = y \\land \\neg z\\)\n\\((x \\land \\neg y \\land \\neg z) \\lor (x \\land \\neg y \\land z) = x \\land \\neg y\\)\nThe simplified expression is the OR of these three terms.\n\n\nAnswer: The simplified DNF is \\((\\neg x \\land z) \\lor (y \\land \\neg z) \\lor (x \\land \\neg y)\\).\n\n\n\nExample 3: Finding and Simplifying CNF\nQuestion: Find the Conjunctive Normal Form (CNF) for a function \\(\\Psi(x, y, z)\\) with the truth table vector \\((00110000)\\) and simplify it.\n\n\nClick to see the solution\n\n\nIdentify rows where the output is 0. These will form the clauses of the CNF.\n\n\\(xyz=000\\): Clause is \\((x \\lor y \\lor z)\\)\n\\(xyz=001\\): Clause is \\((x \\lor y \\lor \\neg z)\\)\n\\(xyz=100\\): Clause is \\((\\neg x \\lor y \\lor z)\\)\n\\(xyz=101\\): Clause is \\((\\neg x \\lor y \\lor \\neg z)\\)\n\\(xyz=110\\): Clause is \\((\\neg x \\lor \\neg y \\lor z)\\)\n\\(xyz=111\\): Clause is \\((\\neg x \\lor \\neg y \\lor \\neg z)\\)\n\nWrite the full CNF by ANDing all clauses: \\[ (x \\lor y \\lor z) \\land (x \\lor y \\lor \\neg z) \\land (\\neg x \\lor y \\lor z) \\land (\\neg x \\lor y \\lor \\neg z) \\land (\\neg x \\lor \\neg y \\lor z) \\land (\\neg x \\lor \\neg y \\lor \\neg z) \\]\nSimplify by grouping terms using the rule \\((A \\lor B) \\land (A \\lor \\neg B) \\equiv A\\).\n\nGroup 1 & 2: \\((x \\lor y \\lor z) \\land (x \\lor y \\lor \\neg z) \\equiv (x \\lor y)\\)\nGroup 3 & 4: \\((\\neg x \\lor y \\lor z) \\land (\\neg x \\lor y \\lor \\neg z) \\equiv (\\neg x \\lor y)\\)\nGroup 5 & 6: \\((\\neg x \\lor \\neg y \\lor z) \\land (\\neg x \\lor \\neg y \\lor \\neg z) \\equiv (\\neg x \\lor \\neg y)\\)\n\nCombine the results: \\[ (x \\lor y) \\land (\\neg x \\lor y) \\land (\\neg x \\lor \\neg y) \\]\nSimplify further.\n\nGroup the first two simplified clauses: \\((x \\lor y) \\land (\\neg x \\lor y) \\equiv y\\).\nNow we have: \\(y \\land (\\neg x \\lor \\neg y)\\).\n\nApply the distributive law: \\[ (y \\land \\neg x) \\lor (y \\land \\neg y) \\]\nSince \\((y \\land \\neg y) \\equiv F\\) (contradiction), the expression simplifies to the first term.\n\nAnswer: The simplified CNF is \\(y \\land \\neg x\\). (The DNF would be the same).\n\n\n\nExample 4: Converting to Algebraic Normal Form (ANF)\nQuestion: Find the Algebraic Normal Form for the expression \\((a \\rightarrow \\neg b) \\land (b \\rightarrow a)\\).\n\n\nClick to see the solution\n\n\nTranslate each part of the expression into its ANF equivalent.\n\nFirst, translate the implications:\n\n\\(a \\rightarrow \\neg b\\): The formula for implication \\(x \\rightarrow y\\) is \\(1 \\oplus x \\oplus xy\\). Here, \\(x=a\\) and \\(y=\\neg b\\).\n\\(b \\rightarrow a\\): Here, \\(x=b\\) and \\(y=a\\). So it becomes \\(1 \\oplus b \\oplus ba\\).\n\n\nSubstitute the ANF for negation. The formula for negation \\(\\neg y\\) is \\(y \\oplus 1\\).\n\n\\(\\neg b \\equiv b \\oplus 1\\).\n\nSubstitute back into the first implication.\n\n\\(a \\rightarrow \\neg b \\equiv 1 \\oplus a \\oplus a(\\neg b) \\equiv 1 \\oplus a \\oplus a(b \\oplus 1)\\)\nDistribute \\(a\\): \\(1 \\oplus a \\oplus (ab \\oplus a)\\)\nSince \\(a \\oplus a = 0\\), this simplifies to \\(1 \\oplus ab\\).\n\nThe full expression is the AND (multiplication) of the two translated parts. \\[ (1 \\oplus ab) \\cdot (1 \\oplus b \\oplus ab) \\]\nExpand the polynomial (multiply the terms). \\[ 1(1 \\oplus b \\oplus ab) \\oplus ab(1 \\oplus b \\oplus ab) \\] \\[ (1 \\oplus b \\oplus ab) \\oplus (ab \\oplus ab^2 \\oplus a^2b^2) \\]\nSimplify using modulo 2 rules: \\(x \\oplus x = 0\\) and \\(x^2 = x\\).\n\n\\(ab^2 = ab\\) and \\(a^2b^2 = ab\\).\nThe expression becomes: \\(1 \\oplus b \\oplus ab \\oplus ab \\oplus ab \\oplus ab\\)\n\nCancel out pairs.\n\n\\(ab \\oplus ab = 0\\). We have two such pairs.\nThe expression simplifies to: \\(1 \\oplus b\\).\n\n\nAnswer: The ANF is \\(1 \\oplus b\\) (which is equivalent to \\(\\neg b\\)).",
    "crumbs": [
      "Discrete Mathematics",
      "2. Logical Equivalence, Normal Forms (DNF, CNF, ANF)"
    ]
  },
  {
    "objectID": "Computer Architecture/lec_2.html",
    "href": "Computer Architecture/lec_2.html",
    "title": "2. Fundamental Ideas of Computer Architecture",
    "section": "",
    "text": "1. Summary\n\n1.1 Hierarchy of Memories\nComputer systems use a variety of memory types, organized into a hierarchy based on their performance characteristics. This structure is a trade-off between speed, capacity, and cost. The levels are arranged like a pyramid: the fastest, smallest, and most expensive memory is at the top, closest to the CPU, while the slowest, largest, and cheapest is at the bottom.\n\nCPU Registers: These are the fastest memory units, located directly inside the CPU (Central Processing Unit). They hold the data that the CPU is actively manipulating at any given moment. Their capacity is extremely small (measured in bytes).\nCache Memory (L1, L2, L3): A small, fast layer of memory that sits between the CPU and the main system memory (RAM). It stores copies of frequently used data from RAM. When the CPU needs data, it checks the cache first. If the data is there (a cache hit), it’s retrieved much faster than from RAM. If not (a cache miss), the data is fetched from RAM and also stored in the cache for future use.\nSystem Memory (RAM): Random-Access Memory is the main working memory of the computer. It is much larger than the cache but also significantly slower. It holds the operating system, running applications, and the data they are using. RAM is volatile, meaning its contents are lost when the power is turned off.\nStorage Devices (SSD, HDD): These are used for long-term data storage. They are the largest and slowest level in the hierarchy and are non-volatile, meaning they retain data without power.\n\nAs data moves from the bottom of the hierarchy to the top, the access speed increases dramatically, but the storage capacity decreases.\n\n\n1.2 Design Simplification via Abstraction\nAbstraction is a core principle used to manage complexity in computer architecture. It involves hiding the complex details of a system and exposing only the essential features. This allows designers and programmers to work with a system at a high level without needing to understand every detail of its low-level implementation.\nFor example, a programmer views the CPU as a simple black box that executes instructions. This is the highest level of abstraction. A computer architect, however, looks inside this box and sees components like the Control Unit (CU), the Arithmetic Logic Unit (ALU), and registers. A hardware engineer might go even deeper, designing the individual logic gates and circuits that make up the ALU. Each layer only needs to understand its own level and the interface to the levels directly above and below it, simplifying the overall design process. As you move from a high-level view to a low-level one, the abstraction level decreases, and the level of detail increases.\n\n\n1.3 Moore’s Law for CPU Performance\nMoore’s Law is an observation made by Gordon Moore in 1965, stating that the number of transistors on an integrated circuit (CPU chip) doubles approximately every two years. For decades, this rapid increase in transistor density directly correlated with an exponential increase in CPU performance and execution speed.\nHowever, since around 2008, the rate of increase for single-thread performance and CPU clock speed has stagnated. This is primarily due to two physical limitations: 1. Heat Dissipation: Faster clock speeds lead to higher power consumption, which generates more heat. At a certain point, it becomes impossible to cool the chip effectively, causing it to overheat and fail. 2. The Speed of Light: As transistors become smaller and closer, the time it takes for electrical signals to travel between them becomes a limiting factor.\nBecause of this stagnation, the industry shifted its focus from making single cores faster to adding more cores to a single chip. This means that performance gains today are primarily achieved through parallelism, not by increasing the speed of a single CPU core.\n\n\n1.4 Performance via Parallelism\nParallelism is the concept of executing multiple tasks or instructions simultaneously to improve performance. In contrast to a uniprocessor system that executes one instruction at a time, a multiprocessor or multicore system contains multiple processing units that can work on different tasks concurrently.\nThis approach is the primary driver of performance improvement in modern computing. For example, a quad-core processor can theoretically work on four different instructions at the exact same time. However, this introduces new challenges. The main problem is data dependency, where one instruction depends on the result of a previous one. Such instructions cannot be executed in parallel and must wait for the preceding one to complete, which requires complex scheduling and synchronization logic.\n\n\n1.5 Performance via Pipelining\nPipelining is a technique that increases the throughput of a single CPU, which is the number of instructions it can complete per unit of time. It doesn’t execute multiple instructions simultaneously in the same way parallelism does; instead, it overlaps the execution steps of different instructions.\nThe execution of a single instruction is broken down into a series of independent stages, such as:\n\nIF (Instruction Fetch): Fetch the instruction from memory.\nID (Instruction Decode): Decode the instruction to see what it does.\nEX (Execute): Perform the calculation in the ALU.\nMEM (Memory Access): Read or write data from/to memory.\nWB (Write Back): Write the result back to a register.\n\nIn a non-pipelined CPU, one instruction must complete all five stages before the next one can begin. In a pipelined CPU, a new instruction can start the first stage as soon as the previous instruction has moved to the second stage. This creates an assembly-line effect where multiple instructions are in different stages of execution at the same time within the same CPU core.\nThe key difference from parallelism is that pipelining overlaps stages of sequential instructions within one processor, while parallelism executes different instructions simultaneously on multiple processors.\n\n\n1.6 Performance via Speculation (Prediction)\nSpeculative Execution is an optimization technique where a computer system performs a task before it is known whether the work is actually needed. The goal is to prevent the CPU from sitting idle while waiting for the outcome of a preceding instruction, such as a conditional branch (if-else or switch statement).\nThe CPU’s branch predictor tries to guess which path of execution will be taken. For example, in a switch statement, the processor might predict which case is most likely to be executed. It will then speculatively start executing the instructions for that predicted path.\n\nIf the prediction was correct, the results are kept, and time has been saved.\nIf the prediction was wrong, the results of the speculative execution are discarded, and the CPU starts over on the correct path. Although there’s a penalty for a wrong guess, on average, the time saved from correct predictions leads to a significant performance boost.\n\n\n\n1.7 Dependability via Redundancy\nRedundancy is the principle of including duplicate or “spare” components in a system to increase its dependability and reliability. If a primary component fails, a backup component can take over its function, ensuring the system continues to operate without interruption.\nThis approach is critical in fault-tolerant systems where failure is not an option, such as in spacecraft, aircraft control systems, or critical financial servers. For instance, a spacecraft might be designed with three identical CPUs all performing the same calculations. The results are compared, and if one CPU produces a different result, it is assumed to be faulty and is ignored by the system.\n\n\n1.8 Make the Common Case Fast\nThis is a fundamental design principle that states that to improve overall performance, you should focus your optimization efforts on the parts of the system that are used most frequently. The benefit gained from making a rare operation faster is often negligible, but a small improvement in a very common operation can have a huge impact.\nFor example, if a program spends 90% of its time executing a particular function, then doubling the speed of that function will nearly double the speed of the entire program. In contrast, doubling the speed of a function that only accounts for 1% of the execution time will have almost no noticeable effect on overall performance. This principle guides architects and programmers on where to invest their time and resources for the greatest return.\n\n\n1.9 Finite State Machines (FSM)\nA Finite State Machine (FSM) is a mathematical model of computation used to design and describe the behavior of systems. An FSM consists of a finite number of states and a set of transitions that define how the system moves from one state to another in response to specific inputs or events.\nAt any given moment, the system can only be in one state. For example, a vending machine can be modeled as an FSM:\n\nStates: Awaiting Client, Requesting Payment, Delivering Product, Returning Money.\nTransitions: A client choosing a product transitions the machine from Awaiting Client to Requesting Payment. A successful payment transitions it to Delivering Product.\n\nFSMs are widely used in computer architecture to model the behavior of digital logic circuits, processor control units, and communication protocols.\n\n\n\n2. Definitions\n\nComputer Architecture: The set of rules and methods that describe the functionality, organization, and implementation of computer systems. It acts as the blueprint for designing the system.\nHierarchy of Memories: A tiered structure of computer storage where memory is organized based on access speed, capacity, and cost. Faster tiers are smaller and more expensive.\nCache: A small, high-speed volatile memory that provides high-speed data access to a processor and stores frequently used computer programs, applications, and data.\nCPU Registers: A small set of data holding places that are part of the computer processor. A register may hold an instruction, a storage address, or any kind of data.\nMoore’s Law: The observation that the number of transistors in an integrated circuit doubles about every two years.\nParallelism: The simultaneous execution of multiple instructions or tasks on different processors or cores to increase computational speed.\nPipelining: A technique where multiple instructions are overlapped in execution within a single processor. Each instruction is broken into stages, and different instructions can be in different stages at the same time.\nSpeculative Execution: An optimization technique where a processor executes instructions before it is certain they will be needed, based on a prediction of program flow.\nRedundancy: The inclusion of extra components that are not strictly necessary to functioning, in case of failure in other components.\nFinite State Machine (FSM): An abstract model of computation that can be in exactly one of a finite number of states at any given time.\n\n\n\n3. Mistakes\n\nConfusing Parallelism and Pipelining: Thinking these are the same concept. Why it’s wrong: Parallelism involves using multiple, independent processing units to execute different tasks simultaneously. Pipelining is a technique used within a single processing unit to overlap the stages of sequential instructions. It improves throughput, but does not execute instructions truly simultaneously in the way parallelism does.\nBelieving Moore’s Law is about CPU speed: Stating that Moore’s Law dictates that CPU clock speeds double every two years. Why it’s wrong: Moore’s Law is specifically about the number of transistors on a chip. While this historically led to faster speeds, the direct correlation has broken down due to heat and power limitations. The law itself is about density, not speed.\nAssuming more cores directly translates to proportional speedup: Thinking that a program will run four times faster on a quad-core CPU than on a single-core CPU. Why it’s wrong: This is only true for tasks that are “embarrassingly parallel” (can be perfectly split into independent parts). Most programs have sequential parts and dependencies that cannot be parallelized, limiting the overall speedup (a concept described by Amdahl’s Law).\nIgnoring the “Common Case Fast” principle: Spending significant time optimizing a part of the code that is rarely executed. Why it’s wrong: The overall performance gain is a product of how much faster a part is and how often it is used. Optimizing an infrequently used component yields a negligible improvement to the total execution time, making it an inefficient use of development resources.\nTreating all memory as equal: Writing code that accesses memory in random patterns without considering the memory hierarchy. Why it’s wrong: Accessing data that is close together in memory (spatial locality) allows the cache to work efficiently, dramatically speeding up execution. Random memory access patterns lead to frequent cache misses, forcing the CPU to wait for the much slower main memory and crippling performance.\n\n\n\n4. Examples\n\nExample 1: Hierarchy of Memories\nQuestion: A programmer declares an integer variable x = 10 inside a function that performs a tight loop of calculations with it. After the program finishes, the result is saved to a file on the hard drive. Where would the value of x most likely reside during each phase: (a) active calculation in the loop, (b) after the program closes, and (c) while the function is running but x is not the immediate operand?\n\n\nClick to see the solution\n\n\nAnalyze Phase (a): During a tight loop of active calculations, the CPU needs the fastest possible access to the variable. This is the primary use case for registers.\nAnalyze Phase (b): After the program closes, all volatile memory (registers, cache, RAM) is cleared. The only place the result persists is in non-volatile storage.\nAnalyze Phase (c): While the function is running, the variable x is loaded from storage into system RAM. If it’s used frequently, it will be copied to the cache for faster access, even when it’s not the immediate operand being processed by the ALU.\n\nAnswer: (a) In a CPU Register. (b) In Storage (the hard drive/SSD). (c) In Cache Memory or System Memory (RAM).\n\n\n\nExample 2: Parallelism vs. Pipelining\nQuestion: A fast-food restaurant needs to speed up its order processing. It considers two options: 1. Hire three more cashiers to run three additional checkout counters. Each cashier handles an entire order from start to finish (take order, process payment, get food). 2. Keep one cashier but create an assembly line with three additional workers: one takes the order, the next processes payment, the next bags the food, and the last hands it to the customer.\nWhich option is an analogy for parallelism, and which is for pipelining? Explain why.\n\n\nClick to see the solution\n\n\nAnalyze Option 1: This option involves multiple independent units (cashiers) performing the same complete task on different inputs (customers) simultaneously. This is the definition of parallelism.\nAnalyze Option 2: This option involves breaking a single task (processing one order) into a series of sequential stages. Multiple orders can be in different stages of the process at the same time, increasing the overall throughput of the single checkout counter. This is the definition of pipelining.\n\nAnswer: Option 1 (multiple cashiers) is an analogy for parallelism. Option 2 (the assembly line) is an analogy for pipelining.\n\n\n\nExample 3: Make the Common Case Fast\nQuestion: You are profiling a web server application and find that 80% of its execution time is spent on a single database query function, getUserProfile(). The rest of the time is split among 50 other minor functions. You have one week to optimize the application. Should you focus on improving getUserProfile() or on optimizing several of the other minor functions?\n\n\nClick to see the solution\n\n\nIdentify the Common Case: The profiling data clearly shows that the getUserProfile() function is the “common case” in terms of time consumption, accounting for 80% of the workload.\nApply the Principle: According to the “Make the Common Case Fast” principle, the largest performance gains will come from optimizing the most frequently executed or most time-consuming part of the system.\nEvaluate the Impact: Even a small 10% improvement in getUserProfile() would reduce the total runtime by 8% (10% of 80%). Achieving a similar 8% total reduction by optimizing the other functions would require a much larger and more difficult optimization effort across many different parts of the code.\n\nAnswer: You should focus exclusively on improving the getUserProfile() function.\n\n\n\nExample 4: Finite State Machine\nQuestion: Design a simple FSM for a pedestrian crosswalk button. The system has two states: Red Light (cars can go) and Green Light (pedestrians can cross). The system has two inputs: a button_press event and a timer_expires event. Describe the states and the transitions between them.\n\n\nClick to see the solution\n\n\nDefine States: The problem specifies the two states:\n\nRed Light (Initial State): Traffic light is red for pedestrians.\nGreen Light: Traffic light is green for pedestrians.\n\nDefine Transitions from Red Light:\n\nWhat happens if the button is pressed? The system should transition to the Green Light state to let the pedestrian cross.\nWhat happens if the timer expires? Nothing, the light stays red for pedestrians until the button is pressed.\n\nDefine Transitions from Green Light:\n\nWhat happens if the button is pressed? Nothing, the light is already green.\nWhat happens if the timer expires? The pedestrian’s crossing time is over, so the system must transition back to the Red Light state to let cars go.\n\n\nAnswer: * States: Red Light (initial), Green Light. * Transitions: * From Red Light, on button_press -&gt; transition to Green Light and start a timer. * From Green Light, on timer_expires -&gt; transition to Red Light.",
    "crumbs": [
      "Computer Architecture",
      "2. Fundamental Ideas of Computer Architecture"
    ]
  },
  {
    "objectID": "Mathematical Analysis I/lec_2.html",
    "href": "Mathematical Analysis I/lec_2.html",
    "title": "2. Complex Numbers, Set Theory, Real Numbers, Mathematical Induction",
    "section": "",
    "text": "1. Summary\n\n1.1 Complex Numbers\nA complex number is a number that can be expressed in the form \\(z = x + iy\\), where \\(x\\) and \\(y\\) are real numbers, and \\(i\\) is the imaginary unit, satisfying the equation \\(i^2 = -1\\). The number \\(x\\) is called the real part of \\(z\\), and \\(y\\) is the imaginary part.\nWhile the rectangular form \\(x + iy\\) is useful for addition and subtraction, the trigonometric form (also known as polar form) is often more convenient for multiplication and division.\n\n1.1.1 Trigonometric Form\nAny complex number \\(z\\) can be represented as \\(z = r(\\cos(\\theta) + i \\sin(\\theta))\\). This form is derived from representing the complex number as a point \\((x, y)\\) in the complex plane.\n\nThe modulus (or absolute value) \\(r\\) is the distance from the origin to the point \\((x, y)\\). It is calculated as: \\[ r = |z| = \\sqrt{x^2 + y^2} \\] The modulus is always a non-negative real number.\nThe argument \\(\\theta\\) is the angle formed by the positive real axis and the line segment from the origin to the point \\((x, y)\\). It is typically measured in radians and restricted to the interval \\([0, 2\\pi)\\). The argument is found using the relationships: \\[ \\cos(\\theta) = \\frac{x}{r}, \\quad \\sin(\\theta) = \\frac{y}{r}, \\quad \\tan(\\theta) = \\frac{y}{x} \\] When using arctan(y/x) to find \\(\\theta\\), care must be taken to place the angle in the correct quadrant based on the signs of \\(x\\) and \\(y\\).\n\nQuadrant I (\\(x &gt; 0, y \\ge 0\\)): \\(\\theta = \\arctan(y/x)\\)\nQuadrant II (\\(x &lt; 0, y &gt; 0\\)): \\(\\theta = \\arctan(y/x) + \\pi\\)\nQuadrant III (\\(x &lt; 0, y &lt; 0\\)): \\(\\theta = \\arctan(y/x) + \\pi\\)\nQuadrant IV (\\(x &gt; 0, y &lt; 0\\)): \\(\\theta = \\arctan(y/x) + 2\\pi\\)\n\n\n\n\n\n1.2 De Moivre’s Theorem\nDe Moivre’s Theorem provides a powerful formula for calculating powers of complex numbers in trigonometric form. It states that for any integer \\(n\\): \\[ (\\cos(\\theta) + i \\sin(\\theta))^n = \\cos(n\\theta) + i \\sin(n\\theta) \\]\nThis theorem is fundamental for two main applications:\n\nPowers of Complex Numbers: To compute \\(z^n\\), first convert \\(z\\) to its trigonometric form \\(r(\\cos(\\theta) + i \\sin(\\theta))\\). Then, \\(z^n = r^n(\\cos(n\\theta) + i \\sin(n\\theta))\\).\nRoots of Complex Numbers: The theorem can be extended to find the \\(n\\)-th roots of a complex number. A non-zero complex number \\(z\\) has exactly \\(n\\) distinct \\(n\\)-th roots, given by the formula: \\[ \\sqrt[n]{z} = \\sqrt[n]{r} \\left( \\cos\\left(\\frac{\\theta + 2k\\pi}{n}\\right) + i \\sin\\left(\\frac{\\theta + 2k\\pi}{n}\\right) \\right) \\] for \\(k = 0, 1, 2, ..., n-1\\).\n\n\n\n1.3 Geometric Representation of Complex Numbers\nComplex numbers can be visualized as points or vectors in a two-dimensional Cartesian plane called the complex plane. The horizontal axis represents the real part, and the vertical axis represents the imaginary part.\nThe modulus \\(|z|\\) represents the length of the vector from the origin to the point \\(z\\). More generally, the expression \\(|z - a|\\) represents the distance between the points \\(z\\) and \\(a\\) in the complex plane. This interpretation allows us to describe geometric shapes:\n\nCircle: The equation \\(|z - a| = r\\) describes a circle with center \\(a\\) and radius \\(r\\).\nDisk: The inequality \\(|z - a| \\le r\\) describes a closed disk (the circle and its interior).\nAnnulus: The inequality \\(r_1 &lt; |z - a| \\le r_2\\) describes an annulus (a ring-like region) between two concentric circles.\n\n\n\n1.4 Basic Set Theory\nA set is a collection of distinct objects, called elements or members. Sets are fundamental to modern mathematics.\n\nSubset (\\(\\subset\\)): A set \\(A\\) is a subset of a set \\(B\\) if every element of \\(A\\) is also an element of \\(B\\).\nEmpty Set (\\(\\emptyset\\) or {}): The unique set containing no elements.\nSet Operations:\n\nUnion (\\(\\cup\\)): The set of all elements that are in \\(A\\), or in \\(B\\), or in both.\nIntersection (\\(\\cap\\)): The set of all elements that are in both \\(A\\) and \\(B\\).\nDifference (\\(\\setminus\\)): \\(A \\setminus B\\) is the set of all elements that are in \\(A\\) but not in \\(B\\).\nComplement (\\(A^c\\)): The set of all elements in the universal set \\(U\\) that are not in \\(A\\).\n\n\n\nDe Morgan’s Laws: These laws relate the operations of union, intersection, and complement:\n\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)\n\n\n\n\n1.5 Real Numbers and Their Properties\nThe set of real numbers (\\(\\mathbb{R}\\)) encompasses rational and irrational numbers. Subsets include:\n\nNatural Numbers (\\(\\mathbb{N}\\)): \\(\\{1, 2, 3, ...\\}\\)\nIntegers (\\(\\mathbb{Z}\\)): \\(\\{..., -2, -1, 0, 1, 2, ...\\}\\)\nRational Numbers (\\(\\mathbb{Q}\\)): Numbers that can be expressed as a fraction \\(p/q\\), where \\(p\\) and \\(q\\) are integers and \\(q \\neq 0\\).\n\n\n1.5.1 Bounds and Completeness\n\nAn upper bound of a set \\(S\\) is a number greater than or equal to every element in \\(S\\). A set that has an upper bound is bounded above.\nThe supremum (sup(S)) is the least upper bound. It is the smallest of all upper bounds.\nA lower bound of a set \\(S\\) is a number less than or equal to every element in \\(S\\). A set that has a lower bound is bounded below.\nThe infimum (inf(S)) is the greatest lower bound. It is the largest of all lower bounds.\n\nThe Completeness Axiom is a defining property of real numbers. It states that every non-empty set of real numbers that is bounded above has a supremum that is also a real number. This axiom ensures that there are no “gaps” in the real number line.\n\n\n1.5.2 Archimedean Property and Density\n\nArchimedean Property: For any real number \\(x\\), there exists a natural number \\(n\\) such that \\(n &gt; x\\). This implies there are no infinitely large or infinitely small real numbers.\nDensity of Rationals: Between any two distinct real numbers, there exists at least one rational number. This means the rational numbers are “densely” spread throughout the real number line. Similarly, the irrational numbers are also dense in the reals.\n\n\n\n\n1.6 Mathematical Induction\nThe Principle of Mathematical Induction is a formal method for proving that a statement \\(P(n)\\) is true for all natural numbers \\(n\\) (or all \\(n\\) from a certain starting point). It works like a chain reaction or a line of falling dominoes.\nThe proof requires two steps: 1. Base Case: Prove that the statement \\(P(n)\\) is true for the first value, typically \\(n = 1\\). This is like tipping the first domino. 2. Inductive Step: Assume that \\(P(k)\\) is true for some arbitrary natural number \\(k\\) (this is the inductive hypothesis). Then, using this assumption, prove that \\(P(k+1)\\) must also be true. This shows that if any domino falls, it will knock over the next one.\nIf both steps are successfully proven, the principle of mathematical induction guarantees the statement is true for all natural numbers \\(n\\).\n\n\n\n2. Definitions\n\nComplex Number: A number of the form \\(x + iy\\), where \\(x\\) and \\(y\\) are real numbers and \\(i^2 = -1\\).\nModulus: The non-negative distance \\(r\\) of a complex number from the origin in the complex plane, calculated as \\(r = \\sqrt{x^2 + y^2}\\).\nArgument: The angle \\(\\theta\\) a complex number’s vector makes with the positive real axis, measured counter-clockwise.\nSet: A well-defined collection of distinct objects, known as elements.\nSubset: A set \\(A\\) is a subset of \\(B\\) if all elements of \\(A\\) are also elements of \\(B\\).\nUnion: The union of sets \\(A\\) and \\(B\\) is a set containing all elements that are in \\(A\\), or in \\(B\\), or in both.\nIntersection: The intersection of sets \\(A\\) and \\(B\\) is a set containing all elements that are common to both \\(A\\) and \\(B\\).\nSupremum (sup): The least upper bound of a set; the smallest value that is greater than or equal to all elements in the set.\nInfimum (inf): The greatest lower bound of a set; the largest value that is less than or equal to all elements in the set.\nCountable Set: A set whose elements can be put into a one-to-one correspondence with the set of natural numbers.\nUncountable Set: An infinite set that is not countable.\n\n\n\n3. Formulas\n\nTrigonometric Form of a Complex Number: \\(z = r(\\cos(\\theta) + i \\sin(\\theta))\\)\nModulus of a Complex Number: \\(r = |z| = \\sqrt{x^2 + y^2}\\)\nArgument \\(\\theta\\) from Rectangular Coordinates:\n\nQuadrant I: \\(\\theta = \\arctan(y/x)\\)\nQuadrants II & III: \\(\\theta = \\arctan(y/x) + \\pi\\)\nQuadrant IV: \\(\\theta = \\arctan(y/x) + 2\\pi\\)\n\nDe Moivre’s Theorem (Powers): \\(z^n = r^n(\\cos(n\\theta) + i \\sin(n\\theta))\\)\nDe Moivre’s Theorem (Roots): \\(\\sqrt[n]{z} = \\sqrt[n]{r} \\left( \\cos\\left(\\frac{\\theta + 2k\\pi}{n}\\right) + i \\sin\\left(\\frac{\\theta + 2k\\pi}{n}\\right) \\right)\\) for \\(k = 0, 1, ..., n-1\\).\nDe Morgan’s Laws:\n\n\\((A \\cup B)^c = A^c \\cap B^c\\)\n\\((A \\cap B)^c = A^c \\cup B^c\\)\n\n\n\n\n4. Mistakes\n\nIncorrectly calculating the argument \\(\\theta\\): Using arctan(y/x) without checking the quadrant of the complex number. Why it’s wrong: The arctan function has a restricted range of \\((-\\pi/2, \\pi/2)\\), which only covers quadrants I and IV. For numbers in quadrants II and III, \\(\\pi\\) must be added to the result to get the correct angle.\nConfusing Supremum with Maximum: Believing that the least upper bound (supremum) of a set must be an element of the set. Why it’s wrong: The maximum must belong to the set, but the supremum does not have to. For example, the open interval \\((0, 1)\\) is bounded above by \\(1\\), and \\(1\\) is its supremum, but the set does not contain \\(1\\), so it has no maximum.\nAssuming \\(A \\setminus B = B \\setminus A\\): Thinking that set difference is a commutative operation. Why it’s wrong: \\(A \\setminus B\\) contains elements in \\(A\\) but not in \\(B\\), while \\(B \\setminus A\\) contains elements in \\(B\\) but not in \\(A\\). These are two different sets unless \\(A=B\\).\nFlawed Inductive Step: In a proof by induction, showing that \\(P(k+1)\\) is true without correctly using the inductive hypothesis \\(P(k)\\). Why it’s wrong: The core logic of induction is proving the implication \\(P(k) \\implies P(k+1)\\). If the assumption \\(P(k)\\) isn’t used to prove \\(P(k+1)\\), the logical chain is broken, and the proof is invalid.\nForgetting to check the base case: Starting an inductive proof directly with the inductive step. Why it’s wrong: The inductive step only proves that if a domino falls, the next one will fall. The base case is what proves the first domino falls, starting the entire chain reaction. Without it, the proof is incomplete.\nTreating \\(\\infty\\) as a real number: Performing arithmetic operations like \\(\\infty - \\infty\\) or \\(\\infty / \\infty\\). Why it’s wrong: Infinity is not part of the real number system (\\(\\mathbb{R}\\)). It is a concept used to describe limits and the size of unbounded sets. Expressions like \\(\\infty - \\infty\\) are indeterminate forms, not defined operations.\n\n\n\n5. Examples\n\nExample 1: Rectangular to Trigonometric Form (Quadrant II)\nQuestion: Convert the complex number \\(z = -1 + \\sqrt{3}i\\) to its trigonometric form.\n\n\nClick to see the solution\n\n\nFind the modulus \\(r\\): The real part is \\(x = -1\\) and the imaginary part is \\(y = \\sqrt{3}\\). \\[ r = \\sqrt{(-1)^2 + (\\sqrt{3})^2} = \\sqrt{1 + 3} = \\sqrt{4} = 2 \\]\nFind the argument \\(\\theta\\): The point \\((-1, \\sqrt{3})\\) is in Quadrant II. \\[ \\tan(\\theta) = \\frac{y}{x} = \\frac{\\sqrt{3}}{-1} = -\\sqrt{3} \\] The reference angle is \\(\\arctan(\\sqrt{3}) = \\pi/3\\). Since we are in Quadrant II, the correct angle is \\(\\theta = \\pi - \\pi/3 = 2\\pi/3\\). Alternatively, using the formula: \\(\\theta = \\arctan(-\\sqrt{3}) + \\pi = -\\pi/3 + \\pi = 2\\pi/3\\).\nWrite the final form: Substitute \\(r\\) and \\(\\theta\\) into \\(r(\\cos(\\theta) + i \\sin(\\theta))\\).\n\nAnswer: The trigonometric form is \\(2(\\cos(2\\pi/3) + i \\sin(2\\pi/3))\\).\n\n\n\nExample 2: De Moivre’s Theorem for Powers\nQuestion: Calculate \\((1 + i)^8\\).\n\n\nClick to see the solution\n\n\nConvert \\(1 + i\\) to trigonometric form:\n\n\\(r = \\sqrt{1^2 + 1^2} = \\sqrt{2}\\).\n\\(\\theta = \\arctan(1/1) = \\pi/4\\) (Quadrant I).\nSo, \\(1 + i = \\sqrt{2}(\\cos(\\pi/4) + i \\sin(\\pi/4))\\).\n\nApply De Moivre’s Theorem: Let \\(n = 8\\). \\[ (\\sqrt{2})^8 \\left( \\cos\\left(8 \\cdot \\frac{\\pi}{4}\\right) + i \\sin\\left(8 \\cdot \\frac{\\pi}{4}\\right) \\right) \\]\nSimplify the expression:\n\n\\((\\sqrt{2})^8 = 2^4 = 16\\).\n\\(\\cos(2\\pi) = 1\\).\n\\(\\sin(2\\pi) = 0\\).\nThe result is \\(16(1 + i \\cdot 0) = 16\\).\n\n\nAnswer: \\((1 + i)^8 = \\textbf{16}\\).\n\n\n\nExample 3: Finding Complex Roots\nQuestion: Find the three cube roots of \\(z = -8\\).\n\n\nClick to see the solution\n\n\nConvert \\(z = -8\\) to trigonometric form:\n\n\\(x = -8\\), \\(y = 0\\).\n\\(r = \\sqrt{(-8)^2 + 0^2} = 8\\).\nThe point \\((-8, 0)\\) is on the negative real axis, so \\(\\theta = \\pi\\).\n\\(z = 8(\\cos(\\pi) + i \\sin(\\pi))\\).\n\nApply the n-th root formula with \\(n=3\\), \\(r=8\\), \\(\\theta=\\pi\\). The formula is \\(\\sqrt[3]{8} \\left( \\cos\\left(\\frac{\\pi + 2k\\pi}{3}\\right) + i \\sin\\left(\\frac{\\pi + 2k\\pi}{3}\\right) \\right)\\).\nCalculate the roots for \\(k=0, 1, 2\\):\n\nFor \\(k=0\\): \\(2(\\cos(\\pi/3) + i \\sin(\\pi/3)) = 2(1/2 + i\\sqrt{3}/2) = 1 + \\sqrt{3}i\\).\nFor \\(k=1\\): \\(2(\\cos((\\pi+2\\pi)/3) + i \\sin((\\pi+2\\pi)/3)) = 2(\\cos(\\pi) + i \\sin(\\pi)) = 2(-1 + 0i) = -2\\).\nFor \\(k=2\\): \\(2(\\cos((\\pi+4\\pi)/3) + i \\sin((\\pi+4\\pi)/3)) = 2(\\cos(5\\pi/3) + i \\sin(5\\pi/3)) = 2(1/2 - i\\sqrt{3}/2) = 1 - \\sqrt{3}i\\).\n\n\nAnswer: The three cube roots are \\(1 + \\sqrt{3}i\\), \\(-2\\), and \\(1 - \\sqrt{3}i\\).\n\n\n\nExample 4: Geometric Sets\nQuestion: Describe the set of points \\(z\\) in the complex plane that satisfies the condition \\(|z - 2i| = 4\\).\n\n\nClick to see the solution\n\n\nInterpret the formula: The expression \\(|z - a| = r\\) represents the set of all points \\(z\\) whose distance from a fixed point \\(a\\) is equal to \\(r\\).\nIdentify the center \\(a\\) and radius \\(r\\):\n\nIn our case, \\(a = 2i\\), which corresponds to the point \\((0, 2)\\).\nThe radius is \\(r = 4\\).\n\nState the geometric shape: This is the definition of a circle.\n\nAnswer: The set is a circle with center at \\((0, 2)\\) (or \\(2i\\)) and a radius of 4.\n\n\n\nExample 5: Set Operations\nQuestion: Let \\(A = \\{1, 2, 3, 4\\}\\) and \\(B = \\{3, 4, 5, 6\\}\\). Find \\(A \\cup B\\), \\(A \\cap B\\), and \\(A \\setminus B\\).\n\n\nClick to see the solution\n\n\nFind the Union (\\(A \\cup B\\)): Combine all unique elements from both sets. \\(\\{1, 2, 3, 4, 5, 6\\}\\).\nFind the Intersection (\\(A \\cap B\\)): Identify the elements that are present in both sets. \\(\\{3, 4\\}\\).\nFind the Difference (\\(A \\setminus B\\)): Start with set A and remove any elements that are also in set B. \\(\\{1, 2\\}\\).\n\nAnswer: * \\(A \\cup B = \\textbf{\\{1, 2, 3, 4, 5, 6\\}}\\) * \\(A \\cap B = \\textbf{\\{3, 4\\}}\\) * \\(A \\setminus B = \\textbf{\\{1, 2\\}}\\)\n\n\n\nExample 6: Supremum and Infimum\nQuestion: Find the infimum and supremum of the set \\(S = \\{1/n \\mid n \\in \\mathbb{N}\\} = \\{1, 1/2, 1/3, ...\\}\\).\n\n\nClick to see the solution\n\n\nAnalyze the set’s elements: The sequence starts at 1 and decreases, getting closer and closer to 0 as \\(n\\) gets larger.\nFind the supremum (least upper bound): The largest element in the set is \\(1\\) (when \\(n=1\\)). All other elements are smaller. Therefore, \\(1\\) is an upper bound. Since \\(1\\) is in the set, it must be the least upper bound.\nFind the infimum (greatest lower bound): All elements are positive, so \\(0\\) is a lower bound. For any number \\(\\epsilon &gt; 0\\), we can find a natural number \\(n\\) such that \\(1/n &lt; \\epsilon\\) (by the Archimedean property). This means no positive number can be a lower bound. Therefore, \\(0\\) must be the greatest lower bound.\n\nAnswer: sup(S) = 1 and inf(S) = 0.\n\n\n\nExample 7: Proof by Induction (Summation)\nQuestion: Prove that for all \\(n \\in \\mathbb{N}\\), the sum \\(1 + 2 + ... + n = \\frac{n(n+1)}{2}\\).\n\n\nClick to see the solution\n\n\nBase Case (\\(n=1\\)):\n\nLeft-hand side (LHS): \\(1\\).\nRight-hand side (RHS): \\(\\frac{1(1+1)}{2} = \\frac{2}{2} = 1\\).\nLHS = RHS, so the base case holds.\n\nInductive Step:\n\nInductive Hypothesis: Assume the formula is true for \\(n=k\\): \\(1 + 2 + ... + k = \\frac{k(k+1)}{2}\\).\nGoal: Prove the formula is true for \\(n=k+1\\): \\(1 + 2 + ... + k + (k+1) = \\frac{(k+1)(k+2)}{2}\\).\nProof: Start with the LHS of the goal and use the hypothesis: \\((1 + 2 + ... + k) + (k+1)\\) \\(= \\left[\\frac{k(k+1)}{2}\\right] + (k+1)\\) (substituting the hypothesis) \\(= \\frac{k(k+1) + 2(k+1)}{2}\\) (finding a common denominator) \\(= \\frac{(k+1)(k+2)}{2}\\) (factoring out \\(k+1\\))\nThis matches the RHS of our goal. The inductive step is complete.\n\nConclusion: By the principle of mathematical induction, the formula is true for all \\(n \\in \\mathbb{N}\\).\n\nAnswer: The proof is complete as shown.\n\n\n\nExample 8: Proof by Induction (Inequality)\nQuestion: Prove Bernoulli’s inequality: \\((1 + x)^n \\ge 1 + nx\\) for all \\(n \\in \\mathbb{N}\\) and \\(x \\ge -1\\).\n\n\nClick to see the solution\n\n\nBase Case (\\(n=1\\)):\n\nLHS: \\((1+x)^1 = 1+x\\).\nRHS: \\(1 + 1x = 1+x\\).\nLHS = RHS, so the inequality holds (with equality).\n\nInductive Step:\n\nInductive Hypothesis: Assume true for \\(n=k\\): \\((1+x)^k \\ge 1+kx\\).\nGoal: Prove true for \\(n=k+1\\): \\((1+x)^{k+1} \\ge 1+(k+1)x\\).\nProof: Start with the LHS of the goal: \\((1+x)^{k+1} = (1+x)^k (1+x)\\) Since \\((1+x) \\ge 0\\) (because \\(x \\ge -1\\)), we can multiply both sides of the hypothesis by \\((1+x)\\) without changing the inequality direction: \\((1+x)^k (1+x) \\ge (1+kx)(1+x)\\) \\((1+x)^{k+1} \\ge 1 + x + kx + kx^2\\) \\((1+x)^{k+1} \\ge 1 + (k+1)x + kx^2\\) Since \\(k &gt; 0\\) and \\(x^2 \\ge 0\\), the term \\(kx^2\\) is non-negative. Therefore: \\(1 + (k+1)x + kx^2 \\ge 1 + (k+1)x\\) By transitivity, we have \\((1+x)^{k+1} \\ge 1+(k+1)x\\).\n\nConclusion: By the principle of mathematical induction, the inequality is true for all \\(n \\in \\mathbb{N}\\).\n\nAnswer: The proof is complete as shown.\n\n\n\nExample 9: Proof by Induction (Divisibility)\nQuestion: Prove that \\(7^n - 1\\) is divisible by 6 for all \\(n \\in \\mathbb{N}\\).\n\n\nClick to see the solution\n\n\nBase Case (\\(n=1\\)):\n\n\\(7^1 - 1 = 6\\).\n\\(6\\) is divisible by 6. The base case holds.\n\nInductive Step:\n\nInductive Hypothesis: Assume \\(7^k - 1\\) is divisible by 6. This means \\(7^k - 1 = 6m\\) for some integer \\(m\\). So, \\(7^k = 6m + 1\\).\nGoal: Prove \\(7^{k+1} - 1\\) is divisible by 6.\nProof: Manipulate the expression for \\(n=k+1\\): \\(7^{k+1} - 1 = 7 \\cdot 7^k - 1\\) Substitute the hypothesis \\(7^k = 6m + 1\\): \\(= 7(6m + 1) - 1\\) \\(= 42m + 7 - 1\\) \\(= 42m + 6\\) \\(= 6(7m + 1)\\)\nSince \\(m\\) is an integer, \\(7m+1\\) is also an integer. Thus, \\(7^{k+1} - 1\\) is a multiple of 6.\n\nConclusion: By the principle of mathematical induction, \\(7^n - 1\\) is divisible by 6 for all \\(n \\in \\mathbb{N}\\).\n\nAnswer: The proof is complete as shown.\n\n\n\nExample 10: Density of Rationals\nQuestion: Find a rational number between \\(\\pi\\) (approx 3.14159) and \\(\\pi + 0.001\\) (approx 3.14259).\n\n\nClick to see the solution\n\n\nIdentify the interval: We are looking for a rational number \\(r\\) such that \\(3.14159 &lt; r &lt; 3.14259\\).\nChoose a denominator: We need a denominator large enough to create fractions within this small interval. A denominator of 10000 would be suitable.\nFind a suitable numerator:\n\n\\(3.14159\\) is \\(31415.9 / 10000\\).\n\\(3.14259\\) is \\(31425.9 / 10000\\).\n\nSelect an integer numerator between \\(31415.9\\) and \\(31425.9\\). A simple choice is \\(31416\\).\nConstruct the rational number: The number is \\(31416 / 10000\\), which is \\(3.1416\\).\nVerify: \\(3.14159 &lt; 3.1416 &lt; 3.14259\\). The condition is met.\n\nAnswer: One possible rational number is \\(3.1416\\) or \\(31416/10000\\).",
    "crumbs": [
      "Mathematical Analysis I",
      "2. Complex Numbers, Set Theory, Real Numbers, Mathematical Induction"
    ]
  }
]