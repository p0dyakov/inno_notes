---
title: "Vectors, Vector Spaces, Linear Independence, Basis, and Dimension"
author: "Zakhar Podyakov"
date: "September 17, 2025"
format: html
engine: knitr
---

#### **1. Summary**

##### **1.1 Introduction to Vectors**
A **vector** is a fundamental mathematical object that possesses both *magnitude* (or length) and *direction*. It's distinct from a **scalar**, which is a simple numerical value (like temperature or speed) that has magnitude but no direction.

Vectors can be represented in two primary ways:
*   **Geometrically**: As a directed line segment, or an arrow, in space. The arrow's length represents the magnitude, and the direction it points represents its direction. A key property is that a vector is independent of its starting position; two arrows with the same length and direction represent the same vector, regardless of where they are in space.
*   **Algebraically**: As an ordered list of numbers, called components. For instance, in a 2D plane, a vector is represented by two components $(x, y)$, and in 3D space, by three components $(x, y, z)$. These components correspond to the vector's projection onto the coordinate axes. By convention, vectors are often written as columns:
    $$ \vec{v} = \begin{pmatrix} x \\ y \end{pmatrix} $$

<!-- DIAGRAM HERE -->

##### **1.2 Basic Vector Operations**
Standard arithmetic operations are defined for vectors, allowing them to be manipulated algebraically.

*   **1.2.1 Vector Addition**: To add two vectors, you add their corresponding components. Geometrically, this is represented by the "tip-to-tail" method: place the tail of the second vector at the tip of the first. The resulting vector (the sum) goes from the tail of the first vector to the tip of the second.
    $$ \vec{u} + \vec{v} = \begin{pmatrix} u_1 \\ u_2 \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \end{pmatrix} $$
    <!-- DIAGRAM HERE -->
*   **1.2.2 Scalar Multiplication**: To multiply a vector by a scalar, you multiply each of its components by that scalar. This operation *scales* the vector, changing its magnitude. If the scalar is positive, the direction remains the same. If negative, the direction is reversed.
    $$ c\vec{v} = c\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} cv_1 \\ cv_2 \end{pmatrix} $$
*   **1.2.3 Vector Subtraction**: Subtraction is defined as adding the negative of a vector. That is, $\vec{u} - \vec{v}$ is the same as $\vec{u} + (-1)\vec{v}$.
    $$ \vec{u} - \vec{v} = \begin{pmatrix} u_1 \\ u_2 \end{pmatrix} - \begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} u_1 - v_1 \\ u_2 - v_2 \end{pmatrix} $$

##### **1.3 Vector Magnitude and Normalization**
*   **1.3.1 Norm of a Vector**: The **norm** (or magnitude/length) of a vector is a non-negative scalar value representing its length. It is calculated using the Pythagorean theorem on its components. The norm of a vector $\vec{v}$ is denoted as $||\vec{v}||$.
    $$ ||\vec{v}|| = \sqrt{v_1^2 + v_2^2 + \dots + v_n^2} $$
*   **1.3.2 Unit Vectors**: A **unit vector** is any vector with a norm of 1. It is useful for representing direction without magnitude. To *normalize* a non-zero vector (i.e., to find the unit vector in its direction), you divide the vector by its own norm.
    $$ \hat{u} = \frac{\vec{v}}{||\vec{v}||} $$
*   **1.3.3 Distance Between Points**: The straight-line distance between two points, say $P$ and $Q$, can be found by first calculating the vector $\vec{PQ}$ that connects them ($\vec{PQ} = Q - P$) and then finding the norm of that vector.
    $$ d(P, Q) = ||\vec{PQ}|| = ||Q - P|| = \sqrt{(q_1-p_1)^2 + (q_2-p_2)^2 + \dots} $$

##### **1.4 Vector Spaces and Subspaces**
*   **1.4.1 Vector Space**: A **vector space** is a collection of objects (called vectors) for which the operations of vector addition and scalar multiplication are defined and satisfy a set of ten rules, known as axioms. These axioms ensure that vectors behave consistently and predictably. Key axioms include closure (adding two vectors or multiplying by a scalar results in a vector still within the space), the existence of a zero vector, and the existence of an additive inverse for every vector. The set of all 2D vectors, denoted $\mathbb{R}^2$, is a common example of a vector space.
*   **1.4.2 Subspace**: A **subspace** is a subset of a larger vector space that is itself a vector space. To verify if a subset is a subspace, a simplified test called the **Subspace Test** is used. A subset $H$ is a subspace if it meets three conditions:
    1.  It contains the **zero vector**.
    2.  It is **closed under addition** (if $\vec{u}$ and $\vec{v}$ are in $H$, then $\vec{u} + \vec{v}$ must also be in $H$).
    3.  It is **closed under scalar multiplication** (if $\vec{u}$ is in $H$ and $c$ is any scalar, then $c\vec{u}$ must also be in $H$).
    For example, any line or plane passing through the origin in $\mathbb{R}^3$ is a subspace of $\mathbb{R}^3$.

##### **1.5 Linear Combinations, Span, and Basis**
*   **1.5.1 Linear Combination and Span**: A **linear combination** is a new vector formed by adding together scalar multiples of other vectors. For example, $\vec{w} = c_1\vec{v}_1 + c_2\vec{v}_2$ is a linear combination of $\vec{v}_1$ and $\vec{v}_2$. The **span** of a set of vectors is the set of *all possible* linear combinations that can be formed from them. The span of a set of vectors always forms a vector space (or a subspace).
    <!-- DIAGRAM HERE -->
*   **1.5.2 Linear Independence**: A set of vectors is **linearly independent** if no vector in the set can be written as a linear combination of the others. This means that none of the vectors are redundant; each one contributes a unique direction. The only way to form the zero vector from a linear combination of linearly independent vectors is if all the scalar coefficients are zero.
*   **1.5.3 Linear Dependence**: A set of vectors is **linearly dependent** if at least one vector can be expressed as a linear combination of the others. This indicates redundancy in the set.
*   **1.5.4 Basis and Dimension**: A **basis** of a vector space is a set of vectors that is both *linearly independent* and *spans the entire space*. A basis provides a minimal set of "building blocks" for the space. While a vector space can have many different bases, the number of vectors in every basis for that space is always the same. This unique number is called the **dimension** of the vector space. For example, the dimension of $\mathbb{R}^3$ is 3, because a standard basis for it is the set of three vectors: $\{(1,0,0), (0,1,0), (0,0,1)\}$.

#### **2. Definitions**

*   **Vector**: A mathematical object that has both magnitude (length) and direction.
*   **Scalar**: A quantity that is fully described by a magnitude alone (a single number).
*   **Norm**: The length or magnitude of a vector, denoted by $||\vec{v}||$.
*   **Unit Vector**: A vector with a norm of 1, often used to represent direction.
*   **Vector Space**: A collection of vectors and a field of scalars that satisfy a set of ten axioms, defining a consistent system for vector addition and scalar multiplication.
*   **Subspace**: A subset of a vector space that is itself a vector space under the same operations.
*   **Linear Combination**: A sum of vectors, each multiplied by a scalar coefficient.
*   **Span**: The set of all possible linear combinations of a given set of vectors. The span of a set of vectors is always a subspace.
*   **Linearly Independent**: A set of vectors where no vector can be written as a linear combination of the others.
*   **Linearly Dependent**: A set of vectors where at least one vector can be written as a linear combination of the others.
*   **Basis**: A set of vectors that is both linearly independent and spans the vector space. It is a minimal generating set for the space.
*   **Dimension**: The number of vectors in any basis for a vector space.

#### **3. Formulas**

*   **Vector Addition**: $\vec{u} + \vec{v} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \end{pmatrix}$
*   **Scalar Multiplication**: $c\vec{v} = \begin{pmatrix} cv_1 \\ cv_2 \end{pmatrix}$
*   **Vector Subtraction**: $\vec{u} - \vec{v} = \begin{pmatrix} u_1 - v_1 \\ u_2 - v_2 \end{pmatrix}$
*   **Norm of a Vector in $\mathbb{R}^n$**: $||\vec{v}|| = \sqrt{v_1^2 + v_2^2 + \dots + v_n^2}$
*   **Distance between Points P and Q**: $d(P, Q) = ||Q - P||$
*   **Normalization (Unit Vector)**: $\hat{u} = \frac{\vec{v}}{||\vec{v}||}$
*   **Projection of vector $\vec{a}$ onto vector $\vec{b}$**: $\text{proj}_{\vec{b}}\vec{a} = \frac{\vec{a} \cdot \vec{b}}{||\vec{b}||^2} \vec{b}$
*   **Reflection of vector $\vec{a}$ over a line defined by vector $\vec{b}$**: $\text{ref}_{\vec{b}}\vec{a} = 2 \cdot \text{proj}_{\vec{b}}\vec{a} - \vec{a}$

#### **4. Mistakes**

*   **Adding a scalar and a vector:** An operation like $5 + \begin{pmatrix} 2 \\ 3 \end{pmatrix}$ is undefined. **Why it's wrong:** Scalars and vectors are fundamentally different types of mathematical objects and cannot be directly added. You can only perform scalar *multiplication*.
*   **Assuming any set of n vectors in $\mathbb{R}^n$ is a basis:** For example, the set $\{\begin{pmatrix} 1 \\ 1 \end{pmatrix}, \begin{pmatrix} 2 \\ 2 \end{pmatrix}\}$ is not a basis for $\mathbb{R}^2$. **Why it's wrong:** A basis must be linearly independent. In this case, the second vector is just twice the first, so they are linearly dependent and only span a line, not the entire plane.
*   **Confusing a subspace with any subset:** A line in $\mathbb{R}^2$ that does not pass through the origin is a subset, but not a subspace. **Why it's wrong:** A subspace must contain the zero vector and be closed under addition and scalar multiplication. A line not through the origin fails the zero vector test.
*   **Mixing up linear independence and spanning:** A set of vectors can be linearly independent but not span the entire space. For example, $\{\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}\}$ is a linearly independent set in $\mathbb{R}^3$, but it only spans the xy-plane, not all of $\mathbb{R}^3$.
*   **Incorrectly calculating the dot product:** The dot product of two vectors results in a scalar, not another vector. **Why it's wrong:** The definition of the dot product is $\vec{u} \cdot \vec{v} = u_1v_1 + u_2v_2 + \dots$, which is a sum of products, resulting in a single number.
*   **Forgetting to take the square root for the norm:** The norm is the length, which is the square root of the sum of squared components. A common mistake is to forget the square root, which calculates the squared norm $||\vec{v}||^2$.

#### **5. Examples**

##### **5.1. Vector Operations**
**Question:** Given vectors $\vec{a} = \begin{pmatrix} 2 \\ -5 \end{pmatrix}$ and $\vec{b} = \begin{pmatrix} -3 \\ 4 \end{pmatrix}$, calculate $3\vec{a} - 2\vec{b}$.
<details>
<summary>Click to see the solution</summary>

1.  **Calculate the scalar multiple $3\vec{a}$:**
    $$ 3\vec{a} = 3 \begin{pmatrix} 2 \\ -5 \end{pmatrix} = \begin{pmatrix} 3 \cdot 2 \\ 3 \cdot (-5) \end{pmatrix} = \begin{pmatrix} 6 \\ -15 \end{pmatrix} $$
2.  **Calculate the scalar multiple $2\vec{b}$:**
    $$ 2\vec{b} = 2 \begin{pmatrix} -3 \\ 4 \end{pmatrix} = \begin{pmatrix} 2 \cdot (-3) \\ 2 \cdot 4 \end{pmatrix} = \begin{pmatrix} -6 \\ 8 \end{pmatrix} $$
3.  **Subtract the resulting vectors:**
    $$ 3\vec{a} - 2\vec{b} = \begin{pmatrix} 6 \\ -15 \end{pmatrix} - \begin{pmatrix} -6 \\ 8 \end{pmatrix} = \begin{pmatrix} 6 - (-6) \\ -15 - 8 \end{pmatrix} = \begin{pmatrix} 12 \\ -23 \end{pmatrix} $$

**Answer:** The resulting vector is **$\begin{pmatrix} 12 \\ -23 \end{pmatrix}$**.
</details>

##### **5.2. Norm and Distance**
**Question:** Find the distance between point $A = (3, -1, 4)$ and point $B = (-1, 1, 2)$.
<details>
<summary>Click to see the solution</summary>

1.  **Find the vector $\vec{AB}$ connecting the two points:**
    $$ \vec{AB} = B - A = \begin{pmatrix} -1 - 3 \\ 1 - (-1) \\ 2 - 4 \end{pmatrix} = \begin{pmatrix} -4 \\ 2 \\ -2 \end{pmatrix} $$
2.  **Calculate the norm (magnitude) of the vector $\vec{AB}$:**
    $$ ||\vec{AB}|| = \sqrt{(-4)^2 + 2^2 + (-2)^2} $$
3.  **Simplify the expression:**
    $$ ||\vec{AB}|| = \sqrt{16 + 4 + 4} = \sqrt{24} = 2\sqrt{6} $$

**Answer:** The distance is **$2\sqrt{6}$**.
</details>

##### **5.3. Unit Vector**
**Question:** Find the unit vector in the same direction as $\vec{v} = \begin{pmatrix} 1 \\ -2 \\ 3 \end{pmatrix}$.
<details>
<summary>Click to see the solution</summary>

1.  **First, calculate the norm of $\vec{v}$:**
    $$ ||\vec{v}|| = \sqrt{1^2 + (-2)^2 + 3^2} = \sqrt{1 + 4 + 9} = \sqrt{14} $$
2.  **Divide the vector $\vec{v}$ by its norm:**
    $$ \hat{v} = \frac{\vec{v}}{||\vec{v}||} = \frac{1}{\sqrt{14}} \begin{pmatrix} 1 \\ -2 \\ 3 \end{pmatrix} = \begin{pmatrix} 1/\sqrt{14} \\ -2/\sqrt{14} \\ 3/\sqrt{14} \end{pmatrix} $$

**Answer:** The unit vector is **$\begin{pmatrix} 1/\sqrt{14} \\ -2/\sqrt{14} \\ 3/\sqrt{14} \end{pmatrix}$**.
</details>

##### **5.4. Linear Independence**
**Question:** Determine if the vectors $\vec{u} = \begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix}$, $\vec{v} = \begin{pmatrix} 3 \\ 1 \\ 4 \end{pmatrix}$, and $\vec{w} = \begin{pmatrix} 5 \\ 5 \\ 6 \end{pmatrix}$ are linearly independent.
<details>
<summary>Click to see the solution</summary>

1.  **Set up the equation for linear dependence:** We need to check if there are non-zero scalars $a, b, c$ such that $a\vec{u} + b\vec{v} + c\vec{w} = \vec{0}$.
    $$ a\begin{pmatrix} 1 \\ 2 \\ 1 \end{pmatrix} + b\begin{pmatrix} 3 \\ 1 \\ 4 \end{pmatrix} + c\begin{pmatrix} 5 \\ 5 \\ 6 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} $$
2.  **Write this as a system of linear equations:**
    $$ \begin{cases} 1a + 3b + 5c = 0 \\ 2a + 1b + 5c = 0 \\ 1a + 4b + 6c = 0 \end{cases} $$
3.  **Solve the system.** We can use substitution or elimination. Subtracting the first equation from the second gives $a - 2b = 0$, so $a = 2b$. Subtracting the first equation from the third gives $b + c = 0$, so $c = -b$.
4.  **Substitute back into the first equation:**
    $$ (2b) + 3b + 5(-b) = 0 $$
    $$ 5b - 5b = 0 $$
    $$ 0 = 0 $$
    This identity means there are infinitely many solutions. For example, if we choose $b=1$, then $a=2$ and $c=-1$.
5.  **Conclusion:** Since we found a non-trivial solution ($a=2, b=1, c=-1$), the vectors are not linearly independent. Specifically, $2\vec{u} + \vec{v} - \vec{w} = \vec{0}$.

**Answer:** The vectors are **linearly dependent**.
</details>

##### **5.5. Subspace Test**
**Question:** Is the set $S$ of all vectors in $\mathbb{R}^2$ of the form $\begin{pmatrix} t \\ 2t \end{pmatrix}$ a subspace of $\mathbb{R}^2$?
<details>
<summary>Click to see the solution</summary>

1.  **Check for the zero vector:** Let $t=0$. The vector is $\begin{pmatrix} 0 \\ 0 \end{pmatrix}$. The zero vector is in $S$. Condition (1) is met.
2.  **Check for closure under addition:** Let $\vec{u} = \begin{pmatrix} t_1 \\ 2t_1 \end{pmatrix}$ and $\vec{v} = \begin{pmatrix} t_2 \\ 2t_2 \end{pmatrix}$ be two arbitrary vectors in $S$. Their sum is:
    $$ \vec{u} + \vec{v} = \begin{pmatrix} t_1 + t_2 \\ 2t_1 + 2t_2 \end{pmatrix} = \begin{pmatrix} (t_1 + t_2) \\ 2(t_1 + t_2) \end{pmatrix} $$
    This resulting vector is of the form $\begin{pmatrix} t' \\ 2t' \end{pmatrix}$ where $t' = t_1 + t_2$. So, the set is closed under addition. Condition (2) is met.
3.  **Check for closure under scalar multiplication:** Let $\vec{u} = \begin{pmatrix} t \\ 2t \end{pmatrix}$ be a vector in $S$ and $c$ be any scalar.
    $$ c\vec{u} = c\begin{pmatrix} t \\ 2t \end{pmatrix} = \begin{pmatrix} ct \\ c(2t) \end{pmatrix} = \begin{pmatrix} (ct) \\ 2(ct) \end{pmatrix} $$
    This resulting vector is of the form $\begin{pmatrix} t'' \\ 2t'' \end{pmatrix}$ where $t''=ct$. So, the set is closed under scalar multiplication. Condition (3) is met.

**Answer:** Yes, the set **is a subspace** because it satisfies all three conditions of the Subspace Test. This corresponds to a line through the origin.
</details>

##### **5.6. Vector Projection**
**Question:** Given $\vec{a} = (2, 2, -1)$ and $\vec{b} = (0, 4, 3)$, compute the projection of $\vec{a}$ onto $\vec{b}$.
<details>
<summary>Click to see the solution</summary>

1.  **Calculate the dot product $\vec{a} \cdot \vec{b}$:**
    $$ \vec{a} \cdot \vec{b} = (2)(0) + (2)(4) + (-1)(3) = 0 + 8 - 3 = 5 $$
2.  **Calculate the squared norm of $\vec{b}$:**
    $$ ||\vec{b}||^2 = 0^2 + 4^2 + 3^2 = 0 + 16 + 9 = 25 $$
3.  **Apply the projection formula:**
    $$ \text{proj}_{\vec{b}}\vec{a} = \frac{\vec{a} \cdot \vec{b}}{||\vec{b}||^2} \vec{b} = \frac{5}{25} \begin{pmatrix} 0 \\ 4 \\ 3 \end{pmatrix} $$
4.  **Simplify the result:**
    $$ \text{proj}_{\vec{b}}\vec{a} = \frac{1}{5} \begin{pmatrix} 0 \\ 4 \\ 3 \end{pmatrix} = \begin{pmatrix} 0 \\ 4/5 \\ 3/5 \end{pmatrix} $$

**Answer:** The projection of $\vec{a}$ onto $\vec{b}$ is **$\begin{pmatrix} 0 \\ 4/5 \\ 3/5 \end{pmatrix}$**.
</details>

##### **5.7. Vector Reflection**
**Question:** Using the vectors from the previous example, compute the reflection of $\vec{a} = (2, 2, -1)$ over the line defined by vector $\vec{b} = (0, 4, 3)$.
<details>
<summary>Click to see the solution</summary>

1.  **Recall the projection vector from the previous example:**
    $$ \text{proj}_{\vec{b}}\vec{a} = \begin{pmatrix} 0 \\ 4/5 \\ 3/5 \end{pmatrix} $$
2.  **Apply the reflection formula: $\text{ref}_{\vec{b}}\vec{a} = 2 \cdot \text{proj}_{\vec{b}}\vec{a} - \vec{a}$:**
    $$ \text{ref}_{\vec{b}}\vec{a} = 2 \begin{pmatrix} 0 \\ 4/5 \\ 3/5 \end{pmatrix} - \begin{pmatrix} 2 \\ 2 \\ -1 \end{pmatrix} $$
3.  **Perform the scalar multiplication:**
    $$ = \begin{pmatrix} 0 \\ 8/5 \\ 6/5 \end{pmatrix} - \begin{pmatrix} 2 \\ 2 \\ -1 \end{pmatrix} $$
4.  **Perform the vector subtraction:**
    $$ = \begin{pmatrix} 0 - 2 \\ 8/5 - 10/5 \\ 6/5 - (-5/5) \end{pmatrix} = \begin{pmatrix} -2 \\ -2/5 \\ 11/5 \end{pmatrix} $$

**Answer:** The reflection of $\vec{a}$ over $\vec{b}$ is **$\begin{pmatrix} -2 \\ -2/5 \\ 11/5 \end{pmatrix}$**.
</details>