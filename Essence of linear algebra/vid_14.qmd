---
title: "14. Eigenvectors and Eigenvalues"
author: "Zakhar Podyakov"
date: "September 18, 2025"
format: html
engine: knitr
---

{{< video https://www.youtube.com/watch?v=PFDu9oVAE-g&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=15 >}}

<!-- [QUIZ]() | [FLASHCARDS]() -->

#### **1. Summary**
##### **1.1 The Core Idea**
In linear algebra, a **linear transformation** can be thought of as a function that moves vectors around in space. While most vectors are knocked off their original line, or **span**, some special vectors are not.

-   An **eigenvector** of a transformation is a non-zero vector that, after the transformation is applied, stays on its original span. It doesn't change its direction, though it might flip.
-   The **eigenvalue** is the scalar factor by which the eigenvector is stretched, squished, or flipped. A positive eigenvalue means the vector is stretched or squished. A negative eigenvalue means it's flipped and then stretched or squished.

This concept is analogous to asking "What does music mean to you?" and getting the answer "The manipulation of notes." While technically true, it misses the deeper essence. Similarly, defining mathematics as just "the manipulation of numbers and structures" misses the rich, intuitive meaning. Eigenvectors and eigenvalues provide a deeper understanding of a transformation's behavior.
<!-- DIAGRAM HERE -->

##### **1.2 The Eigenvector Equation**
The relationship between a transformation matrix `A`, its eigenvector $\vec{v}$, and its corresponding eigenvalue $\lambda$ is captured by the fundamental equation:
$$
A\vec{v} = \lambda\vec{v}
$$
This equation states that the action of the matrix `A` on the vector $\vec{v}$ (matrix-vector multiplication) is the same as simply scaling the vector $\vec{v}$ by the scalar $\lambda$ (scalar-vector multiplication). Our goal is to find the pairs of $\lambda$ and non-zero $\vec{v}$ that make this equation true for a given matrix `A`.

##### **1.3 Solving for Eigenvalues and Eigenvectors**
To solve the equation $A\vec{v} = \lambda\vec{v}$, we manipulate it algebraically.

1.  **Rewrite the Right Side:** The right side, $\lambda\vec{v}$, can be expressed as a matrix-vector product. We use the **identity matrix**, `I`, which has ones on the diagonal and zeros elsewhere. The matrix $(\lambda I)$ is a diagonal matrix with $\lambda$ on its diagonal, and multiplying it by $\vec{v}$ has the effect of scaling $\vec{v}$ by $\lambda$.
    $$
    A\vec{v} = (\lambda I)\vec{v}
    $$
2.  **Rearrange the Equation:** Move all terms to one side to set the equation to the zero vector.
    $$
    A\vec{v} - (\lambda I)\vec{v} = \vec{0}
    $$
3.  **Factor out the Vector:**
    $$
    (A - \lambda I)\vec{v} = \vec{0}
    $$
We are looking for a non-zero vector $\vec{v}$ that this new matrix, $(A - \lambda I)$, transforms into the zero vector.

###### **1.3.1 Finding the Eigenvalue ($\lambda$)**
A matrix transforms a non-zero vector into the zero vector only if the transformation squishes space into a lower dimension. This property is indicated by the **determinant** of the matrix being zero.

-   Therefore, to find the eigenvalues, we must find the values of $\lambda$ for which the determinant of the matrix $(A - \lambda I)$ is zero.
    $$
    \det(A - \lambda I) = 0
    $$
-   This equation is called the **characteristic polynomial** of the matrix `A`. Solving it for $\lambda$ yields the eigenvalues.
<!-- DIAGRAM HERE -->

###### **1.3.2 Finding the Eigenvector ($\vec{v}$)**
Once you have an eigenvalue $\lambda$, you substitute it back into the equation $(A - \lambda I)\vec{v} = \vec{0}$ and solve for the vector $\vec{v}$. The set of all solutions for a given $\lambda$ is the **eigenspace** corresponding to that eigenvalue. Any non-zero vector in that eigenspace is an eigenvector.

##### **1.4 Special Cases**
-   **Rotation:** A rotation in 2D, such as a 90-degree rotation, might have no real eigenvectors because every vector is rotated off its span. The characteristic polynomial will have no real roots, only complex ones.
-   **3D Rotation:** Every 3D rotation has an **axis of rotation**. Any vector lying on this axis is an eigenvector with an eigenvalue of 1, as it remains unchanged by the rotation.
-   **Uniform Scaling:** A transformation that scales everything by the same factor (e.g., doubles the length of every vector) has an eigenvalue of 2. In this case, *every* vector is an eigenvector.

##### **1.5 Eigenbasis and Diagonalization**
###### **1.5.1 Eigenbasis**
If a transformation has enough eigenvectors that they can span the entire space, we can pick a set of these eigenvectors to be our **basis vectors**. This new basis is called an **eigenbasis**.

###### **1.5.2 Diagonal Matrices**
When a transformation is described using an eigenbasis, its matrix representation becomes a **diagonal matrix**.

-   A **diagonal matrix** is a matrix where all non-diagonal entries are zero.
-   The diagonal entries are the eigenvalues corresponding to each basis eigenvector.
<!-- DIAGRAM HERE -->

###### **1.5.3 The Power of Diagonalization**
Working with diagonal matrices is computationally much simpler. For instance, raising a diagonal matrix `D` to a power (e.g., $D^{100}$) simply involves raising each diagonal entry to that power.

This simplicity is leveraged through a **change of basis**. If a matrix `A` is not diagonal, but it has an eigenbasis, we can convert it to a diagonal matrix `D`.

-   Let `P` be the change of basis matrix whose columns are the eigenvectors of `A`.
-   The diagonal matrix `D` is found using the formula: $D = P^{-1}AP$.
-   This allows for the efficient computation of powers of `A`: $A^n = P D^n P^{-1}$. This process is known as **diagonalization**.

#### **2. Definitions**
* **Eigenvector**: A non-zero vector that changes only by a scalar factor when a linear transformation is applied to it. Its direction remains unchanged on its span.
* **Eigenvalue**: The scalar factor by which an eigenvector is scaled during a linear transformation. Denoted by $\lambda$.
* **Eigenspace**: The set of all eigenvectors that share the same eigenvalue, along with the zero vector.
* **Span**: The set of all possible vectors that can be reached by stretching, squishing, or combining a given set of vectors. The span of a single vector is the line passing through it and the origin.
* **Characteristic Polynomial**: The polynomial, $\det(A - \lambda I)$, whose roots are the eigenvalues of the matrix `A`.
* **Eigenbasis**: A basis of a vector space consisting entirely of eigenvectors of a given linear transformation.
* **Diagonal Matrix**: A matrix where all entries off the main diagonal are zero.

#### **3. Formulas**
* **Eigenvector Definition**: $A\vec{v} = \lambda\vec{v}$
* **Equation for Solving**: $(A - \lambda I)\vec{v} = \vec{0}$
* **Characteristic Equation (for finding eigenvalues)**: $\det(A - \lambda I) = 0$
* **Diagonalization**: $D = P^{-1}AP$, where `P` is the change-of-basis matrix composed of eigenvectors.
* **Matrix Powers with Diagonalization**: $A^n = PD^nP^{-1}$

#### **4. Mistakes**
* **Assuming all matrices have real eigenvectors:** A rotation, for instance, might not have any vectors that remain on their original span. This results in a characteristic polynomial with no real solutions for $\lambda$.
* **Confusing matrix multiplication with scalar multiplication:** The equation $A\vec{v} = \lambda\vec{v}$ equates two different types of operations which is why the identity matrix `I` is introduced to create the solvable form $(A - \lambda I)\vec{v} = \vec{0}$.
* **Forgetting that eigenvectors must be non-zero:** The zero vector always satisfies the equation $(A - \lambda I)\vec{v} = \vec{0}$, but it is explicitly excluded from the definition of an eigenvector.
* **Incorrectly calculating the characteristic polynomial:** A common mistake is to compute $\det(A) - \lambda$ instead of the correct $\det(A - \lambda I)$. One must subtract $\lambda$ from the diagonal elements of `A` *before* computing the determinant.
* **Assuming all matrices are diagonalizable:** For a matrix to be diagonalizable, it must have a full set of eigenvectors that can form a basis for the space. A shear transformation is an example of a matrix that is not diagonalizable because it doesn't have enough eigenvectors to span the space.

#### **5. Examples**
##### **5.1 Find Eigenvalues**
**Question:** Find the eigenvalues of the matrix $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$.
<details>
<summary>Click to see the solution</summary>

1.  **Set up the characteristic equation** $\det(A - \lambda I) = 0$.
    $$
    A - \lambda I = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix} - \lambda \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 3-\lambda & 1 \\ 0 & 2-\lambda \end{pmatrix}
    $$
2.  **Calculate the determinant**.
    $$
    \det \begin{pmatrix} 3-\lambda & 1 \\ 0 & 2-\lambda \end{pmatrix} = (3-\lambda)(2-\lambda) - (1)(0) = (3-\lambda)(2-\lambda)
    $$
3.  **Solve for $\lambda$**.
    $$
    (3-\lambda)(2-\lambda) = 0
    $$
    The solutions are $\lambda_1 = 3$ and $\lambda_2 = 2$.

**Answer:** The eigenvalues are **3** and **2**.
</details>

##### **5.2 Find Eigenvectors**
**Question:** Find the eigenvectors for the matrix $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$ using the eigenvalues found previously ($\lambda_1 = 3, \lambda_2 = 2$).
<details>
<summary>Click to see the solution</summary>

**For $\lambda_1 = 3$**:
1.  Solve $(A - 3I)\vec{v} = \vec{0}$.
    $$
    \begin{pmatrix} 3-3 & 1 \\ 0 & 2-3 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 0 & 1 \\ 0 & -1 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
    $$
2.  This gives the equations $0x + 1y = 0$ and $0x - 1y = 0$, both of which simplify to $y=0$. The variable `x` can be any non-zero value. Thus, any vector of the form $\begin{pmatrix} x \\ 0 \end{pmatrix}$ is an eigenvector. A simple choice is $\vec{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$.

**For $\lambda_2 = 2$**:
1.  Solve $(A - 2I)\vec{v} = \vec{0}$.
    $$
    \begin{pmatrix} 3-2 & 1 \\ 0 & 2-2 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 1 & 1 \\ 0 & 0 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
    $$
2.  This gives the equation $x + y = 0$, or $x = -y$. Any vector satisfying this condition, like $\begin{pmatrix} 1 \\ -1 \end{pmatrix}$, is an eigenvector. Let's choose $\vec{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$.

**Answer:** An eigenvector for $\lambda=3$ is **$\begin{pmatrix} 1 \\ 0 \end{pmatrix}$**. An eigenvector for $\lambda=2$ is **$\begin{pmatrix} 1 \\ -1 \end{pmatrix}$**.
</details>

##### **5.3 Verify an Eigenvector**
**Question:** Verify that $\vec{v} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$ is an eigenvector of the matrix $B = \begin{pmatrix} 4 & -1 \\ 2 & 1 \end{pmatrix}$ and find its eigenvalue.
<details>
<summary>Click to see the solution</summary>

1.  **Compute the left side of the equation $B\vec{v} = \lambda\vec{v}$**.
    $$
    B\vec{v} = \begin{pmatrix} 4 & -1 \\ 2 & 1 \end{pmatrix} \begin{pmatrix} 1 \\ 2 \end{pmatrix} = \begin{pmatrix} 4(1) - 1(2) \\ 2(1) + 1(2) \end{pmatrix} = \begin{pmatrix} 2 \\ 4 \end{pmatrix}
    $$
2.  **Compare the result with the original vector $\vec{v}$**.
    The result $\begin{pmatrix} 2 \\ 4 \end{pmatrix}$ is exactly $2 \times \begin{pmatrix} 1 \\ 2 \end{pmatrix}$.
3.  **Identify the eigenvalue**.
    Since $B\vec{v} = 2\vec{v}$, the vector $\vec{v}$ is an eigenvector and the corresponding eigenvalue is $\lambda = 2$.

**Answer:** $\vec{v} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$ is an eigenvector with an eigenvalue of **2**.
</details>

##### **5.4 Eigenvalues of a Diagonal Matrix**
**Question:** What are the eigenvalues and eigenvectors of the diagonal matrix $D = \begin{pmatrix} -5 & 0 \\ 0 & 4 \end{pmatrix}$?
<details>
<summary>Click to see the solution</summary>
A diagonal matrix scales the basis vectors.
-   The first basis vector $\begin{pmatrix} 1 \\ 0 \end{pmatrix}$ is scaled by -5.
-   The second basis vector $\begin{pmatrix} 0 \\ 1 \end{pmatrix}$ is scaled by 4.

The basis vectors are the eigenvectors, and the corresponding diagonal entries are the eigenvalues.

**Answer:** The eigenvalues are **-5** and **4**. The corresponding eigenvectors are **$\begin{pmatrix} 1 \\ 0 \end{pmatrix}$** and **$\begin{pmatrix} 0 \\ 1 \end{pmatrix}$**, respectively.
</details>

##### **5.5 Complex Eigenvalues**
**Question:** Find the eigenvalues for the rotation matrix $R = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$, which rotates vectors by 90 degrees counter-clockwise.
<details>
<summary>Click to see the solution</summary>

1.  **Set up the characteristic equation** $\det(R - \lambda I) = 0$.
    $$
    \det \left( \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} - \lambda \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \right) = \det \begin{pmatrix} -\lambda & -1 \\ 1 & -\lambda \end{pmatrix} = 0
    $$
2.  **Calculate the determinant**.
    $$
    (-\lambda)(-\lambda) - (-1)(1) = \lambda^2 + 1
    $$
3.  **Solve for $\lambda$**.
    $$
    \lambda^2 + 1 = 0 \implies \lambda^2 = -1
    $$
    This equation has no real solutions. The solutions are the complex numbers $\lambda = i$ and $\lambda = -i$.

**Answer:** The matrix has no real eigenvalues, indicating no real vectors are left on their span by the rotation. The eigenvalues are the complex numbers **$i$** and **$-i$**.
</details>

##### **5.6 Change to an Eigenbasis**
**Question:** Given the matrix $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$ and its eigenvectors $\vec{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ and $\vec{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}$, find the diagonal matrix `D` that represents the same transformation in the eigenbasis.
<details>
<summary>Click to see the solution</summary>
When we change to an eigenbasis, the new matrix is a diagonal matrix whose entries are the eigenvalues corresponding to the basis vectors.
-   The eigenvalue for $\vec{v}_1$ is $\lambda_1 = 3$.
-   The eigenvalue for $\vec{v}_2$ is $\lambda_2 = 2$.

The resulting diagonal matrix `D` will have these eigenvalues on its diagonal.

**Answer:** The diagonal matrix is **$D = \begin{pmatrix} 3 & 0 \\ 0 & 2 \end{pmatrix}$**.
</details>

##### **5.7 Computing Matrix Powers**
**Question:** Using the concept of diagonalization, compute $A^3$ for the matrix $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$.
<details>
<summary>Click to see the solution</summary>

1.  **Recall the necessary matrices** from the previous examples:
    -   Original Matrix: $A = \begin{pmatrix} 3 & 1 \\ 0 & 2 \end{pmatrix}$
    -   Change of Basis Matrix (eigenvectors as columns): $P = \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix}$
    -   Diagonal Matrix (eigenvalues on diagonal): $D = \begin{pmatrix} 3 & 0 \\ 0 & 2 \end{pmatrix}$
2.  **Find the inverse of P**. For a 2x2 matrix $\begin{pmatrix} a & b \\ c & d \end{pmatrix}$, the inverse is $\frac{1}{ad-bc}\begin{pmatrix} d & -b \\ -c & a \end{pmatrix}$.
    $$
    P^{-1} = \frac{1}{(1)(-1) - (1)(0)} \begin{pmatrix} -1 & -1 \\ 0 & 1 \end{pmatrix} = -1 \begin{pmatrix} -1 & -1 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix}
    $$
    (Interestingly, P is its own inverse).
3.  **Compute $D^3$**.
    $$
    D^3 = \begin{pmatrix} 3^3 & 0 \\ 0 & 2^3 \end{pmatrix} = \begin{pmatrix} 27 & 0 \\ 0 & 8 \end{pmatrix}
    $$
4.  **Compute $A^3 = PD^3P^{-1}$**.
    $$
    A^3 = \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix} \begin{pmatrix} 27 & 0 \\ 0 & 8 \end{pmatrix} \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix}
    $$
    First, multiply $P$ and $D^3$:
    $$
    \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix} \begin{pmatrix} 27 & 0 \\ 0 & 8 \end{pmatrix} = \begin{pmatrix} 27 & 8 \\ 0 & -8 \end{pmatrix}
    $$
    Then, multiply the result by $P^{-1}$:
    $$
    \begin{pmatrix} 27 & 8 \\ 0 & -8 \end{pmatrix} \begin{pmatrix} 1 & 1 \\ 0 & -1 \end{pmatrix} = \begin{pmatrix} 27(1)+8(0) & 27(1)+8(-1) \\ 0(1)-8(0) & 0(1)-8(-1) \end{pmatrix} = \begin{pmatrix} 27 & 19 \\ 0 & 8 \end{pmatrix}
    $$
**Answer:** $A^3 = \begin{pmatrix} 27 & 19 \\ 0 & 8 \end{pmatrix}$.
</details>