---
title: "11. Taylor Series, Polynomial Approximations, Calculus"
author: "Zakhar Podyakov"
date: "September 19, 2025"
format: html
engine: knitr
---

{{< video https://www.youtube.com/watch?v=3d6DsjIBzJ4&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=12 >}}

<!-- [QUIZ]() | [FLASHCARDS]() -->

#### **1. Summary**
##### **1.1 Introduction to Taylor Series**
The **Taylor series** is a fundamental concept in calculus that allows us to represent a function as an infinite sum of terms. These terms are calculated from the values of the function's derivatives at a single point. This method is incredibly powerful for approximating complex, non-polynomial functions with simpler polynomial functions, especially near a specific point. This is useful because polynomials are much easier to work withâ€”they are easy to compute, differentiate, and integrate. This makes Taylor series an essential tool in mathematics, physics, and engineering.

The core idea is that if you know a lot about a function at one single point (its value, its rate of change, the rate of change of its rate of change, and so on), you can use that information to construct a polynomial that "hugs" the original function's graph near that point. The more derivatives you use, the better the approximation becomes.

##### **1.2 The Intuition: An Example with a Pendulum**
A great way to understand the practical power of this approximation is through a physics problem, like calculating the potential energy of a pendulum.

###### **1.2.1 The Problem with the Original Function**
The height of a pendulum bob of length $R$ at an angle $\theta$ from the vertical is given by the expression $R(1 - \cos(\theta))$. While accurate, the $\cos(\theta)$ term can make calculations in physics (like solving differential equations of motion) awkward and complicated.

###### **1.2.2 The Small-Angle Approximation**
For small angles $\theta$ (close to 0), physicists often use the approximation:
$$ \cos(\theta) \approx 1 - \frac{\theta^2}{2} $$
This is actually the second-order Taylor polynomial for $\cos(\theta)$ around $\theta = 0$.

Substituting this approximation into the potential energy formula simplifies it significantly:
$$ R(1 - \cos(\theta)) \approx R(1 - (1 - \frac{\theta^2}{2})) = R(\frac{\theta^2}{2}) $$
This simplified quadratic expression is much easier to work with and provides a very accurate approximation for small oscillations, revealing a deeper connection to other oscillating systems like a mass on a spring.

<!-- DIAGRAM HERE -->

##### **1.3 Building a Polynomial Approximation for cos(x)**
Let's build this quadratic approximation for $f(x) = \cos(x)$ around the point $x=0$. Our goal is to find a polynomial $P(x) = c_0 + c_1x + c_2x^2$ that best matches $\cos(x)$ near this point. We do this by matching the derivatives of $P(x)$ and $\cos(x)$ at $x=0$.

- **Match the value (0th derivative):** We want the polynomial's value to match the function's value at $x=0$.
  - $f(0) = \cos(0) = 1$
  - $P(0) = c_0 + c_1(0) + c_2(0)^2 = c_0$
  - Therefore, we set $c_0 = 1$.

- **Match the first derivative:** We want the slope of the polynomial to match the slope of the function at $x=0$.
  - $f'(x) = -\sin(x)$, so $f'(0) = -\sin(0) = 0$.
  - $P'(x) = c_1 + 2c_2x$, so $P'(0) = c_1$.
  - Therefore, we set $c_1 = 0$.

- **Match the second derivative:** We want the concavity (how the slope is changing) to match at $x=0$.
  - $f''(x) = -\cos(x)$, so $f''(0) = -\cos(0) = -1$.
  - $P''(x) = 2c_2$.
  - Therefore, we set $2c_2 = -1$, which gives $c_2 = -\frac{1}{2}$.

Combining these coefficients, we get our approximation:
$$ P(x) = 1 + 0x - \frac{1}{2}x^2 = 1 - \frac{1}{2}x^2 $$
This is precisely the small-angle approximation we saw earlier.

<!-- DIAGRAM HERE -->

##### **1.4 The General Taylor Series Formula**
We can generalize this process for any function $f(x)$ that is infinitely differentiable at a point $a$. We want to find a polynomial $P(x) = c_0 + c_1(x-a) + c_2(x-a)^2 + \dots$ that matches all derivatives of $f(x)$ at $x=a$.

By taking successive derivatives of the polynomial and evaluating them at $x=a$, we find a pattern for the coefficients:
- $P(a) = c_0 \implies c_0 = f(a)$
- $P'(a) = c_1 \implies c_1 = f'(a)$
- $P''(a) = 2c_2 \implies c_2 = \frac{f''(a)}{2}$
- $P'''(a) = 3 \cdot 2 \cdot c_3 = 6c_3 \implies c_3 = \frac{f'''(a)}{6}$

In general, the nth coefficient is given by:
$$ c_n = \frac{f^{(n)}(a)}{n!} $$
where $f^{(n)}(a)$ is the nth derivative of $f$ evaluated at $a$, and $n!$ is the factorial of $n$.

This gives the formula for the **Taylor series** of a function $f(x)$ about a point $a$:
$$ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!} (x-a)^n = f(a) + f'(a)(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \dots $$
When the series is centered at $a=0$, it is called a **Maclaurin series**.

##### **1.5 Convergence and Radius of Convergence**
An infinite series does not always produce a finite, meaningful number. For a Taylor series to be useful, it must **converge**.

- **Convergence**: A series converges if the sequence of its partial sums (adding more and more terms) approaches a specific finite limit.
- **Divergence**: If the partial sums do not approach a limit, the series diverges.

The **radius of convergence** is the distance from the center point $a$ within which the Taylor series is guaranteed to converge to the actual function value.
- For functions like $e^x$, $\sin(x)$, and $\cos(x)$, the radius of convergence is infinite; their Taylor series match the function for all real numbers $x$.
- For other functions, like $\ln(x)$ centered at $a=1$, the radius is finite. The series for $\ln(x)$ only converges for $x$ in the interval $(0, 2]$. Outside this range, the polynomial approximations diverge wildly from the actual function.

#### **2. Definitions**
*   **Taylor Series**: An expansion of a function into an infinite sum of terms, where each term is calculated from the function's derivatives at a single point (the center). It represents the function in a neighborhood around that point.
*   **Taylor Polynomial**: A finite sum of the initial terms of a Taylor series. An nth-degree Taylor polynomial is a polynomial of degree $n$ that provides an approximation of the function near the center point.
*   **Maclaurin Series**: A special case of the Taylor series where the expansion is centered around the point $a=0$.
*   **Approximation**: The process of using a simpler function, such as a polynomial, to estimate the values of a more complex function within a certain range.
*   **Convergence**: The property of an infinite series where its partial sums approach a finite limit as the number of terms increases.
*   **Radius of Convergence**: For a Taylor series centered at $a$, it is the value $R$ such that the series converges for all $x$ where $|x-a| < R$ and diverges for all $x$ where $|x-a| > R$.

#### **3. Formulas**
*   **General Taylor Series about $x=a$**:
    $$ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n = f(a) + \frac{f'(a)}{1!}(x-a) + \frac{f''(a)}{2!}(x-a)^2 + \frac{f'''(a)}{3!}(x-a)^3 + \dots $$
*   **Maclaurin Series (Taylor Series about $x=0$)**:
    $$ f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(0)}{n!}x^n = f(0) + \frac{f'(0)}{1!}x + \frac{f''(0)}{2!}x^2 + \frac{f'''(0)}{3!}x^3 + \dots $$
*   **Taylor Series for $e^x$ at $a=0$**:
    $$ e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \dots $$
*   **Taylor Series for $\cos(x)$ at $a=0$**:
    $$ \cos(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n} = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots $$
*   **Taylor Series for $\sin(x)$ at $a=0$**:
    $$ \sin(x) = \sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!}x^{2n+1} = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots $$

#### **4. Mistakes**
*   **Forgetting the factorial ($n!$):** A very common mistake is to omit the $n!$ in the denominator of the terms. **Why it's wrong:** The factorial term arises from repeatedly differentiating the power $(x-a)^n$ and is essential for the polynomial's derivatives to match the function's derivatives.
*   **Using the wrong center point:** Evaluating the derivatives at a point other than the center $a$ of the expansion. **Why it's wrong:** The entire theory is based on using local information at the point $a$ to build the approximation. Using derivatives from another point will result in an incorrect polynomial.
*   **Assuming a series always converges:** Believing that a Taylor series for a function will approximate it for any value of $x$. **Why it's wrong:** Many Taylor series only converge within a specific radius of convergence. Outside this radius, the series diverges and is useless for approximation.
*   **Incorrectly calculating higher-order derivatives:** Making an error in finding the derivatives of the function $f(x)$. **Why it's wrong:** The coefficients of the series depend directly on these derivatives, so any mistake will lead to an incorrect series.

#### **5. Examples**
##### **5.1. Finding the Taylor Series for $e^{2x}$**
**Question:** Find the first four non-zero terms of the Maclaurin series (centered at $a=0$) for the function $f(x) = e^{2x}$.
<details>
<summary>Click to see the solution</summary>
1.  **Calculate the first few derivatives of $f(x)$:**
    *   $f(x) = e^{2x}$
    *   $f'(x) = 2e^{2x}$
    *   $f''(x) = 4e^{2x}$
    *   $f'''(x) = 8e^{2x}$
2.  **Evaluate these derivatives at the center $a=0$:**
    *   $f(0) = e^0 = 1$
    *   $f'(0) = 2e^0 = 2$
    *   $f''(0) = 4e^0 = 4$
    *   $f'''(0) = 8e^0 = 8$
3.  **Use the Maclaurin series formula to construct the polynomial:**
    $$ P(x) = f(0) + \frac{f'(0)}{1!}x + \frac{f''(0)}{2!}x^2 + \frac{f'''(0)}{3!}x^3 + \dots $$
4.  **Substitute the values:**
    $$ P(x) = 1 + \frac{2}{1}x + \frac{4}{2}x^2 + \frac{8}{6}x^3 + \dots = 1 + 2x + 2x^2 + \frac{4}{3}x^3 + \dots $$

**Answer:** The first four terms are **$1 + 2x + 2x^2 + \frac{4}{3}x^3$**.
</details>

##### **5.2. Approximating $\sqrt{x}$ near $x=9$**
**Question:** Find the second-degree Taylor polynomial for $f(x) = \sqrt{x}$ centered at $a=9$.
<details>
<summary>Click to see the solution</summary>
1.  **Calculate the required derivatives:**
    *   $f(x) = x^{1/2}$
    *   $f'(x) = \frac{1}{2}x^{-1/2}$
    *   $f''(x) = -\frac{1}{4}x^{-3/2}$
2.  **Evaluate the derivatives at the center $a=9$:**
    *   $f(9) = \sqrt{9} = 3$
    *   $f'(9) = \frac{1}{2}(9)^{-1/2} = \frac{1}{2 \cdot 3} = \frac{1}{6}$
    *   $f''(9) = -\frac{1}{4}(9)^{-3/2} = -\frac{1}{4 \cdot 27} = -\frac{1}{108}$
3.  **Construct the second-degree Taylor polynomial:**
    $$ P_2(x) = f(9) + \frac{f'(9)}{1!}(x-9) + \frac{f''(9)}{2!}(x-9)^2 $$
4.  **Substitute the values:**
    $$ P_2(x) = 3 + \frac{1/6}{1}(x-9) + \frac{-1/108}{2}(x-9)^2 = 3 + \frac{1}{6}(x-9) - \frac{1}{216}(x-9)^2 $$

**Answer:** The second-degree Taylor polynomial is **$P_2(x) = 3 + \frac{1}{6}(x-9) - \frac{1}{216}(x-9)^2$**.
</details>

##### **5.3. Full Taylor Series for $\sin(x)$**
**Question:** Find the Maclaurin series for $f(x) = \sin(x)$.
<details>
<summary>Click to see the solution</summary>
1.  **Find the derivatives and evaluate at $a=0$:**
    *   $f(x) = \sin(x) \implies f(0) = 0$
    *   $f'(x) = \cos(x) \implies f'(0) = 1$
    *   $f''(x) = -\sin(x) \implies f''(0) = 0$
    *   $f'''(x) = -\cos(x) \implies f'''(0) = -1$
    *   $f^{(4)}(x) = \sin(x) \implies f^{(4)}(0) = 0$
    The pattern of derivative values at 0 is $0, 1, 0, -1, 0, \dots$
2.  **Plug into the Maclaurin formula:**
    $$ \sin(x) = \frac{0}{0!} + \frac{1}{1!}x + \frac{0}{2!}x^2 + \frac{-1}{3!}x^3 + \frac{0}{4!}x^4 + \frac{1}{5!}x^5 + \dots $$
3.  **Simplify the series:**
    $$ \sin(x) = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots $$

**Answer:** The Maclaurin series for $\sin(x)$ is **$\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n+1)!}x^{2n+1}$**.
</details>

##### **5.4. Approximation of $\cos(0.1)$**
**Question:** Use the second-order Taylor polynomial for $\cos(x)$ at $x=0$ to approximate $\cos(0.1)$.
<details>
<summary>Click to see the solution</summary>
1.  **Recall the second-order Taylor polynomial for $\cos(x)$ at $x=0$:**
    From section 1.3, we know $P_2(x) = 1 - \frac{x^2}{2}$.
2.  **Substitute $x=0.1$ into the polynomial:**
    $$ \cos(0.1) \approx P_2(0.1) = 1 - \frac{(0.1)^2}{2} $$
3.  **Calculate the result:**
    $$ 1 - \frac{0.01}{2} = 1 - 0.005 = 0.995 $$
    (The actual value is approximately $0.995004165...$, so this is a very good approximation).

**Answer:** The approximation for $\cos(0.1)$ is **$0.995$**.
</details>

##### **5.5. Taylor Polynomial for $\ln(1+x)$**
**Question:** Find the third-order Taylor polynomial for $f(x) = \ln(1+x)$ centered at $a=0$.
<details>
<summary>Click to see the solution</summary>
1.  **Calculate derivatives and evaluate at $a=0$:**
    *   $f(x) = \ln(1+x) \implies f(0) = \ln(1) = 0$
    *   $f'(x) = (1+x)^{-1} \implies f'(0) = 1$
    *   $f''(x) = -(1+x)^{-2} \implies f''(0) = -1$
    *   $f'''(x) = 2(1+x)^{-3} \implies f'''(0) = 2$
2.  **Construct the third-order polynomial:**
    $$ P_3(x) = f(0) + \frac{f'(0)}{1!}x + \frac{f''(0)}{2!}x^2 + \frac{f'''(0)}{3!}x^3 $$
3.  **Substitute the values:**
    $$ P_3(x) = 0 + \frac{1}{1}x + \frac{-1}{2}x^2 + \frac{2}{6}x^3 = x - \frac{1}{2}x^2 + \frac{1}{3}x^3 $$

**Answer:** The third-order Taylor polynomial is **$P_3(x) = x - \frac{1}{2}x^2 + \frac{1}{3}x^3$**.
</details>

##### **5.6. Finding a Specific Coefficient**
**Question:** Determine the coefficient of the $x^5$ term in the Maclaurin series for $f(x) = \frac{x}{1-x^2}$.
<details>
<summary>Click to see the solution</summary>
1.  **Recall the geometric series formula**: $\frac{1}{1-r} = 1 + r + r^2 + r^3 + \dots$
2.  **Substitute $r=x^2$**:
    $$ \frac{1}{1-x^2} = 1 + (x^2) + (x^2)^2 + (x^2)^3 + \dots = 1 + x^2 + x^4 + x^6 + \dots $$
3.  **Multiply the entire series by $x$ to get $f(x)$:**
    $$ f(x) = x \left( \frac{1}{1-x^2} \right) = x(1 + x^2 + x^4 + x^6 + \dots) = x + x^3 + x^5 + x^7 + \dots $$
4.  **Identify the coefficient of the $x^5$ term.** The term is $x^5$, so its coefficient is 1.

**Answer:** The coefficient is **1**.
</details>

##### **5.7. Using a Known Series**
**Question:** Find the Maclaurin series for $f(x) = x^2 \cos(x)$.
<details>
<summary>Click to see the solution</summary>
1.  **Start with the known Maclaurin series for $\cos(x)$:**
    $$ \cos(x) = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots $$
2.  **Multiply each term in the series by $x^2$:**
    $$ f(x) = x^2 \left( 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots \right) $$
3.  **Distribute the $x^2$:**
    $$ f(x) = x^2 - \frac{x^4}{2!} + \frac{x^6}{4!} - \frac{x^8}{6!} + \dots $$

**Answer:** The Maclaurin series for $x^2 \cos(x)$ is **$\sum_{n=0}^{\infty} \frac{(-1)^n}{(2n)!}x^{2n+2}$**.
</details>